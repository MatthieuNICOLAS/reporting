#+STARTUP: inlineimages
#+TODO: TODO IN-PROGRESS CANCELLED DONE

* Journal de bord
** Semaine du <2016-09-12 lun.> au <2016-09-16 ven.>
*** Done
- Faire un état de l'art des mécanismes d'authentification
  - Différences entre OAuth et OpenID
    - OAuth est un protocole d'*autorisation*
    - Il permet à un utilisateur de donner accès à certaines données/actions de son compte à un service tiers
      - Exemple avec Google +
	- Récupérer les informations du profil
	- Récupérer les informations des cercles d'amis de l'utilisateur
	- Envoyer des mails au nom de l'utilisateur
      - Exemple avec GitHub
	- Récupérer les informations du profil
	- Accéder aux repos de l'utilisateur
	- Faire des commits en son nom
    - Il ne s'agit cependant pas d'un protocole d'*authentification*
      - On peut supposer que si Google ou GitHub nous donne accès au compte de l'utilisateur, c'est car ce dernier s'est authentifié correctement
      - Mais rien n'empêche un site ayant obtenu un code (car l'utilisateur a donné l'autorisation à ce dernier) d'utiliser ce code pour usurper l'identité de l'utilisateur sur un autre site
    - OpenID lui est un protocole d'*authentification*
      - Il permet seulement de vérifier l'identité d'un utilisateur
      - Il ne permet pas d'accéder à des données de son compte autre que celles du profil
    - OpenID Connect est un protocole basé sur OAuth 2.0 qui ajoute une couche d'authentification au protocole
    - Sources
      - http://security.stackexchange.com/questions/44611/difference-between-oauth-openid-and-openid-connect-in-very-simple-term
      - https://oauth.net/2/
      - https://en.wikipedia.org/wiki/OpenID
      - http://openid.net/connect/
      - http://www.thread-safe.com/2012/01/problem-with-oauth-for-authentication.html
  - Libraries/Frameworks
    - Pour OAuth2: https://oauth.net/code/
    - Pour OpenID Connect: http://openid.net/developers/libraries/
*** Planned
** Semaine du <2016-09-19 lun.> au <2016-09-23 ven.>
*** Done
- Faire un état de l'art des mécanismes d'authentification
  - Réalisation des slides
    - Disponibles ici : https://github.com/MatthieuNICOLAS/authentication-systems-2016-09-20/
  - Ajout des nouvelles sources :
    - [[https://pdfs.semanticscholar.org/3733/2607f7a7ac8284c514845957fd00583e5614.pdf][Different Ways to Authenticate Users with the Pros and Cons of each Method]]
      - Bonne définition de l'*Authentification*.
      - Parle de l'authentification à facteurs multiples :
        - Passwords
        - Smart cards
        - X509 certificate
        - Biometrics
      - Présente les avantages et inconvénients ainsi que les vulnérabilités de chacune.
    - [[http://stackoverflow.com/questions/663402/what-are-the-differences-between-ldap-and-active-directory][What are the differences between LDAP and Active Directory?]]
      - Donne les définitions de *Directory Service*, *Active Directory* et *Lightweight Directory Access Protocol*
    - [[https://www.neustar.biz/blog/what-is-single-sign-on-deployment-pros-cons][The Pros & Cons of Implementing Single Sign-On]]
      - Explique les différences entre *Full Sign-On*, *Reduced Sign-On* et *Federated Logins*
    - [[https://tools.ietf.org/html/rfc6749][RFC 6749 - The OAuth 2.0 Authorization Framework]]
      - Description du protocole OAuth 2.0
    - [[http://wiki.oauth.net/w/page/27249271/OAuth%202%20for%20Native%20Apps][OAuth 2 for Native Apps]]
    - [[https://tools.ietf.org/html/draft-ietf-oauth-native-apps-03][Authorization Flow for Native Apps Using App-Claimed URI Schemes]]
    - [[http://nat.sakimura.org/2012/01/20/openid-connect-nutshell/][OpenID Connect in a nutshell]]
    - [[http://wiki.openid.net/w/page/12995171/Introduction][OpenID explaination]]
    - [[https://en.wikipedia.org/wiki/OAuth#/media/File:OpenIDvs.Pseudo-AuthenticationusingOAuth.svg][OpenID Authentication vs Pseudo-Authentication using OAuth]]
    - [[https://www.owasp.org/index.php/Authentication_Cheat_Sheet][Authentication Cheat Sheet]]
- Finaliser les slides sur les mécanismes d'authentification et les envoyer à TVPaint
  - Ajout de références vers les articles lus/utilisés et pouvant s'avérer utiles pour leur compréhension
  - Création d'un thread sur le forum de TVPaint pour linker les slides et les inviter à poser leurs questions
- MUTE : Implémenter le bot de traduction
  - Problème avec la librairie *mute-client*
    - *mute-client* embarque *AceEditorAdapter*
    - Ce code JS suppose que *AceEditor* est dans le scope
    - Ce n'est pas le cas dans le bot
- PLM : Activer Blockly
  - Modification du code de *GitActor* pour gérer les langages de programmation visuels
    - Stocker le code généré par l'outil de programmation visuel
    - Mais aussi stocker le /code visuel/
      - Pour pouvoir regénérer l'espace de travail de l'apprenant à sa prochaine connexion
  - Modification du code de *PLMActor* pour gérer les langages de programmation visuels
    - Envoi à *GitActor* le /code visuel/
    - Lors de la récupération de la session de l'utilisateur, on ne récupère pas le code de l'élève
      - Puisqu'il s'agit du code généré par l'outil de programmation visuel
        - Par exemple du code Python dans le cas de Blockly
    - Il faut récupérer plutôt le /code visuel/ pour regénérer l'espace de travail
    - Pour le moment, on se contente de renvoyer un /code visuel/ vide
  - Activation de Blockly
    - Création d'une instance de *LangBlockly*
    - Ajout de celle-ci dans les langages de programmation supportés
  - Modification du code pour gérer les exercices ne supportant pas Blockly
    - Passage automatique au langage de programmation par défaut si le langage courant n'est pas supporté
    - Affichage d'un message d'avertissement lorsque l'utilisateur essaie de passer à un langage non-supporté par l'exo courant
  - Mise à jour des sérialisation JSON des exercices
*** Planned
**** DONE Faire un état de l'art des mécanismes d'authentification
- Étudier les différents mécanismes existants et comment ils interagissent entre eux
  - SAML
  - SOAP
  - OAuth
  - OpenID
  - LDAP

**** DONE Finaliser les slides sur les mécanismes d'authentification et les envoyer à TVPaint
- J'ai noté quelques sources qui pourraient s'avérer utiles pour TVPaint
- Les ajouter aux slides
- Envoyer les slides à TVPaint
**** DONE PLM : Activer Blockly
- [[http://www.pentilanero.com/][Pentila]] m'a recontacté à propos de PLM
- Ils sont en train de travailler sur PLM pour voir comment ajouter de nouveaux exercices fonctionnant avec Blockly
- Sauf que j'ai désactivé Blockly lors du refactoring
- Activer de nouveau Blockly
- Vérifier son bon fonctionnement
** Semaine du <2016-09-26 lun.> au <2016-09-30 ven.>
*** Done
- TVPaint : Réviser les notions autour du *Business Process* et des *Workflows*
  - L'activité /Call/ est-elle utilisable ou à éviter ?
  - Que signifie la notion d'entité lorsqu'on parle de /Choreography/ ?
    - Similaire à la notion de /Pool/ ?
  - Différences entre /Choreography/ et /Collaboration/
    - Pourquoi utiliser l'un et pas l'autre ?
    - Formalisme différent, et la /Choreography/ fonctionne par le biais d'envoi de messages
  - Une /Choreography/ est-elle forcément entre 2 entités ?
    - Il n'y a jamais eu le besoin de définir une choréographie entre 3+ entités ?
    - Non, une /Choreography/ peut avoir lieu entre 3+ entités
- MUTE : Implémenter le bot de traduction
  - Ajout de la classe *TranslatorBot*
    - Instancie un *Bot* pour être pouvoir être ajouté au réseau
    - Instancie un *Coordinator* lors de son ajout au réseau
    - Écoute l'évènement /update/ du *Coordinator* pour déclencher l'opération de traduction
    - Écoute l'évènement /operations/ du *Coordinator* pour transmettre les opérations générées localement aux pairs
    - Lors d'un /update/, parcourt le document pour trouver le texte à traduire
      - Le texte à traduire est délimité par les balises suivantes
        - /tl <langue source> <langue destination>
        - end/
    - Demande à *YandexTranslateService* de traduire le texte
    - Remplace le texte à traduire + balises par le résultat renvoyé par *YandexTranslateService*
  - Malheureusement, ce n'était pas le comportement attendu
    - On souhaite insérer une balise dans le document
    - Le bot doit
      - Récupérer le texte précédent cette balise
      - Le traduire
      - L'insérer après la balise
  - Implémentation de ce comportement
    - Ajout de *RealTimeTranslator*
    - Détecte le tag de l'utilisateur /rt
    - Le remplace par son propre tag
      - Cela lui permet de récupérer l'ID LogootSplit de ce tag
      - Cet ID est ensuite utilisé pour récupérer l'index du tag dans le document
    - Traduit le texte
      - Utilise /diff/ pour comparer l'ancienne traduction et la nouvelle
      - Permet de seulement mettre à jour les parties de la traduction concernées par les modifications du texte initial
- PLM : Corriger l'exécution du code de l'apprenant en Python
  - Le bug rencontré par Cédric n'est pas reproductible dans mon environnement de dev
  - Par contre, dans un container Docker basé sur l'image de webPLM, je rencontre une erreur lié à *JRuby*
    - Je n'inclus pas le jar de *JRuby* dans *PLM-engine*
  - Ajout de *JRuby* dans *PLM-engine*
    - Résous l'erreur lié à *JRuby*
  - Je rencontre dorénavant l'erreur reportée par Cédric
    - Cette erreur semble liée à la version de *Jython* utilisée
  - Mise à jour de *Jython*
  - Le plus troublant est que les juges arrivaient à exécuter du code Python
    - *JRuby* était correctement inclus dans le jar de *PLM* fourni aux juges
    - Mais ils auraient dû déclencher l'erreur liée à la version de *Jython*
*** Planned
**** DONE PLM : Corriger l'exécution du code de l'apprenant en Python
- Cédric de Pentila m'a contacté à propos des problèmes qu'il rencontre pour exécuter du code Python
- Il rencontre l'erreur suivante en essayant d'exécuter son programme Python
#+BEGIN_SRC
java.lang.NullPointerException
  at org.python.core.Py.recursiveIsInstance(Py.java:1861)
  at org.python.core.Py.isInstance(Py.java:1828)
  at org.python.core.__builtin__.isinstance(__builtin__.java:725)
  at org.python.core.Py.displayException(Py.java:1009)
  at org.python.core.PyException.printStackTrace(PyException.java:79)
  at org.python.core.PyException.toString(PyException.java:98)
  at java.lang.Throwable.<init>(Throwable.java:311)
  at java.lang.Exception.<init>(Exception.java:102)
  at javax.script.ScriptException.<init>(ScriptException.java:65)
  at org.python.jsr223.PyScriptEngine.scriptException(PyScriptEngine.java:192)
  at org.python.jsr223.PyScriptEngine.eval(PyScriptEngine.java:43)
  at org.python.jsr223.PyScriptEngine.eval(PyScriptEngine.java:33)
  at javax.script.AbstractScriptEngine.eval(AbstractScriptEngine.java:264)
  at plm.core.lang.ScriptingLanguage.runEntity(Unknown Source)
  at plm.core.model.lesson.ExerciseRunner$3.run(Unknown Source)
  at java.lang.Thread.run(Thread.java:745)
#+END_SRC
- Trouver l'origine de cette erreur et la résoudre
**** DONE MUTE : Implémenter le bot de traduction
- Dans le cadre de l'évaluation de l'équipe du 13 octobre, une démo de [[https://github.com/coast-team/mute-demo][MUTE]] est prévue
- L'idée est de mettre en avant la fonctionnalité des bots à l'aide d'un bot qui traduirait pour nous le document
- Le code du bot est disponible ici : https://github.com/coast-team/mute-bot-eve
- Analyser le document pour détecter les parties du document à traduire
- Interroger *Yandex* pour traduire le texte
- Remplacer le texte par sa traduction
**** DONE TVPaint : Réviser les notions autour du *Business Process* et des *Workflows*
- Nécessaire pour pouvoir mieux appréhender la tâche consistant à définir un process pour représenter le déroulement de la réalisation d'un film avec TVPaint
- Sources à utiliser:
  - http://webloria.loria.fr/~charoy/uploads/Main/BPM2pp.pdf
  - http://www.workflowpatterns.com/
  - http://fr.bonitasoft.com/ressources
** Semaine du <2016-10-03 lun.> au <2016-10-07 ven.>
*** Done
- TVPaint : Définir le business process correspondant à la réalisation d'un film
  - Quelques questions sont apparus au cours de la réalisation
    - Est-ce qu'il y a une phase de validation
      - Après la réalisation du storyboard
      - Après la réalisation de l'animatique
    - Est-ce que l'animatique et le storyboard se font de façon séquentielle ou parallèle?
    - Est-ce que l'animatique "modifie" le storyboard ou produit une nouvelle donnée?
    - Qui s'occupe de l'élaboration du layout du shot?
    - Est-ce que l'élaboration du layout du shot inclus le typage de chaque clip?
- PLM : Release d'une nouvelle version de PLM
  - Transfert des commits modifiant l'UI dans une branche distincte
  - Activation des leçons sur la récursivité
  - Correction du nom des fichiers de consignes pour l'exercice *Occurrences*
  - Correction de l'entité Java de l'exercice *IsMember*
  - Augmentation de la limite de temps d'exécution de PLM-judge
  - Release de webPLM:2.1.1 et de PLM-judge:2.1.1
- PLM : Corriger l'exécution de code Java
  - L'erreur ne semble se produire qu'en exécutant du code via les juges
  - L'erreur est liée à 2 morceaux de code
    - [[https://github.com/BuggleInc/PLM/blob/master/src/plm/core/lang/ProgrammingLanguage.java#L131-L139][ProgrammingLanguage.getProgrammingLanguage()]]
    - [[https://github.com/BuggleInc/PLM/blob/master/src/plm/core/model/lesson/BlankExercise.java#L26-L27][BlankExercise()]]
  - Lorsqu'on désérialise un exercice, on regénère les instances de *SourceFile* pour chaque langage de programmation
  - Ainsi, on instancie le *SourceFile* et on le stocke dans une *Map* en l'associant au *ProgrammingLanguage* retourné par /getProgrammingLanguage()/
  - Sauf que la fonction /getProgrammingLanguage()/ retourne une valeur par défaut s'il ne trouve pas de *ProgrammingLanguage* correspondant à la chaîne passée en paramètre
  - Du coup, lorsqu'on rencontre un *ProgrammingLanguage* inconnu, on remplace le *SourceFile* associé au langage par défaut par celui nouvellement créé
  - Ici, c'est *Blockly* qui n'est pas supporté par *PLM-judge* et qui pose problème
  - Ajout du support de *Blockly*
  - Ouverture d'une issue pour garder une trace du problème : https://github.com/BuggleInc/PLM/issues/477
- PLM : Corriger l'exercice Polygon360
  - L'erreur ne provient pas de la sérialisation JSON stockée
    - Supprimer la sérialisation de l'exercice et l'instancier depuis les sources ne corrige pas le problème
  - Le plus troublant est l'affichage du monde objectif
  - Une partie du polygone semble manquer dans le monde objectif
    #+CAPTION: Partie manquante du polygone
    #+NAME:   fig:polygon360-missingline.png
    [[file:img/polygon360-missingline.png]]
  - Représentation des lignes indiquées dans le message d'erreur
    #+CAPTION: Lignes posant problème
    #+NAME:   fig:polygon360-showlines.png
    [[file:img/polygon360-showlines.png]]
    - La ligne bleue correspond à la ligne manquante dans le monde objectif
    - La ligne rouge correspond à la ligne manquante dans le monde courant
  - On arrive à la même conclusion en listant les *Shapes* présentes dans chacun des mondes
    #+BEGIN_SRC
    // Lines of the current world with x1 or x2 > 262
    CurrentWorld: Line (x262,263 y127,117 / x263,445 y135,028 / black)
    CurrentWorld: Line (x262,923 y164,938 / x263,968 y154,996 / black)
    CurrentWorld: Line (x263,445 y135,028 / x264,177 y149,000 / black)

    // Lines of the answer world with x1 or x2 > 262
    AnswerWorld: Line (x262,263 y127,117 / x263,445 y135,028 / black)
    AnswerWorld: Line (x262,923 y164,938 / x263,968 y154,996 / black)
    AnswerWorld: Line (x263,968 y154,996 / x264,177 y149,000 / black)
    #+END_SRC
*** Planned
**** DONE PLM : Release une nouvelle version de PLM
- Pour le module de TOP à TN, les étudiants vont travailler sur PLM
- Les enseignements de ce module porte notamment sur la récursivité
- Les leçons correspondantes ne sont pas activées dans la version actuelle de la PLM
- Les activer et déployer la nouvelle version
**** DONE PLM : Corriger l'exécution de code Java
- Depuis la mise à jour, l'exécution du code Java génère une erreur
  #+BEGIN_SRC
  Compilation error: Environment.java:0:class, interface, or enum expected
  #+END_SRC
- Trouver l'origine de l'erreur et la corriger
** Semaine du <2016-10-10 lun.> au <2016-10-14 ven.>
*** Done
- TVPaint : Définir le business process correspondant à la réalisation d'un film
  - Ajout des phases de vérification pour
    - Le storyboard
    - L'animation
  - Ajout des données des formulaires
    - Création du film
    - Phases de vérification
  - Difficultés rencontrées
    - Bloque sur l'instanciation d'un *Storyboard* et d'une *Animation* à partir des fichiers soumis par les utilisateurs
    - Aussi des difficultés sur la multi-instanciation du process pour gérer un shot
      - On souhaite générer une instance du process pour chaque shot
      - La liste des shots se trouvent dans l'instance de *Film*
      - Mais je n'arrive pas accéder à la variable de process /movie/
      - Pour l'instant, je passe par une autre variable de process /shots/
    - Je n'arrive plus non plus à créer un type /enum/ avec Bonita Soft
  - Quelques questions sur le workflow
    - Que se passe-t-il/que fait-on si un shot ne passe pas la dernière étape de validation?
      - L'étape de validation concernée se trouve après l'activité /compositing/
      - Est-ce qu'elle ne sert qu'à valider cette activité ou elle sert à valider l'ensemble des clips?
  - Quelques questions sur les modèles de données
    - À quoi correspond le modèle de données *Scene* ?
    - Que contient le modèle de données *Animation* ?
- MUTE : Préparer la démo pour l'évaluation INRIA
  - Philippe a installé les différents composants de la démo sur les Raspberries et configuré les interfaces réseaux
  - Scénario :
    - Introduction
      - Au départ, seul MUTE est déployé
      - Le bot est démarré, mais il n'est pas encore relié au réseau
      - Gérald (qui projetera son écran) se connectera à un document pré-existant
      - Collaboration rapide pour montrer l'aspect temps réel
    - Ajout du bot
      - On le connecte au réseau
      - On l'invite dans l'édition collaborative
      - On l'active
      - On observe qu'il traduit le texte déjà existant et met ensuite à jour en temps réel (mais avec délai) la traduction
    - Sans serveur
      - On débranche la Raspberry correspondant au serveur
      - On observe que la collaboration fonctionne toujours
  - Texte à taper :
    #+BEGIN_QUOTE
    Pourquoi je veux vous réunir : pour vous ou pour moi?
    Evidemment pour moi, cela résoudrait tout pour moi ; j'en ai décidé ainsi depuis longtemps...
    On m'a raconté que votre soeur Adélaïde avait dit de mon portrait qu'avec une beauté pareille on pouvait bouleverser le monde.
    Mais j'ai renoncé au monde ; cela vous paraît drôle venant de moi, alors que vous me rencontrez couverte de bijoux et de dentelles en compagnie d'ivrognes et de scélérats?
    Ne faites pas attention à cela, je n'existe presque plus, et je le sais ; Dieu sait ce qui habite en moi à ma place.
    -- Dostoïevski dans son roman "Idiot"
    #+END_QUOTE
  - Répétition de la démo
- PLM : Release une image de NGINX pour le mode développement
  - Ajout d'un répertoire pour indiquer que la config actuelle est celle pour TELECOM Nancy
  - Modification de la configuration pour ajouter le reverse-proxy pour la queue de message
  - Ajout d'une autre configuration pour le mode développement
  - Génération des images Docker correspondantes
*** Planned
**** DONE PLM : Release une image de NGINX pour le mode développement
- Depuis le rework du protocole de communication avec les juges, NGINX est utilisé comme reverse-proxy pour accéder à la queue de message
  - Le port 15674 (utilisé par STOMP) n'est pas ouvert sur la machine de TN
  - NGINX permet d'accéder à ce port via un reverse-proxy
- Ceci empêche le docker-compose pour le mode développement de fonctionner correctement
  - Il ne met pas en place de NGINX
- Faire une image Docker de NGINX pour le développement
- Mettre à jour le docker-compose correspondant
**** DONE MUTE : Préparer la démo pour l'évaluation INRIA
- Tester l'environnement de la démo
- Établir le scénario de la démo
- Trouver un texte à taper et se le répartir
** Semaine du <2016-10-17 lun.> au <2016-10-21 ven.>
*** Done
- TVPaint : Définir le business process correspondant à la réalisation d'un film
  - De nouvelles questions sur le workflow
    - Est-ce que l'activité "Assignation outils/images" peut être entièrement automatisée ou pas?
- MUTE : Faire la roadmap du projet
  - La liste des tâches est disponible sur [[https://app.asana.com/][Asana]]
  - Définition des différentes étapes
    - v1: MUTE--
    - v2: Notepad equivalent
    - v3: Fourre-tout
  - Choix des technos
    - Angular 2
    - Angular Matérial 2
    - Ava
    - TSLint
*** Planned
**** DONE MUTE : Faire la roadmap du projet
- Pour répondre au besoin d'INRIA
- Lister les tâches à effectuer
- Les attribuer aux différentes étapes/versions du projet
- Établir le coût de chacune des tâches
**** DONE MUTE : Se former aux technologies choisies
- Lire [[https://books.ninja-squad.com/angular2][Become A Ninja With Angular 2]] et [[https://www.gitbook.com/book/basarat/typescript/details][TypeScript Deep Dive]]
** Semaines du <2016-11-14 lun.> au <2016-11-25 ven.>
*** Done
- MUTE : Développement de la nouvelle version de MUTE
  - Ajout de l'éditeur de texte *CodeMirror*
  - Création du modèle de données *LogootSRopes* du document
  - Détection des modifications de l'utilisateur et génération des *TextOperations* correspondantes
    - *TextInsert* et *TextDelete*
  - Mise à jour du modèle à partir de ces opérations textes
  - Envoi des *LogootSOperations* correspondantes aux modifications aux collaborateurs
  - Réception et ré-instantiation des *LogootSOperations*
  - Mise à jour du modèle à partir des opérations *LogootSplit*
  - Mise à jour de la vue du document
  - Passage à la nouvelle version de /Mute-structs/
  - Correction de bugs liées à la nouvelle version de /Mute-structs/
    - Suppression d'une boucle infinie dans la recherche d'un noeud
    - Correction des assertions effectuées lors des rotations
    - Correction des expressions permettant d'indiquer si l'on peut /append/ ou /prepend/ du texte à un bloc
** Semaine du <2016-11-28 lun.> au <2016-12-02 ven.>
*** Done
- TVPaint : Étudier comment collaborer dans un projet réalisé avec BonitaSoft
  - D'après [[http://community.bonitasoft.com/questions-and-answers/does-bonita-support-git-repository][ce topic]] et [[http://documentation.bonitasoft.com/6.x-7.2/workspaces-and-repositories-1][cette doc]], on ne peut pas partager un projet dans *Bonita* avec la version /Community/
  - La fonctionnalité est ajoutée dans la version /Subscription/
  - La doc ne semble disponible que pour SVN par contre
  - Et il manque les tarifs sur le site de *Bonita*, il faut prendre contact avec eux pour les obtenir
- MUTE : Développement du bot de stockage
  - Projet disponible [[https://github.com/coast-team/mute-bot-storage][ici]]
*** Planned
**** DONE TVPaint : Envoyer le travail effectué
**** DONE TVPaint : Étudier comment collaborer dans un projet réalisé avec BonitaSoft
- Voir si on peut partager avec Git
**** DONE MUTE : Développement du bot de stockage
** Semaine du <2016-12-05 lun.> au <2016-12-09 ven.>
*** Done
- MUTE : Lire l'article sur les barrières causales
  - Happened before relation
    - a -> b if a and b are events in the same process and a occured before b
    - a -> b if a is the event of sending a message M in a process and b is the event of delivery of the same message to another process
    - if a -> b and b -> c then a -> c
    - if a -/> b and b -/> a then a and b are said to be concurrent and represented as a || b
  - Reception != Delivery
    - Réception du message par le protocole de causal ordering
    - Livraison du message par le protocole de causal ordering à l'application
  - Destination set
    - Si on reçoit un message M2 ayant pour dépendance M1.
    - Si on a pas reçu M1 car on ne fait pas parti de son destination set, alors on peut le retirer de la liste des dépendances et délivrer M2.
  - Matrice Delivered
    - En local stocke et tient à jour matrice NxN Delivered tel que
      - Soit i le process courant, j et k 2 autres processes
      - Delivered(i)[j, k] = x indique que tous les messages de Pj à destination de Pk ayant une clock <= x ont été délivrés
	- Delivered(i) indique la matrice Delivered du process i
  - Vecteur CB
    - En local, maintien un vecteur CB de taille N de telle manière que si (k,x) appartiennent à CB(i)[j], cela implique que le prochain message de Pi à Pj devra être délivré uniquement après avoir reçu le Xième de Pk.
    - CB(i) = { j: { (process_id, counter), ... }, ... }
*** Planned
**** DONE MUTE : Lire l'article sur les barrières causales
- Maintenant que le bot de stockage est implémenté, on rencontre un problème lors de la synchronisation
- Si un utilisateur possède une version plus récente du document que le bot de stockage, celle-ci va se faire écraser lors de la synchronisation
- Alors qu'avec *LogootSplit*, on pourrait juste déterminer les opérations manquantes et synchroniser proprement les documents
- Dans un 1er temps on va implémenter un vecteur d'état pour déterminer les opérations manquantes
- Mais à terme, on pourra le remplacer par une barrière causale (ou mieux) pour optimiser le processus
- Se renseigner sur les barrières causales
** Semaine du <2016-12-12 lun.> au <2016-12-16 ven.>
*** Done
- MUTE : Refactorer *DocService*
  - Gestion des messages spécifiques à ce service dans *DocService*
    - Réception des messages
    - Sérialisation/Désérialisation des objets de /mute-structs/
  - Remplacement des instances de *Subject* par des couples *Observable*/*Observer*
    - Le but de *Subject* a l'air d'émettre une valeur, et non pas une suite d'évènements
      - *AsyncSubject* peut posséder plusieurs valeurs au cours du temps, mais celle-ci n'est émise seulement qu'à la complétion du /stream/
      - *BehaviorSubject* permet d'émettre plusieurs valeurs au cours du temps, mais il a besoin d'une valeur initiale et garde en mémoire la dernière valeur émise
      - *ReplaySubject* permet d'émettre plusieurs valeurs au cours du temps, mais il rejoue l'historique des valeurs à chaque abonné
    - C'est le couple *Observable*/*Observer* qui semble le plus indiqué dans ce cas
      - Il permet d'émettre plusieurs valeurs au cours du temps
      - Aucune valeur n'est nécessaire à sa création
      - Si on s'y abonne "en retard", on ne recevra que les prochaines valeurs émises
- MUTE : Ajouter *EditorService*
  - Ajout de *EditorService*
  - Modification de *DocService* pour lire les opérations locales à partir du stream
  - Modification de *EditorComponent* pour émettre les opérations via *EditorService*
- MUTE : Nettoyer les streams
  - À la destruction de *EditorComponent*, le stream /operationStream/ n'est pas automatiquement détruit.
  - Désabonnement aux streams à la destruction de *EditorComponent*
  - Ajout d'une méthode /clean()/ à *DocService* pour déclencher le désabonnement aux streams
  - Appel de /DocService.clean()/ à la destruction de *DocComponent*
- MUTE : Trouver l'origine du bug empêchant d'envoyer les opérations locales
  - Le problème provient plus exactement de la sérialisation de l'opération *LogootSAdd* ou *LogootSDel*
  - Maintenant qu'on utilise la version corrigée de /mute-structs/, j'ai mis à jour la définition du message *Identifier* dans /protobuf/
  - Au lieu d'envoyer une liste de /double/, j'envoie désormais une liste de /int32/
  - Cependant, le /replicaNumber/ fourni par /sigver/ est potentiellement un /double/
    - Voir https://github.com/coast-team/sigver/blob/master/src/sigver.js#L4 et https://github.com/coast-team/sigver/blob/master/src/sigver.js#L130
  - Notification du problème @Philippe
*** Planned
**** DONE MUTE : Refactorer *DocService*
- Actuellement, une partie de la logique de *DocService* se trouve dans *NetworkService*
- La déplacer dans *DocService*
- En profiter pour nettoyer le code
**** DONE MUTE : Ajouter *EditorService*
- Actuellement, *EditorComponent* interagit avec *DocService* pour lui fournir les opérations locales
  - Il expose son stream à *DocService* qui s'y abonne
- Cependant, lorsque *EditorComponent* est détruit (lorsque l'utilisateur retourne sur la liste des documents), *DocService* écoute toujours le stream des opérations locales
- Déplacer le stream des opérations locales dans un service *EditorService*
- Modifier *EditorComponent* pour qu'il émette les opérations par le biais de *EditorService*
**** DONE MUTE : Nettoyer les streams
- Actuellement, les différents *Services* et *Components* communiquent par le biais de /streams/
- Cependant, ceux-ci ne sont pas nettoyés notamment à la destruction des *Components*
  - Ceci semble provoquer des erreurs lors de la détection des changements puisqu'on essaie de mettre à jour vues qui ont été détruites
  - Et il s'agit bien évidemment d'une fuite mémoire
- Se désabonner des streams à la destruction des *Components*
- Se désabonner des streams à la destructions des *Services*
**** DONE MUTE : Trouver l'origine du bug empêchant d'envoyer les opérations locales
- De temps en temps, l'éditeur plante après la génération de la 1ère opération locale
- Cependant aucune erreur n'est générée
- Ce bug semble lié à l'envoi de l'opération aux autres pairs
  - Mais ce bug se déclenche même lorsqu'on édite le document seul
- Trouver l'origine de ce bug
** Semaine du <2017-01-03 mar.> au <2017-01-06 ven.>
*** Done
- MUTE : Ajouter le stockage au sein du navigateur du document
  - Plusieurs librairies sont disponibles pour utiliser une base de données au sein du navigateur
    - [[https://pouchdb.com/][PouchDB]]
      - Semble porté par sa communauté
      - Celle-ci est importante (<2017-01-03 mar.>: 8022 stars, 236 contributeurs)
    - [[https://localforage.github.io/localForage/][localForage]]
      - Porté par *Mozilla*
      - Dispose d'une communauté importante (<2017-01-03 mar.>: 7103 stars)
    - [[http://jio.readthedocs.io/en/latest/][jIO]]
      - Porté par *Nexedi*
      - Dispose de connecteurs pour stocker les données sur un service distant
  - Ces librairies reposent principalement sur /IndexedDB/, mais possèdent un mécanisme de fallback sur /WebSQL/ ou même /LocalStorage/
  - Elles proposent toutes les 3 une syntaxe reposant sur les /Promises/ ou les /callbacks/
  - Pour le moment, utilise *jIO*
  - Ajout du service *StorageService*
    - Instancie une base de données
    - Dispose d'une méthode /put()/ pour enregistrer un objet
    - Dispose d'une méthode /get()/ pour récupérer un objet
  - Modification de *DocService*
    - Lorsque le document est mis à jour, utilise *StorageService* pour stocker cette version du document
    - Lorsqu'on crée une session de collaboration, initialise le document à partir de sa version stockée si possible
- TVPaint : Étudier la gestion des ressources dans BonitaSoft
  - Pour gérer les organisations, groupes, rôles et utilisateurs, il faut passer par *BPM Studio*
    - Organization > Manage
    - Un utilisateur appartient à un groupe ou plusieurs groupes d'une organisation et possède un rôle dans chacun de ces groupes
  - Attribuer les tâches (/actor mapping/)
    - Dans l'onglet *Actors* du workflow, on peut créer et supprimer les différents filtres utilisés pour faire du /actor mapping/
    - C'est ensuite dans *Configuration* que l'on peut ajouter un comportement aux filtres
      - Possibilité de filtrer par groupe, rôle ou appartenance
      - Possibilité de définir un ensemble d'utilisateurs spécifiques
- TVPaint : Étudier comment interagir avec BonitaSoft par API
  - S'authentifier
    - POST http://localhost:8728/bonita/loginservice
    - Paramètres:
      - /username/
      - /password/
      - /redirect/: un booléen indiquant si on souhaite être dirigé après l'exécution de la requête
	- /redirectURL/ si /redirect/ est égal à /true/
    - Exemple:
      - POST http://localhost:8728/bonita/loginservice?username=walter.bates&password=1234&redirect=true
    - Réponse:
      - Le cookie obtenu dans la réponse est l'élément important qui permettra d'authentifier les requêtes suivantes
  - Récupérer l'identifiant de l'utilisateur
    - GET http://localhost:8728/bonita/API/identity/user
    - Paramètres
      - /f/: le champ avec lequel on souhaite filtrer
    - Exemple:
      - GET http://localhost:8728/bonita/API/identity/user?f=userName=walter.bates
    - Réponse:
      #+BEGIN_SRC
[
  {
    "firstname": "Walter",
    "icon": "icons/default/icon_user.png",
    "creation_date": "2016-10-03 10:58:50.106",
    "userName": "walter.bates",
    "title": "Mr",
    "created_by_user_id": "-1",
    "enabled": "true",
    "lastname": "Bates",
    "last_connection": "2017-01-05 11:42:22.132",
    "password": "",
    "manager_id": "3",
    "id": "4",
    "job_title": "Human resources benefits",
    "last_update_date": "2016-10-03 10:58:50.106"
  }
]
      #+END_SRC
  - Récupérer les tâches disponibles ou assignées à l'utilisateur
    - GET http://localhost:8728/bonita/API/bpm/humanTask
    - Paramètres:
      - /f/: le champ avec lequel on souhaite filtrer
    - Exemple:
      - GET http://localhost:8728/bonita/API/bpm/humanTask?f=assigned_id=4
    - Réponse:
      #+BEGIN_SRC
[
  {
    "displayDescription": "",
    "executedBy": "0",
    "rootContainerId": "3002",
    "assigned_date": "2017-01-05 13:17:45.454",
    "displayName": "Create movie project",
    "executedBySubstitute": "0",
    "dueDate": "2017-01-05 12:25:15.246",
    "description": "",
    "type": "USER_TASK",
    "priority": "normal",
    "actorId": "315",
    "processId": "5578352443955206281",
    "caseId": "3002",
    "name": "Create movie project",
    "reached_state_date": "2017-01-05 11:25:15.251",
    "rootCaseId": "3002",
    "id": "60004",
    "state": "ready",
    "parentCaseId": "3002",
    "last_update_date": "2017-01-05 11:25:15.251",
    "assigned_id": "4"
  }
]
      #+END_SRC
    - Autre exemple:
      - GET http://localhost:8728/bonita/API/bpm/humanTask?state=waiting
    - Réponse:
      #+BEGIN_SRC
[
  {
    "displayDescription": "",
    "executedBy": "0",
    "rootContainerId": "3013",
    "assigned_date": "",
    "displayName": "Submit storyboard",
    "executedBySubstitute": "0",
    "dueDate": "2017-01-05 18:06:12.223",
    "description": "",
    "type": "USER_TASK",
    "priority": "normal",
    "actorId": "318",
    "processId": "5720704175050565481",
    "caseId": "3013",
    "name": "Submit storyboard",
    "reached_state_date": "2017-01-05 17:06:12.228",
    "rootCaseId": "3013",
    "id": "60038",
    "state": "ready",
    "parentCaseId": "3013",
    "last_update_date": "2017-01-05 17:06:12.228",
    "assigned_id": ""
  }
]
      #+END_SRC
  - Assigner une tâche
    - PUT http://localhost:8728/bonita/API/bpm/humanTask/:humanTaskID
    - Exemple:
      - PUT http://localhost:8728/bonita/API/bpm/humanTask/60038
        #+BEGIN_SRC
{
  "assigned_id":"4"
}
        #+END_SRC
    - Réponse:
      - Réponse vide, juste le status *200* témoigne du bon fonctionnement de la requête
  - Effectuer une tâche
    - POST http://localhost:8728/bonita/API/bpm/userTask/:userTaskID/execution
    - Paramètres:
      - Dans l'URL
	- /userTaskID/: l'identifiant de la tâche que l'on exécute
      - Dans le corps de la requête
	- Les éléments du formulaire si nécessaire
    - Exemple:
      - POST http://localhost:8728/bonita/API/bpm/userTask/60037/execution
        #+BEGIN_SRC
{
  "name":"Scott Pilgrim 2",
  "width":1920,
  "height":1080,
  "framerate":24
}
	#+END_SRC
    - Réponse:
      - Réponse vide, juste le status *204* témoigne du bon fonctionnement de la requête
- TVPaint : Définir le business process correspondant à la réalisation d'un film
  - Présentation du business process lors de la réunion du <2017-01-06 ven.>
  - Reste à développer la tâche /compositing/
- MUTE : Ajouter la gestion des documents stockées en local
  - Ajout d'un service *StorageManagerService*
    - Garde une liste des services de stockage
    - Expose une référence vers le service de stockage courant
  - Ajout d'une classe abstraite *AbstractStorageService*
    - S'enregistre auprès de *StorageManagerService*
    - Expose deux fonctions:
      - /isReachable(): Promise<boolean>/
      - /getDocuments(): Promise<any>/
  - Modification de *BotStorageService* pour hériter de *AbstractStorageService*
  - Ajout du component *StorageComponent*
    - Possède en paramètre un *AbstractStorageService*
    - Vérifie si le service de stockage est disponible
    - Permet d'accéder à la liste de ses documents si c'est le cas
    - Se désactive sinon
  - Modification de *NavComponent*
    - Récupère dorénavant la liste des services de stockage à l'aide de *StorageManagerService*
    - Instancie un *StorageComponent* pour chacun d'entre eux
  - Modification de *DocsComponent*
    - Récupère dorénavant la liste des documents à l'aide de *StorageManagerService*
    - Reste à voir comment uniformiser le comportement des différents services de stockage
      - Récupération du document
      - Sauvegarde
*** Planned
**** DONE MUTE : Ajouter le stockage au sein du navigateur du document
**** DONE TVPaint : Étudier la gestion des ressources dans BonitaSoft
- Voir pour générer des rôles
- Voir pour générer des acteurs
- Voir comment attribuer les tâches
**** DONE TVPaint : Étudier comment interagir avec BonitaSoft par API
- Voir comment spécifier le début et la fin d'une tâche par API
**** DONE TVPaint : Définir le business process correspondant à la réalisation d'un film
- Le process a été décrit sommairement dans l'image suivante
  #+CAPTION: Réalisation d'un film
  #+NAME:   fig:WorkflowExample2.png
  [[file:img/WorkflowExample2.png]]
- Le réaliser sous *Bonita Studio*
  - Réfléchir aux données nécessaires
  - Voir comment représenter la réalisation des shots et des clips
** Semaine du <2017-01-09 lun.> au <2017-01-13 ven.>
*** Done
- RH : Durée maximale de CDDs à Inria
  - J'ai vu avec le service RH concernant la durée maximale que je peux passer en CDD à Inria
  - Elle est de 5 ans et 11 mois
  - Par contre, les thèses sont sous un autre régime
  - Je peux donc effectuer une thèse auprès Inria après mon contrat
- MUTE : Ajouter la gestion des documents stockées en local
  - Renommage de *StorageService* en *LocalStorageService*
  - Modification de *StorageManagerService*
    - Injecte *LocalStorageService* et *BotStorageService* dans son constructeur
    - Les enregistre lui-même dans sa liste des services de stockage
    - Sinon, tant que ces services ne sont pas injectés par ailleurs, ils ne sont pas instanciés et enregistrés
  - Modification de *LocalStorageService*
    - Ajout de /getDocuments()/ pour renvoyer la liste des documents stockés en local
  - Modification de *NetworkService*
    - Ajout de la méthode /cleanWebChannel()/
      - Auparavant effectué au cours du /join()/
      - Séparation de ces 2 méthodes
  - Modification de *DocComponent*
    - On avait un problème lorsqu'on passait d'un document à l'autre
    - Les *Services* sont instanciés à leur 1ère utilisation et sont conservés jusqu'à la fin de la session
    - Cependant les *Components* eux sont détruits dès qu'ils ne sont plus affichés, et de nouveau instanciés lorsqu'on y accède de nouveau
    - Si on change d'URL mais qu'il s'agit toujours du même *Component*, on conserve l'instance courante
    - Ainsi, lorsqu'on passait d'un document à l'autre, il arrivait que les services n'arrivent plus à communiquer entre eux
      - Certains streams étaient coupés à la destruction de *DocComponent*
    - Ou qu'au contraire les services continuent d'envoyer des données correspondant à un autre document
      - Notamment lorsqu'on revenait à la page de gestion des documents
    - Destruction du *WebChannel* lors de la destruction de *DocComponent*
    - Destruction du *WebChannel* précédent et génération d'un nouveau lors du passage d'un document à un autre
*** Planned
**** DONE MUTE : Ajouter la gestion des documents stockées en local
- Ajouter une page listant les documents stockées en local
- Elle devrait permettre d'accéder à ces documents et de les supprimer
** Semaine du <2017-01-16 lun.> au <2017-01-20 ven.>
*** Done
- MUTE : Refactoring du couplage entre les services
  - Mapping des entrées/sorties des services dans le *Module* qui les fournit
- MUTE : Rendre générique l'utilisation des *StorageServices* par *DocService*
  - Puisque les services fonctionnent dorénavant par le biais d'entrées/sorties, cette tâche n'est plus pertinente
- MUTE : Ajouter le mécanisme de join propre
  - Ajout de *SyncService*
    - Ajoute à chaque opération émise un couple /id/ et /clock/
    - Maintient en parallèle un vecteur d'état indiquant pour chaque pair la /clock/ correspondant à sa plus récente opération reçue
    - Lorsqu'on rejoint un document, émet ce vecteur d'état à un pair
    - Celui-ci compare notre vecteur d'état avec le sien pour déterminer quelles sont les opérations que nous avons manquées
  - Ajout de *SyncMessageService*
    - Il s'agit du composant chargé de l'envoi et de la réception des messages de synchronisation
    - Observe les sorties de *SyncService*, les encode avec /Protobuf/ et utilise *NetworkService* pour les transmettre aux autres pairs
    - Observe *NetworkService* pour récupérer les messages lui étant destinés et instancie à partir de ces données les objets attendus par *SyncService*
  - Ajout de *SyncStorageService*
    - Il s'agit du composant chargé d'enregistrer l'état de *SyncService* pour le réutiliser à la prochaine session
    - Observe les sorties de *SyncService* pour récupérer son état et le stocker
    - Observe *NetworkService* pour détecter le document courant, récupérer l'état correspondant et le transmettre à *SyncService*
  - Ajout du mapping de ces services dans *DocModule*
*** Planned
**** DONE MUTE : Refactoring du couplage entre les services
- Actuellement, les services sont couplés
  - On injecte dans le constructeur d'un service des instances des autres services dont il dépend
- Ainsi, ajouter un nouveau composant telle que *SyncService* implique de modifier les services qui vont interagir avec lui
- Refactorer les services pour qu'ils exposent leurs entrées et sorties sous forme de streams
- Mapper les entrées/sorties des services dans un composant d'/orchestration/
**** DONE MUTE : Ajouter le mécanisme de join propre
**** CANCELLED MUTE : Rendre générique l'utilisation des *StorageServices* par *DocService*
- Actuellement, l'utilisation de *BotStorageService* et *LocalStorageService* est implémentée en dur dans le code de MUTE
- De même, leur comportement est différent
  - Le bot de stockage se comporte comme un utilisateur
  - Alors que *LocalStorageService* fonctionne par le biais d'appels à une API
- Uniformiser leur utilisation par *DocService*
** Semaine du <2017-01-23 lun.> au <2017-01-27 ven.>
*** Done
- MUTE : Ajouter la seconde partie du mécanisme de synchronisation
  - Ajout de *Interval* qui représente les opérations qu'il nous manque d'un pair
    - /id/ identifie le pair
    - /begin/ et /end/ délimitent l'interval des /clocks/ qu'il nous manque
  - Modification du message *REPLYSYNC* pour qu'il comporte aussi un tableau d'*Intervals*
  - Génération de ce tableau lors du traitement du message *QUERYSYNC* par *SyncService*
- MUTE : Refactorer la liste des documents
  - Besoin de mettre en place un service intermédiaire *DocsStorage*
  - Ce service devrait
    - Récupérer les listes de documents provenant des différents services de stockage
    - Fusionner les listes de documents pour ne conserver qu'une seule occurrence par document
*** Planned
**** DONE MUTE : Ajouter la seconde partie du mécanisme de synchronisation
- Actuellement, lorsqu'on se connecte, on envoie son vecteur d'état à un pair
- Celui-ci détecte les opérations qu'il possède mais qu'il nous manque à partir de ce vecteur et du sien
- Il nous envoie ces opérations
- Il peut aussi détecter les opérations que l'on possède mais qu'il lui manque à partir de ces mêmes informations
- Ajouter cette seconde passe
** Semaines du <2017-01-30 lun.> au <2017-02-17 ven.>
*** Done
- MUTE : Extraire la logique interne de MUTE dans une librairie /mute-core/
  - Librairie disponible ici: https://github.com/coast-team/mute-core
  - Comporte *CollaboratorsService*, *DocService*, *SyncService* et *SyncMessageService*
  - Ajout de l'interface *MessageEmitter* permettant de spécifier le protocole et d'exposer
    - Les messages à broadcaster
    - Les messages à envoyer à un pair particulier
    - Les messages à envoyer à un seul pair, mais choisi aléatoirement
- MUTE : Corriger le déclenchement du message /QuerySync/
  - Ajout d'un setter /setJoinAndStateSources(joinSource, stateSource?)/
    - S'agit de la fusion des setters /set joinSource/ et /set storedStateSource/
  - Le traitement des 2 sources étant lié, il est nécessaire de lier leur affectation
  - /stateSource/ est un paramètre optionnel
  - C'est sa présence ou non qui permet de définir le comportement à adopter
- MUTE : Refactorer *EditorComponent* pour gérer correctement les tableaux de *TextOperations*
  - La méthode /CodeMirror.Editor.operation(fn: () => void)/ est employée ici
  - Consiste à exécuter un appel de la méthode passée en paramètre
  - Elle permet de modifier le contenu de l'éditeur *CodeMirror* sans que celui-ci ne déclenche de rafraîchissements
  - Ceci permet donc d'effectuer un grand nombre d'opérations avant d'afficher uniquement l'état final
  - Amélioration des performances de l'application
    - Initialisation plus rapide (de quelques secondes à 1 seule) de l'éditeur lors de la synchronisation via un pair ou le système de stockage avec 100+ opérations
- MUTE : Ajouter la suppression d'un ou plusieurs documents depuis la liste des docs
  - Ajout de /delete (name: string): Promise<void>/ et /deleteAll (): Promise<void>/ à *AbstractStorageService*
  - Modification de *DocsComponent* pour utiliser ces fonctions
  - Utilisation de *MdSnackBar* pour afficher le message d'erreur si une se produit
    - Besoin de respecter un délai (~500ms) entre chaque message sous peine de faire planter l'UI
*** Planned
**** DONE MUTE : Extraire la logique interne de MUTE dans une librairie /mute-core/
- Actuellement, la logique de l'application se trouve directement dans *MUTE*
- Ceci pose des problèmes de duplication du code lorsqu'il s'agit d'écrire
  - un bot
  - une version /React/ de *MUTE*
- Extraire la logique interne et la déplacer dans une librairie /mute-core/ permettrait une meilleure réusabilité du code
**** DONE MUTE : Adapter /mute/ pour utiliser /mute-core/
- Une fois /mute-core/ implémentée, il est nécessaire de refactorer /mute/ pour
  - Supprimer les services obsolètes/dupliqués dans /mute-core/
  - Instancier *MuteCore* et effectuer le mapping de ses entrées/services avec les composants de /mute/
  - Gérer la destruction de l'instance de *MuteCore*
**** DONE MUTE : Refactorer *CursorsService* en *CursorsDirective*
- Un *Service* Angular ne devrait pas affecter l'interface graphique selon moi
- Cependant, *CursorsService* le fait
- L'utilisation d'un *Component* ou d'une *Directive* est plus indiquée dans ce cas de figure
- Ici, il s'agirait plutôt d'une *Directive*
  - On souhaite ajouter un comportement à un *Component* existant, l'éditeur
- Ceci permettra en plus
  - De passer des paramètres à la directive via les /@Input()/
  - De profiter des lifehooks proposés par Angular
**** DONE MUTE : Remplacer les couples *Observable/Observers* par des *Subjects*
- Jugeant que *AsyncSubject*, *BehaviorSubject* et *ReplaySubject* ne correspondaient pas à ce que je voulais faire, j'ai utilisé à la place des couples *Observable/Observers*
  - Génère et expose un *Observable*
  - Maintient la liste des *Observers* qui ont /subscribe()/ à l'*Observable*
- Ceci complexifie inutilement le code
  - Lors de la génération de l'*Observable*, on retrouve généralement le code suivant
    #+BEGIN_SRC
    this.observable = Observable.create((observer) => {
      // Ajout du nouvel observer à la liste des observers lors d'un subscribe()
      this.observers.push(observer)
    })
    #+END_SRC
  - Puis, lors de l'émission d'une nouvelle valeur
    #+BEGIN_SRC
    this.observers.forEach((observer) => {
      observer.next(valeur)
    })
    #+END_SRC
- Philippe vient de m'apprendre qu'il existe le type *Subject* qui implémente déjà ce comportement
- Utiliser *Subject* à la place de ces couples
**** DONE MUTE : Remplacer les /Observable.map()/ par des *Subscriptions* + *Subjects*
- Actuellement, certains *Observables* exposés par des composants de l'application sont générés en effectuant un mapping sur un flux en entrée
- Cependant ceci pose plusieurs problèmes
  - Le composant ne possède pas le moindre contrôle sur l'*Observable* généré par le mapping
    - Il se contente de transformer les valeurs qu'il reçoit et les retransmettre
    - Il ne peut donc pas émettre d'évènement /complete/ si besoin, notamment lors de sa destruction
  - Le flux de sortie n'est pas généré tant que le flux d'entrée n'a pas été passé au composant
    - Ainsi, essayer de s'abonner au flux de sortie avant d'avoir fourni le flux d'entrée génèrera une erreur
- Ce comportement me paraît donc /error-prone/
- Il serait préférable d'instancier en interne des *Subjects* et de les exposer sous forme d'*Observables*
- Le composant doit donc s'abonner aux flux d'entrées, effectuer les opérations de transformation et émettre les nouvelles valeurs via les *Subjects*
**** DONE MUTE : Corriger le déclenchement du message /QuerySync/
- La condition de déclenchement du message /QuerySync/ est un peu particulière
  #+BEGIN_SRC
  if storageService
    wait(JoinEvent, IsReadyEvent) // où IsReadyEvent indique quand on a fini d'initialiser le document à partir de la version stockée dans le système de stockage
  else
     wait(JoinEvent)
  #+END_SRC
- Actuellement, le code gérant ce déclenchement est brouillon
- Améliorer ça
**** DONE MUTE : Coder en dur le nom des services lorsqu'ils émettent des messages
- Un message est composé de contenu mais aussi d'un champ /service/
- Ce champ permet aux services, lorsqu'ils reçoivent un message, de filtrer uniquement les messages les concernant
- Actuellement, lorsqu'un service émet un message, il renseigne ce champ en utilisant /this.constructor.name/ afin que ce nom soit unique
- Cependant, lorsqu'on build l'application pour le mode production, une minification du code est effectuée
- Et il semblerait que suite à cette minification, plusieurs services se retrouvent avec un constructeur de même nom
- Les services essaient donc de parser et de traiter des messages qui ne leurs sont pas destinés
- Remplacer les /this.constructor.name/ par des constantes
**** DONE MUTE : Refactorer /mute-core/ pour pouvoir traiter des tableaux de *LogootSOperations*
- Comme on émet les *LogootSOperations* une par une, /mute-core/ est designé pour les recevoir une par une
- Ainsi, lorsqu'une *RichLogootSOperation* est reçue
  - Elle est transformée en *LogootSoperation* par *SyncService*
  - Elle est appliquée au modèle par *DocService*
  - Puis *DocService* émet la *TextOperation* correspondante
- Cependant, nous pouvons recevoir plusieurs *RichLogootSOperations* d'un coup maintenant
  - Lors de l'initialisation en utilisant le système de stockage
  - Lors de la synchronisation avec un autre pair
- Nous envoyons donc une multitude de messages inutilement
- Ces messages peuvent eux-mêmes déclencher des rafraichissements de l'interface
**** DONE MUTE : Refactorer *EditorComponent* pour gérer correctement les tableaux de *TextOperations*
- Maintenant que *DocService* émet plusieurs *TextOperations* en un seul message, il est nécessaire d'adapter *EditorComponent*
- Améliorer les performances de l'application en désactivant le rafraichissement de *CodeMirror* dès que son contenu est modifié
  - Rafraichir *CodeMirror* qu'une fois qu'on a fini d'appliquer l'ensemble des *TextOperations*
**** DONE MUTE : Ajouter la suppression d'un ou plusieurs documents depuis la liste des docs
- Maintenant que nous proposons une liste des documents, il est nécessaire de pouvoir la gérer
- Il faut donc pouvoir supprimer un ou plusieurs documents
** Semaine du <2017-02-20 lun.> au <2017-02-24 ven.>
*** Done
- CRDT : Lire *CRDT notes*
  - Pessimistic Replication
    - Système de lock
    - Lorsqu'un client essaie d'accéder ou de modifier la donnée repliquée, un système de synchronisation empêche les réplicas de diverger
    - Semble lourd (quid de la disponibilité ?) mais semble utilisable dans certains cas
      #+BEGIN_QUOTE
      But, in local area networks, it can be acceptable because the latency to contact another replica is low.
      #+END_QUOTE
  - Active Replication
    - Lorsqu'un client essaie de modifier la donnée répliquée, l'ensemble des replicas est modifié au cours de la transaction
      - Ne peut pas avoir une divergence des replicas
*** Planned
** Semaine du <2017-02-27 lun.> au <2017-03-03 ven.>
*** Done
- TVPaint
  - Récupérer la liste des process
    - GET http://localhost:8728/bonita/API/bpm/process?s
    - Paramètres
      - /s/: le champ avec lequel on souhaite filtrer
    - Exemple:
      - GET http://localhost:8728/bonita/API/bpm/process?s=Demo Movie Management
    - Réponse:
      #+BEGIN_SRC
[
  {
    "displayDescription": "",
    "deploymentDate": "2017-02-27 16:55:39.076",
    "displayName": "Demo Movie Management",
    "name": "Demo Movie Management",
    "description": "",
    "deployedBy": "4",
    "id": "5736144163858952046",
    "activationState": "ENABLED",
    "version": "1.0",
    "configurationState": "RESOLVED",
    "last_update_date": "2017-02-27 16:55:39.208",
    "actorinitiatorid": "502"
  },
  {
    "displayDescription": "",
    "deploymentDate": "2017-02-20 15:37:44.819",
    "displayName": "Movie Management",
    "name": "Movie Management",
    "description": "",
    "deployedBy": "4",
    "id": "9107737410621326053",
    "activationState": "ENABLED",
    "version": "1.0",
    "configurationState": "RESOLVED",
    "last_update_date": "2017-02-20 15:37:45.103",
    "actorinitiatorid": "401"
  }
]
      #+END_SRC
  - Récupérer le contrat d'instantiation d'un process
    - GET http://localhost:8728/bonita/API/bpm/process/:processId/contract
    - Exemple:
      - GET http://localhost:8728/bonita/API/bpm/process/5736144163858952046/contract
    - Réponse:
      #+BEGIN_SRC
{
  "inputs": [],
  "constraints": []
}
      #+END_SRC
  - Instancier un process
    - POST http://localhost:8728/bonita/API/bpm/process/:processId/instantiation
    - Exemple:
      - POST http://localhost:8728/bonita/API/bpm/process/5736144163858952046/instantiation
    - Réponse:
      #+BEGIN_SRC
{
  "caseId": 5004
}
      #+END_SRC
- MUTE : Modifier *MuteCore* pour qu'il n'attende plus un *JoinEvent* pour démarrer
  - Ajout de /initSubject/ dans *MuteCore* et de la méthode /init(key: string)/ pour signaler que le modèle est initialisé
  - Modification de *DocService* pour dépendre de *InitEvent* et non plus *JoinEvent*
  - Modification de *SyncService* pour récupérer l'id de l'utilisateur lors de la construction de l'objet
  - Modification de *NetworkService* pour déclencher le join après l'initialisation
  - Modification de *StorageService* pour récupérer l'état après l'initialisation
  - Modification de *DocComponent*
    - Génération de l'id de l'utilisateur
      - On ne dispose à ce moment d'aucune information sur les autres pairs
      - Il faut donc générer un identifiant (*int32*) et espérer qu'il soit unique
      - /Math.random()/ permet de le faire
      - Mais utiliser un générateur de nombres aléatoires à sécurité cryptographique permet de s'assurer un comportement plus aléatoire
      - [[https://developer.mozilla.org/en-US/docs/Web/API/RandomSource/getRandomValues][getRandomValues()]] permet de faire ça dans le browser
*** Planned
**** DONE MUTE : Modifier *MuteCore* pour qu'il n'attende plus un *JoinEvent* pour démarrer
- Actuellement, *JoinEvent* est l'évènement initial qui permet au modèle
  - De s'instancier
  - De récupérer l'état stocké en local
  - De se synchroniser avec un pair
- Cet évènement est seulement déclenché lorsqu'on rejoint le réseau
- Si un problème empêche l'utilisateur de rejoindre le réseau, alors l'éditeur est inutilisable
- Alors que rien n'empêche de travailler en mode déconnecté pour le moment et de tenter de se reconnecter plus tard
- Modifier la logique interne de *MuteCore* pour
  - Ajouter un *InitEvent* indiquant au modèle
    - De s'instancier
    - De récupérer l'état stocké en local
  - *JoinEvent* ne permettra que de déclencher une synchronisation
** Semaine du <2017-03-06 lun.> au <2017-03-10 ven.>
*** Done
- MUTE : Refactorer la liste des documents
  - Philippe s'en est chargé
- MUTE : Ajouter la gestion du titre du document
  - Un simple *LWW-Register* suffit
  - La seule difficulté concerne la génération du timestamp utilisé pour ordonner les titres
  - Une horloge de Lamport ne semble pas suffire
    - Permet d'assurer que pour des opérations /a/ et /b/ et une fonction /C(x)/ retournant le timestamp d'une opération /x/, alors /a -> b => C(a) < C(b)/
    - Mais ne permet pas de s'assurer que /C(a) < C(b) => a -> b/
    - En effet /C(a) < C(b)/ peut aussi indiquer que les opérations sont en concurrence
  - Besoin d'ajouter un élément pour créer un ordre total
    - Dans le cas d'une égalité entre les horloges, l'identifiant de l'utilisateur peut être utilisé pour ordonner les timestamps
    - Exemple pour deux timestamps /<ts, id>/ et /<ts', id'>/ :
      #+BEGIN_SRC
      if (ts > ts') return <ts, id>
      if (ts' > ts) return <ts', id'>
      if (id > id') return <ts, id>
      return <ts', id'>
      #+END_SRC
- Thèse : Discussion avec Claudia
  - Discussion autour du sujet de thèse
  - Continuer les travaux autour du modèle de confiance
  - Amélioration de l'expérience basée sur le trust game
    - Ajout d'un mécanisme de réputation
      - La confiance est
      - La réputation, elle, est établie sur un groupe d'utilisateurs
    - Comparaison du comportement des utilisateurs par rapport à la confiance et/ou à la réputation
  - Application du modèle de confiance à l'édition collaborative
    - Evaluation de la qualité des contributions d'un utilisateur
    - Déterminer les compromis d'une collaboration
    - Prédiction des actions d'un utilisateur en fonction
    - Gestion des droits d'accès par rapport au score de confiance
- Thèse : Discussion avec Gérald
  - Problème de renaming pas adapté à l'équipe
    - Pas exactement le domaine de compétence et le type de problème habituellement traité
  - Idée d'interactions entre un système externe et un CRDT
    - Un document et son modèle CRDT correspondant pourraient être stockés dans git
    - Un utilisateur, avec une application externe, pourrait vouloir modifier le document
    - Comment détecter les changements et mettre à jour son modèle CRDT
    - Comment transmettre ces modifications à l'éditeur
  - Faire le lien avec les cahiers scientifiques
    - De plus en plus de cahiers scientifiques sont rédigés pour des raisons de reproductibilité
      - Plusieurs formats: IPython, ORG-mode
    - Pourraient être rédigés de façon collaborative
    - Embarque des morceaux de code à exécuter
    - Où exécuter les tâches ?
      - Peut vouloir déléguer l'exécution des tâches si elles sont lourdes
      - Retrouve la notion de bot ?
    - Besoin de répliquer les données de l'expérience si délégation de l'exécution
- MUTE : Débugger la liste des documents
  - [ ] Réinitialiser *NavComponent* lors de son affichage
    - Dans ce cas, sélectionner un dossier déclencherait une mise à jour de /activeFile/
  - [ ] Distinguer /activeDoc/ et /activeFolder/
    - *DocsComponent* a besoin de connaitre /activeFolder/ à son initialisation pour générer la liste des documents
    - *NavComponent* permet de mettre à jour /activeFolder/ lorsqu'un changement du dossier sélectionné est détecté
    - *DocComponent* peut mettre à jour /activeDoc/ à son initialisation et à sa destruction
    - *ToolbarComponent* a besoin de connaitre /activeFolder/ et /activeDoc/
      - Si /activeDoc/ est défini, alors affiche ses infos
      - Sinon, affiche les infos de /activeFolder/
      - Peut facilement être implémenté avec /combineLatest/ de *RxJS*
        #+BEGIN_SRC
        activeFolderSource
         .combineLatest(activeDocSource)
         .map(([folder: Folder, doc: Doc]) => {
           if (doc) {
             return doc
           }
           return folder
         })
         .subscribe((file: File) => {
           // Do something
         })
        #+END_SRC
- PIDR : Réflexion avec Quentin et Gérald
  - Lien entre l'automate qu'on souhaite obtenir et le fonctionnement interne d'une chaîne de Markov par exemple
  - La question était "Pourquoi ne pas effectuer les actions du bot directement plutôt que de générer un fichier ?"
    - Reproductibilité de l'expérience
    - Permet de découpler le modèle d'apprentissage et l'implémentation du comportement
    - Comme le fichier suit le formalisme d'une grammaire, peut facilement utiliser un parser pour implémenter le comportement
- PIDR : Réflexion avec Vinh et Le
  - Le résultat de l'analyseur de traces doit être une machine à états ou sa représentation
    - Sinon, de quoi pourrait-il s'agir ?
      - Une séquence d'actions ?
	- Dans ce cas, on aurait un ou plusieurs comportements fixés pour un groupe d'utilisateurs donné
	- Est-ce représentatif ?
	- Mais au moins, ça serait reproductible
  - Une chaîne de Markov a pour but de prédire la prochaine action en fonction de l'état actuel
    - L'état actuel doit contenir toutes les informations nécessaires pour faire le choix
  - Une chaîne de Markov ne correspondrait donc pas si ce que l'on cherche à obtenir est un automate
  - Conseillent de regarder plutôt du côté du /process mining/
    - Vinh recommande [[http://www.processmining.org/prom/start][Prom]]
    - Permettrait d'extraire une machine à états pondérée à partir de séquences d'actions
- MUTE : Débugger l'ouverture d'un nouveau document
  - Bug dû à l'enchainement des évènements
  - Actuellement, lorsque *EditorComponent* détecte un changement de l'instance *DocService*, il s'abonne à /onDocValue/ pour récupérer la nouvelle valeur
  - Lorsqu'une nouvelle valeur du document lui est fourni, il met à jour le contenu du document
  - Mais depuis la refonte pour utiliser /onInit/, /onDocValue/ est déclenché avant que *EditorComponent* se soit abonné
  - Attendre que *EditorComponent* soit initialisé pour appeler /muteCore.init()/ dans *DocComponent*
*** Planned
**** CANCELLED MUTE : Refactorer la liste des documents
- Actuellement, on affiche la liste de tous les objets contenus dans la BDD pour former la liste des documents
- Sauf que certains objets ne devraient pas en faire partie
  - Les données conservées pour chaque document pour *SyncService* par exemple
- De plus, on différencie les documents en fonction des systèmes de stockage où ils sont conservées
- Cela peut s'avérer perturbant pour les utilisateurs
- Unifier la liste des documents
**** DONE MUTE : Débugger la gestion des documents
- Depuis la mise à jour de la liste des documents, la sauvegarde en locale des documents n'est plus disponible
- On enregistre les meta-données du document
  - Titre
  - Clé
  - Stockages utilisés
- Mais plus son contenu
- Débugger ça
** Semaine du <2017-03-13 lun.> au <2017-03-17 ven.>
*** Done
- MUTE : Débugger l'ouverture d'un nouveau document
  - Ajout de l'évènement /isReady/ dans *EditorComponent*
    - Déclenché initialement lors de /ngOnInit()/
    - Puis ensuite à chaque /ngOnChanges()/
  - Modification de *DocComponent* pour qu'il attende cet évènement pour déclencher /muteCore.init()/
- MUTE : Affichage du digest du document
  - Modification de *DocService*
    - Ajout du stream /onDocDigest/
    - Permet d'émettre la valeur du digest
    - Le digest est généré une fois dans l'état /idle/ depuis 1s
      - Permet d'éviter de le calculer à chaque modification locale ou distante
  - Modification de *DocComponent*
    - S'abonne au stream /onDocDigest/
    - Transmet les différentes valeurs à *UiService*
  - Modification de *DevLabelComponent*
    - Récupère le digest par le biais de *UiService*
    - Affiche le digest
- TVPaint : Implémenter le prototype orchestrant TVPaint server et Bonita
  - Erreur lors du lancement du programme
    - =error while loading shared libraries: libPocoFoundation=
  - POCO s'avère être un ensemble de librairies pour développer des applications web en C++
    - https://github.com/pocoproject/poco
  - Installation de POCO
    #+BEGIN_SRC
    ./configure
    make -s
    sudo make install
    #+END_SRC
  - Mise à jour de /ldconfig/
    - =sudo ldconfig=
  - Le serveur démarre dorénavant
    - Si exécuté en tant qu'utilisateur: /Instruction non permise/
    - Si exécuté en tant que root: rend la main mais ne semble pas démarré
  - Jordan a réussi à débugger le serveur
    - Le problème semblait provenir de librairies qui étaient incluses dans le build mais non nécessaires
  - Initialisation du serveur
    - Ne pas cliquer sur le 1er bouton !
    - Besoin de générer la BDD au 1er lancement
      - Create New Database -> Warp Factor 2.5
      - Sélectionner un dossier vide qui va contenir la BDD
      - Crash de l'appli normal
    - 2nd lancement
      - Sélectionner la base de données précédemment créée dans la liste de droite
  - Serveur dorénavant disponible à [[http://localhost:9980]]
  - API de TVPaint Server
    - Colorspaces
      - Récupérer la liste des colorspaces
        #+BEGIN_SRC
$ curl http://localhost:9980/colorspace
<html>
<head>
<title>Colorspace list</title>
</head>
<body>
<ul>
    <li><a href="/colorspace/8199c8bd-35d8-44d8-8992-1c5a6d091817">8199c8bd-35d8-44d8-8992-1c5a6d091817</a></li>
    <li><a href="/colorspace/7920bf82-9054-47a9-b248-f1f4de67e619">7920bf82-9054-47a9-b248-f1f4de67e619</a></li>
    <li><a href="/colorspace/cf95b451-abae-4194-8cb2-30fee386d4d9">cf95b451-abae-4194-8cb2-30fee386d4d9</a></li>
    <li><a href="/colorspace/70201f7f-c4aa-40df-99f7-0da45ddd6bbd">70201f7f-c4aa-40df-99f7-0da45ddd6bbd</a></li>
    <li><a href="/colorspace/35b6b6a6-533f-4b0f-92da-cd142d057ae4">35b6b6a6-533f-4b0f-92da-cd142d057ae4</a></li>
    <li><a href="/colorspace/7a8357db-595c-4379-80c7-ae4f0d17c474">7a8357db-595c-4379-80c7-ae4f0d17c474</a></li>
    <li><a href="/colorspace/56546542-3c5c-482b-9e2d-0bd7d674ccb2">56546542-3c5c-482b-9e2d-0bd7d674ccb2</a></li>
    <li><a href="/colorspace/7a832038-9c47-481d-8fc5-0cba01875471">7a832038-9c47-481d-8fc5-0cba01875471</a></li>
    <li><a href="/colorspace/7335efb6-a311-458a-8e6e-adbe6bc35dc2">7335efb6-a311-458a-8e6e-adbe6bc35dc2</a></li>
    <li><a href="/colorspace/426a891a-ed0b-4c06-8614-0aa893ca8d33">426a891a-ed0b-4c06-8614-0aa893ca8d33</a></li>
    <li><a href="/colorspace/87089522-ff78-4e99-81b1-24240595592a">87089522-ff78-4e99-81b1-24240595592a</a></li>
    <li><a href="/colorspace/3790cd83-9e7b-4e8b-9356-6b6e78bb1ca7">3790cd83-9e7b-4e8b-9356-6b6e78bb1ca7</a></li>
    <li><a href="/colorspace/652e0344-33f3-4f20-ac43-dcfb2493e623">652e0344-33f3-4f20-ac43-dcfb2493e623</a></li>
    <li><a href="/colorspace/51658695-398b-44cf-9591-b35ab304d1b7">51658695-398b-44cf-9591-b35ab304d1b7</a></li>
    <li><a href="/colorspace/32c28afa-f8e7-441b-81ec-2599cf5091ce">32c28afa-f8e7-441b-81ec-2599cf5091ce</a></li>
    <li><a href="/colorspace/809f1634-1a8f-45bd-87bf-8aec9c67a621">809f1634-1a8f-45bd-87bf-8aec9c67a621</a></li>
    <li><a href="/colorspace/040b7ff1-1975-4e03-93c9-0a15671cfe41">040b7ff1-1975-4e03-93c9-0a15671cfe41</a></li>
    <li><a href="/colorspace/4d1ac0d3-5943-457d-901d-95322a8d39c7">4d1ac0d3-5943-457d-901d-95322a8d39c7</a></li>
    <li><a href="/colorspace/a2b11f5c-0144-4691-a92a-529a594e929f">a2b11f5c-0144-4691-a92a-529a594e929f</a></li>
</ul>
</body>
</html>
        #+END_SRC
    - Clips
      - Récupérer la liste des clips
        #+BEGIN_SRC
$ curl http://localhost:9980/clip
<html>
<head>
<title>Clip list</title>
</head>
<body>
<ul>
    <li><a href="/clip/c8635487-54a0-4cc3-ba6a-774a4c3f2628">c8635487-54a0-4cc3-ba6a-774a4c3f2628</a></li>
</ul>
</body>
</html>
        #+END_SRC
      - Récupérer un clip
	#+BEGIN_SRC
$ curl http://localhost:9980/clip/c8635487-54a0-4cc3-ba6a-774a4c3f2628
<object class="::nClip::cClip" instanceauid="c8635487-54a0-4cc3-ba6a-774a4c3f2628">
    <state>
        <data2state>
            <object class="::nData2::nStructure::cStructPersistentState">
                <state mName="data2state" mValue="void" />
                <children>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentname">
                            <mValue format="string-utf8">clip1</mValue>
                        </state>
                    </object>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentcopyright">
                            <mValue format="string-utf8">@copyleft</mValue>
                        </state>
                    </object>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentcomment">
                            <mValue format="string-utf8">@So cute :)</mValue>
                        </state>
                    </object>
                    <object class="::nData2::nValue::cInteger">
                        <state mName="width" mValue="100" mStep="1" />
                    </object>
                    <object class="::nData2::nValue::cInteger">
                        <state mName="height" mValue="200" mStep="1" />
                    </object>
                    <object class="::nData2::nValue::cDouble">
                        <state mName="framerate" mValue="24" mStep="1" />
                    </object>
                    <object class="::nData2::nValue::cInteger">
                        <state mName="currentframe" mValue="0" mStep="1" />
                    </object>
                    <object class="::nDocument::nData2::nValue::cFavorites">
                        <state mName="favorites">
                            <mValue>
                                <mRoot>
                                    <mName format="string-utf8">Root</mName>
                                    <mContent />
                                </mRoot>
                            </mValue>
                        </state>
                    </object>
                </children>
            </object>
        </data2state>
        <userdata>
            <object class="::nData2::{Data2.UserData.cpp}::cUserDataStructPersistentState">
                <state mName="userdata" mValue="void" />
                <children>
                    <object class="::nData2::nStructure::cStruct">
                        <state mName="timeline" mValue="void" />
                        <children>
                            <object class="::nData2::nValue::cDouble">
                                <state mName="framestart" mValue="0" mStep="1" />
                            </object>
                            <object class="::nData2::nValue::cDouble">
                                <state mName="framesize" mValue="20" mStep="1" />
                            </object>
                            <object class="::nData2::nValue::cInteger">
                                <state mName="newlayerindex" mValue="0" mStep="1" />
                            </object>
                        </children>
                    </object>
                </children>
            </object>
        </userdata>
    </state>
    <relations>
        <UsedInShots kind="unordered">
            <target object="ea7a9721-4291-4043-b589-37e0932a806b" />
        </UsedInShots>
        <RootLayer kind="1">
            <target object="dd7abe7c-5a02-4ed0-aca2-ea41fd779445" />
        </RootLayer>
        <Colorspace kind="1">
            <target object="8199c8bd-35d8-44d8-8992-1c5a6d091817" />
        </Colorspace>
        <StoredIn kind="unordered">
            <target object="aac82be6-d624-46c0-98a8-ec3209f87c4d" />
        </StoredIn>
        <Content kind="unordered" />
    </relations>
</object>
        #+END_SRC
      - Créer un clip
        #+BEGIN_SRC
$ curl -X POST -d name=clip1 -d width=100 -d height=200 -d framerate=24 -d colorspace=8199c8bd-35d8-44d8-8992-1c5a6d091817 http://localhost:9980/clip
<newobject class="::nClip::cClip" instanceauid="1b00f271-1754-4d71-8f2f-24e49a568fb0" />
        #+END_SRC
      - Associer un clip à un shot
        #+BEGIN_SRC
$ curl -X PUT http://localhost:9980/shot/ea7a9721-4291-4043-b589-37e0932a806b/append/c8635487-54a0-4cc3-ba6a-774a4c3f2628
<html>
<head>
<title>OK</title>
</head>
<body>
LINK ESTABLISHED</body>
</html>
        #+END_SRC
    - Shots
      - Récupérer la liste des shots
        #+BEGIN_SRC
$ curl http://localhost:9980/shot
<html>
<head>
<title>Shot list</title>
</head>
<body>
<ul>
    <li><a href="/shot/ea7a9721-4291-4043-b589-37e0932a806b">ea7a9721-4291-4043-b589-37e0932a806b</a></li>
    <li><a href="/shot/bde3202e-5dcf-4e5d-9a2c-b014abfc76b8">bde3202e-5dcf-4e5d-9a2c-b014abfc76b8</a></li>
    <li><a href="/shot/3c773691-f34c-4950-94a1-bc8b4e4a66c3">3c773691-f34c-4950-94a1-bc8b4e4a66c3</a></li>
</ul>
</body>
</html>
        #+END_SRC
      - Récupérer un shot
        #+BEGIN_SRC
$ curl http://localhost:9980/shot/ea7a9721-4291-4043-b589-37e0932a806b
<object class="::nFilm::cShot" instanceauid="ea7a9721-4291-4043-b589-37e0932a806b">
    <state>
        <data2state>
            <object class="::nData2::nStructure::cStructPersistentState">
                <state mName="data2state" mValue="void" />
                <children>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentname">
                            <mValue format="string-utf8">shot1</mValue>
                        </state>
                    </object>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentcopyright">
                            <mValue format="string-utf8">@copyleft</mValue>
                        </state>
                    </object>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentcomment">
                            <mValue format="string-utf8">@So cute :)</mValue>
                        </state>
                    </object>
                    <object class="::nData2::nValue::cDoubleBounded">
                        <state mName="opacity" mValue="1" mStep="1" mMinValue="0" mMaxValue="1" />
                    </object>
                    <object class="::nData2::nValue::cEnum">
                        <state mName="backgroundmode" mValue="::nClip::eBackground::kNone" />
                    </object>
                    <object class="::nData2::nValue::cColor">
                        <state mName="backgroundcolor" mValue="[0.964203,1.000000,0.824890,1.000000]" />
                    </object>
                    <object class="::nData2::nValue::cColor">
                        <state mName="backgroundcolor1" mValue="[0.436035,0.222473,0.013916,1.000000]" />
                    </object>
                    <object class="::nData2::nValue::cColor">
                        <state mName="backgroundcolor2" mValue="[0.385101,0.716919,0.097076,1.000000]" />
                    </object>
                    <object class="::nDocument::nData2::nValue::cFavorites">
                        <state mName="favorites">
                            <mValue>
                                <mRoot>
                                    <mName format="string-utf8">Root</mName>
                                    <mContent />
                                </mRoot>
                            </mValue>
                        </state>
                    </object>
                </children>
            </object>
        </data2state>
        <userdata>
            <object class="::nData2::{Data2.UserData.cpp}::cUserDataStructPersistentState">
                <state mName="userdata" mValue="void" />
                <children>
                    <object class="::nData2::nStructure::cStruct">
                        <state mName="timeline" mValue="void" />
                        <children>
                            <object class="::nData2::nValue::cDouble">
                                <state mName="framestart" mValue="0" mStep="1" />
                            </object>
                            <object class="::nData2::nValue::cDouble">
                                <state mName="framesize" mValue="20" mStep="1" />
                            </object>
                            <object class="::nData2::nValue::cInteger">
                                <state mName="currentframe" mValue="0" mStep="1" />
                            </object>
                        </children>
                    </object>
                </children>
            </object>
        </userdata>
    </state>
    <relations>
        <Clips kind="ordered">
            <target object="c8635487-54a0-4cc3-ba6a-774a4c3f2628">
                <properties>
                    <property name="plane" object="5f57bd5e-b57a-4f87-96f9-de2e48edb0f9" />
                </properties>
            </target>
        </Clips>
        <Parents kind="unordered">
            <target object="3fac5b0e-fcd6-4432-837d-b1252dd8285b" />
            <target object="3fac5b0e-fcd6-4432-837d-b1252dd8285b" />
        </Parents>
        <StoredIn kind="unordered">
            <target object="b6ff362e-7001-4328-8079-4e82fa698501" />
        </StoredIn>
        <Content kind="unordered" />
    </relations>
</object>
	#+END_SRC
      - Créer un shot
        #+BEGIN_SRC
$ curl -X POST -d name=shot1 http://localhost:9980/shot
<newobject class="::nFilm::cShot" instanceauid="0d52f072-f6bb-4271-9cd0-669e4ad7ec36" />
        #+END_SRC
      - Associer un shot à un film
        #+BEGIN_SRC
$ curl -X PUT http://localhost:9980/film/9491a3d8-1e2e-4b54-a6d7-806de9c2d767/append/ea7a9721-4291-4043-b589-37e0932a806b
<html>
<head>
<title>OK</title>
</head>
<body>
LINK ESTABLISHED</body>
</html>
        #+END_SRC
    - Films
      - Récupérer la liste des films
	#+BEGIN_SRC
$ curl http://localhost:9980/film
<html>
<head>
<title>Film list</title>
</head>
<body>
<ul>
    <li><a href="/film/9491a3d8-1e2e-4b54-a6d7-806de9c2d767">9491a3d8-1e2e-4b54-a6d7-806de9c2d767</a></li>
    <li><a href="/film/997a7a0e-b6de-44a7-9c5d-ebe45903bab1">997a7a0e-b6de-44a7-9c5d-ebe45903bab1</a></li>
</ul>
</body>
</html>
        #+END_SRC
      - Récupérer un film
        #+BEGIN_SRC
$ curl http://localhost:9980/film/9491a3d8-1e2e-4b54-a6d7-806de9c2d767
<object class="::nFilm::cFilm" instanceauid="9491a3d8-1e2e-4b54-a6d7-806de9c2d767">
    <state>
        <data2state>
            <object class="::nData2::nStructure::cStructPersistentState">
                <state mName="data2state" mValue="void" />
                <children>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentname">
                            <mValue format="string-utf8">tagada</mValue>
                        </state>
                    </object>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentcopyright">
                            <mValue format="string-utf8">@copyleft</mValue>
                        </state>
                    </object>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentcomment">
                            <mValue format="string-utf8">@So cute :)</mValue>
                        </state>
                    </object>
                </children>
            </object>
        </data2state>
        <userdata>
            <object class="::nData2::{Data2.UserData.cpp}::cUserDataStructPersistentState">
                <state mName="userdata" mValue="void" />
                <children>
                    <object class="::nData2::nStructure::cStruct">
                        <state mName="timeline" mValue="void" />
                        <children>
                            <object class="::nData2::nValue::cDouble">
                                <state mName="zoom" mValue="1" mStep="1" />
                            </object>
                            <object class="::nData2::nValue::cInteger">
                                <state mName="newshotindex" mValue="0" mStep="1" />
                            </object>
                        </children>
                    </object>
                </children>
            </object>
        </userdata>
    </state>
    <relations>
        <RootScene kind="1">
            <target object="3fac5b0e-fcd6-4432-837d-b1252dd8285b" />
        </RootScene>
        <CameraSettings kind="1">
            <target object="1ee1f8e0-0dca-4d2e-9208-8c579e59150a" />
        </CameraSettings>
        <StoredIn kind="unordered">
            <target object="0f76db8d-1ca3-4e05-8ede-a84d7e6cc74b" />
        </StoredIn>
        <Content kind="unordered" />
    </relations>
</object>
        #+END_SRC
      - Créer un film
        #+BEGIN_SRC
$ curl -X POST -d name=tagada http://localhost:9980/film
<newobject class="::nFilm::cFilm" instanceauid="997a7a0e-b6de-44a7-9c5d-ebe45903bab1" />
        #+END_SRC
  - Problème pour récupérer le lien entre le film et ses shots
    - Actuellement, un film comporte une *RootScene*
    - C'est en récupérant les informations de la *RootScene* que nous sommes capables de retrouver les shots du film
      #+BEGIN_SRC
$ curl http://localhost:9980/object/3fac5b0e-fcd6-4432-837d-b1252dd8285b
<object class="::nFilm::cRootScene" instanceauid="3fac5b0e-fcd6-4432-837d-b1252dd8285b">
    <state>
        <data2state>
            <object class="::nData2::nStructure::cStructPersistentState">
                <state mName="data2state" mValue="void" />
                <children>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentname">
                            <mValue format="string-utf8">@Untitled-07</mValue>
                        </state>
                    </object>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentcopyright">
                            <mValue format="string-utf8">@copyleft</mValue>
                        </state>
                    </object>
                    <object class="::nData2::nValue::cWString">
                        <state mName="documentcomment">
                            <mValue format="string-utf8">@So cute :)</mValue>
                        </state>
                    </object>
                </children>
            </object>
        </data2state>
    </state>
    <relations>
        <Film kind="1">
            <target object="9491a3d8-1e2e-4b54-a6d7-806de9c2d767" />
        </Film>
        <Children kind="ordered">
            <target object="ea7a9721-4291-4043-b589-37e0932a806b" />
            <target object="ea7a9721-4291-4043-b589-37e0932a806b" />
            <target object="ea7a9721-4291-4043-b589-37e0932a806b" />
        </Children>
        <Parents kind="unordered" />
        <StoredIn kind="unordered" />
        <Content kind="unordered" />
    </relations>
</object>
      #+END_SRC
    - Mais cette URL est censée être temporaire
    - Comment récupérer la liste des shots d'un film à terme ?
      - Semblerait que les shots conservent une référence vers la *RootScene*
      - Utiliser ce lien ?
  - En fait, on peut s'en sortir sans avoir besoin d'accéder directement à la *RootScene*
    - Il suffit de vérifier que la *RootScene* référencée dans *Film* est bien aussi référencée par les *Shots*
  - Parser du XML en JS
    - Une librairie semble se démarquer: [[https://github.com/Leonidas-from-XIV/node-xml2js]]
    - Exemple d'utilisation
      #+BEGIN_SRC
this.cookieRequest.get("http://localhost:9980/film/9491a3d8-1e2e-4b54-a6d7-806de9c2d767",
  (error, response, body) => {
     xml2js.parseString(body, function (err, result) {
     console.dir(result);
  });
      #+END_SRC
    - Résultat
      #+BEGIN_SRC
{ object:
   { '$':
      { class: '::nFilm::cFilm',
        instanceauid: '9491a3d8-1e2e-4b54-a6d7-806de9c2d767' },
     state: [ [Object] ],
     relations: [ [Object] ] } }
      #+END_SRC
  - L'authentification avec Bonita
    - Besoin d'ajouter /redirect=false/ à la query string
    - C'est la seule manière de récupérer un code de status de 500 si l'authentification échoue
    - Sans ce paramètre, peu importe le résultat de l'authentification, le code de status est de 200
      - Il faut dans ce cas comparer le contenu de la réponse pour déterminer si l'authentification a réussi ou échoué
- CRDT : Lire *A Conflict-Free Replicated JSON Datatype*
  - Objectifs:
    - Tous les replicas doivent converger vers le même état
    - Aucun input ne doit être perdu
      - Exclu les *LWW-Registers*
    - Fonctionne avec un réseau P2P
    - Les communications peuvent être chiffrées
  - Le format JSON est une structure à plusieurs niveaux
    - Implique qu'il faut pouvoir gérer des opérations concurrentes à différents niveaux de l'arbre
  - Comportement
    - Si modifie un registre en concurrence, conserve l'ensemble des valeurs (*Multi-Value Register*)
    - Si modifie une liste en concurrence, merge les listes
    - Si modifie un registre composé de plusieurs registres, merge les modifications
      - Du coup, on peut se retrouver avec un scénario /bizarre/
      - Si un utilisateur supprime l'objet alors qu'un utilisateur met à jour une de ses propriétés en concurrence
      - Le résultat de la fusion sera alors que la propriété mise à jour
      - L'objet n'est plus cohérent
- Emacs : Configuration de l'éditeur
  - Activation du gestionnaire de packages *MELPA*
    #+BEGIN_SRC
    (require 'package) ;; You might already have this line
    (add-to-list 'package-archives '("melpa" . "https://melpa.org/packages/"))
    (when (< emacs-major-version 24)
      ;; For important compatibility libraries like cl-lib
      (add-to-list 'package-archives '("gnu" . "http://elpa.gnu.org/packages/")))
    (package-initialize) ;; You might already have this line
    #+END_SRC
  - Installation de packages
    - Affichage de la liste des paquets: =M-x list-packages=
    - Installer un paquet:
      - Touche =i= pour marquer le paquet comme à installer
      - Puis =x= pour quitter le menu et passer à l'installation
    - Activer un thème: =M-x load-theme=
  - Liens intéressants
    - Sur les commandes de Emacs: https://www.gnu.org/software/emacs/refcards/pdf/refcard.pdf
    - Sur les fonctionnalités de base de *ORG-MODE*: http://orgmode.org/worg/org-tutorials/org4beginners.html
- PLM : Ajouter [[plumbr.eu][Plumbr]] à PLM
  - Ajout de nouvelles images Docker
    - Ajout d'un *VOLUME* contenant le jar de *Plumbr*
    - Modifie *ENTRYPOINT* ou *CMD* pour référencer ce jar
  - Il s'avère que des fichiers sont manquants
    #+BEGIN_SRC
    plm_1           | *************************************************************************************
    plm_1           | * Plumbr is missing the following required properties: serverUrl,logConf,accountId. *
    plm_1           | * Either make sure the plumbr.properties file is present next to plumbr.jar         *
    plm_1           | * or specify individual properties via -D parameters in your startup script.        *
    plm_1           | *                                                                                   *
    plm_1           | * Check out https://plumbr.eu/support/agent-configuration                           *
    plm_1           | * for more information or contact support@plumbr.eu                                 *
    plm_1           | *************************************************************************************
    #+END_SRC
  - Ajout des fichiers manquants
  - En fait, il n'y avait pas besoin de générer des images custom pour utiliser les agents
    - Dans /docker-compose.yml/, on peut ajouter des volumes au conteneur et modifier la commande utilisée
    - Il est donc possible de définir l'utilisation d'agents que dans le /docker-compose.yml/
    - Ceci permet d'avoir une image de base et de personnaliser son comportement en fonction de la config
  - Mise à jour des /docker-compose.yml/
*** Planned
**** DONE MUTE : Débugger l'ouverture d'un nouveau document
- Si on est sur *DocComponent* et qu'on ouvre un nouveau document, le contenu du document n'est pas remis à 0
- Résoudre ce bug
**** DONE MUTE : Affichage du digest du document
- Pour s'assurer que toutes les copies du document convergent, une fonction /digest()/ existe
- Celle-ci retourne un entier représentant le contenu du document
- Afficher le digest du document pour faciliter la comparaison des copies
**** DONE PLM : Ajouter [[plumbr.eu][Plumbr]] à PLM
- S'agit d'une solution de monitoring pour JVM
- Voir comment elle s'intègre avec Docker et si conflit avec New Relic
** Semaine du <2017-03-20 lun.> au <2017-03-24 ven.>
*** Done
- MUTE : Écrire la partie /Re-synchronisation hors-ligne et collaboration ad-hoc/
  - Explication du couple /<id, clock>/ ajouté à chacune des opérations
  - Explication du vecteur d'états
  - Explication du comportement de l'algo à la réception d'une opération
  - Explication du comportement de l'algo à la réception d'un vecteur d'état
- Discussion avec Weihai
  - Problème de collision d'identifiants
    - Dans la théorie, on admet que l'identifiant de site est unique et sert de désambiguiteur
    - En pratique, il s'avère que générer cet identifant unique n'est pas trivial
      - Comme nous supportons les partitions, nous n'avons pas accès à l'ensemble des identifiants des autres pairs lors de la connexion
      - Nous pouvons donc pas nous assurer que l'identifiant que nous générons n'est pas partagé avec un autre utilisateur
    - Pour réduire les chances d'obtenir une collision d'identifiant, nous pouvons utiliser un identifiant long
    - Mais comme l'identifiant de site est utilisé pour générer les identifiants de blocs, ceci impacte les performances du modèle
      - Existe-t-il des études sur l'impact de la taille de l'identifiant sur les performances?
    - Mais même en utilisant des identifiants longs il sera toujours possible d'obtenir des collisions
    - Il faudrait donc un mécanisme de /recovery/ pour gérer ce cas
  - La probabilité d'obtenir une collision d'identifiants en fonction de la taille de l'identifiant est décrite ici
    - /Birthday attack/: https://en.wikipedia.org/wiki/Birthday_attack
  - Mais obtenir une collision sur l'identifiant de site n'est pas une fatalité
  - Le problème survient si plusieurs utilisateurs génère des blocs différents avec le même identifiant
    - La probabilité de cet évènement est plus difficile à déterminer
      - Probabilité d'obtenir une collision d'identifiants
      - Probabilité que les nombres aléatoires générés soit égaux
	- Dépend de l'emplacement de l'insertion
	- Puisque l'interval de génération du nombre aléatoire dépend du bloc précédent et du suivant
      - Probabilité que les horloges logiques soient égales
  - L'idée de Weihai est de
    - Utiliser des identifiants de site par session plutôt qu'à vie pour limiter la casse
    - Posséder pour chaque session
      - Un identifiant de site long, qui servira de désambiguiteur
      - Un identifiant de site court, qui servira pour générer les opérations
    - Lorsqu'un utilisateur démarre une session, son identifiant long est ajouté au log d'opérations
    - Lorsqu'un utilisateur quitte une session, une opération est ajoutée au log
    - Lorsqu'un utilisateur rejoint un réseau, il doit vérifier s'il n'y a pas eu de collisions d'identifiants de bloc
      - Doit reparcourir le log pour faire ça ?
      - Comment identifier la paternité de l'opération dans le cas suivant ?
	- /open longId1 shortId/
	- /open longId2 shortId/
	- /insert shortId/
    - S'il y a eu une collision, utiliser le /longId/ comme désambiguiteur
      - Renaming des opérations ?
      - Suppression des opérations ?
- TVPaint : Implémenter le prototype orchestrant TVPaint server et Bonita
  - Librairies de clients REST
    - [X] request: [[https://github.com/request/request]]
      - Très populaire
      - "Bas" niveau
    - [ ] node-rest-client: [[https://github.com/aacerox/node-rest-client]]
      - Plus élaboré et "haut" niveau que request
      - Largement moins populaire
      - Manque la gestion des cookies
  - Outils de génération de doc
    - [ ] TSDoc: [[https://github.com/xperiments/TSDoc]]
      - Pas maintenu
    - [X] typedoc: [[https://github.com/TypeStrong/typedoc]]
      - Plus populaire
      - Maintenu
      - Mais la documentation de l'outil est peu fournie
      - Commande pour générer la doc : =typedoc --out docs/ --mode file --module commonjs --target ES6 src=
  - Implémentation de *BonitaClient*
    - Fournit des méthodes de base pour interagir avec Bonita
      - /retrieveProcessId()/
      - /instantiateProcess()/
      - /retrieveTaskIds()/
*** Planned
**** DONE MUTE : Écrire la partie /Re-synchronisation hors-ligne et collaboration ad-hoc/
- Dans un des livrables pour *Open-Paas::NG*, une partie porte sur le mécanisme de synchronisation implémenté dans /mute-core/
  - https://github.com/coast-team/mute-core/blob/master/lib-src/sync/SyncService.ts
- Rédiger cette partie
** Semaine du <2017-03-27 lun.> au <2017-03-31 ven.>
*** Done
- MUTE : Ne plus accepter d'opérations tant qu'on est pas synchronisé
  - Ajout d'un attribut /isSync/
    - /false/ par défaut
    - Une fois qu'on a reçu et traité le message /replySync/, /isSync/ passe à /true/
  - Mise en buffer des opérations tant que /isSync/ est /false/
  - Quand /isSync/ passe à /true/, traite les opérations contenues dans le buffer
  - Puis ensuite traite les opérations reçues dès qu'elles arrivent
    - Plus de mise en buffer
- MUTE : Ne plus répondre à des messages /querySync/ tant qu'on est pas synchronisé
  - Réutilise /isSync/
  - Met en buffer les requêtes tant que /isSync/ est /false/
  - Traite les requêtes dès que /isSync/ passe à /true/
  - Puis ensuite traite les requêtes reçues dès qu'elles arrivent
- MUTE : Ne plus accepter d'opérations sans posséder les précedentes
  - Ajout de /isAlreadyApplied()/ pour vérifier si une opération a déjà été délivrée ou non
  - Ajout de /isAppliable()/ pour vérifier si l'on peut délivrer une opération ou non
  - Lorsqu'on reçoit une opération, vérifie si /isAppliable()/
    - Si l'opération est applicable, la délivre
    - Sinon
      - Met l'opération en buffer
      - Set le flag /isSync/ à /false/
	- Dorénavant, les opérations reçues et les demandes de synchronisation seront mise en attente
      - Envoi d'un message /querySync/
*** Planned
**** DONE MUTE : Ne plus accepter d'opérations tant qu'on est pas synchronisé
- Actuellement, on accepte les opérations distantes avant même que l'on se soit synchronisé avec un pair
- Ceci a conduit à un bug où une opération a été délivrée avant que la synchronisation se soit effectuée
  - Ceci est aussi dû au fait que l'on accepte les opérations dès que /clock > v.get(id)/
- Corriger cela
**** DONE MUTE : Ne plus répondre à des messages /querySync/ tant qu'on est pas synchronisé
- De la même façon, on répond aux messages /querySync/ avant même que l'on soit soi-même synchronisé
- Du coup, un utilisateur peut se croire synchroniser, et se retrouver avec un document vide, alors qu'en fait des opérations existent
- Corriger cela
**** DONE MUTE : Ne plus accepter d'opérations sans posséder les précedentes
- Actuellement, une opération est acceptée tant que sa /clock/ est supérieure à celle que l'on connaît pour cet /id/
- Cependant, des opérations intermédiaires peuvent être manquantes
- Accepter cette opération masque donc ce fait
- Résoudre ce problème
** Semaine du <2017-04-03 lun.> au <2017-04-07 ven.>
*** Done
- MUTE : Supprimer le système de flag /isSync/
  - Suppression des systèmes de bufferisation liés à ce flag
  - Simplification de la gestion des opérations distantes reçues
    - Auparavant, si une opération reçue n'était pas applicable, on rejetait la liste d'opérations, marquait /isSync/ comme /false/ et déclenchait le mécanisme d'anti-entropie
    - Les opérations ainsi que les messages /querySync/ reçus pendant ce temps étaient mis en attente
    - Maintenant, si une opération reçue n'est pas applicable, on se contente de mettre l'opération concernée en attente
    - Récupérer l'opération manquante sera la tâche du mécanisme d'anti-entropie
- MUTE : Déclencher le mécanisme de synchronisation périodiquement
  - Tous les 10±5 secondes, envoi un message /querySync/
- MUTE : Ajouter un bouton pour pouvoir facilement exporter le log d'opérations
  - Ajout d'un bouton /Log/ dans *DevLabelComponent*
  - Ajout de la méthode /exportLog()/ dans *DevLabelComponent*
    - Récupére le /docID/ du document courant
    - Extrait le log d'opérations depuis la base de données
    - Génère un *ObjectURL* à partir de ce log pour pouvoir le télécharger
    - Génère un nom de fichier de la forme /log-<docID>-<digest>.json/
    - Met à jour une balise /<a>/ pour pointer vers ce fichier
    - Simule un click de l'utilisateur sur ce lien
- MUTE : Ajouter un bouton pour pouvoir facilement exporter le modèle
*** Planned
**** DONE MUTE : Supprimer le système de flag /isSync/
- On a constaté plusieurs problèmes liés à ce flag
- Le 1er est qu'il existe un scénario dans lequel aucun pair n'est marqué comme synchronisé
  - Ceci se produit si le 1er utilisateur quitte sans avoir répondu au message /querySync/ du 2nd utilisateur
  - Le 2nd utilisateur n'ayant jamais reçu de /replySync/, son flag /isSync/ est bloqué à /false/
  - Ainsi, chaque opération reçue ou /querySync/ par le 2nd utilisateur sera bufferisée
  - Les utilisateurs qui se connecteront par la suite n'arriveront jamais à se synchroniser dans ce cas
- Le 2nd problème est que le mécanisme de bufferisation s'avère perturbant pour les utilisateurs
  - Soudainement, car une opération qui a été reçue n'a pu être délivrée, l'ensemble des opérations distantes sont mises en attente
  - L'utilisateur ne perçoit donc plus les modifications distantes tant que la synchronisation ne s'est pas de nouveau correctement effectuée
  - De plus, on peut de nouveau tomber dans le cas du 1er problème si le pair avec lequel nous essayons de nous synchroniser se déconnecte sans avoir émis de réponse
- Puisque ce mécanisme semble apporter plus de problèmes qu'il n'en résout, le supprimer
**** DONE MUTE : Déclencher le mécanisme de synchronisation périodiquement
- Puisqu'on a simplifié le mécanisme de synchronisation en retirant le système de flag, on peut dorénavant le déclencher périodiquement
- Ceci permettrait de récupérer les opérations qui n'ayant pas été reçues
**** DONE MUTE : Ajouter un bouton pour pouvoir facilement exporter le log d'opérations
- Lorsqu'une divergence est constatée, nous extrayons les logs d'opérations des différentes copies pour essayer d'identifier l'origine du problème
- Actuellement, j'ai un snippet de code à exécuter directement dans la console du navigateur pour exporter le log
- Ajouter un bouton pour automatiser l'exécution de ce code et faciliter la tâche pour les utilisateurs s'avéra sûrement très utile
**** DONE MUTE : Ajouter un bouton pour pouvoir facilement exporter le modèle
- Nous avons eu un cas particulier où les digests des différentes copies du document divergés, mais où les contenus des copies étaient identiques
- En extrayant les logs d'opérations, nous n'avons pas réussi à reproduire la divergence des digests
- Comparer les modèles nous permettrait d'identifier l'origine de cet étrange résultat
- Logger les différentes versions du modèle me paraît inutilement lourd
- Un bouton pour exporter la sérialisation du modèle me semble plus adapté
** Semaine du <2017-04-24 lun.> au <2017-04-28 ven.>
*** Done
*** Planned
** Semaine du <2017-05-02 mar.> au <2017-05-05 ven.>
*** Done
- <<bug-ct44>> MUTE : Checker le log du document /ct44/ fourni par Victorien avec l'insertion foireuse
  - On trouve dans ce log un problème de causalité
    - L'opération *LogootSDel* supprimant le bloc /{ base: [ 2146186868, -1138834828, 9, 28, 836704880, 669113997, 0 ], begin: 0, end: 0 }/ est exécutée avant l'opération insérant ce bloc
    - L'opération *LogootSDel* est exécutée en 485 tandis que l'opération *LogootSAdd* concernée est exécutée en 506
  - En examinant le déroulement de l'algorithme, nous avons remarqué que l'opération de suppression ci-dessus n'est pas ignorée lorsqu'on ne trouve pas le noeud correspondant
  - À la place, on effectue une suppression dans un autre noeud
  - Ceci entraîne un état inconsistent de cet autre noeud et donc du modèle
  - Des modifications futures de ce bloc échouent donc
- MUTE : Modifier la méthode /delBlock()/ pour gérer le cas où certains identifiants ont déjà été retirés du bloc
- MUTE : Modifier la méthode /delBlock()/ pour ne pas effectuer de suppression dans le cas où le bloc n'existe pas
  - Plus précisement, ce bug était dû au fait que la suppression concernait le bloc résultant d'un split et provenait du comportement de /searchPos()/
  - Dans /delBlock()/, on utilise /searchPos()/ pour trouver le bloc possédant l'identifiant /id/ du début de l'interval à supprimer
  - Dans /searchPos()/
    - On prend la racine comme 1er noeud de comparaison
    - On compare l'identifiant /id/ recherché par rapport aux identifiants de début /id1/ et de fin /id2/ du noeud courant
      - Si /id/ < /id1/ alors on continue la recherche à partir du fils gauche du noeud courant
      - Si /id2/ < /id/ alors on continue la recherche à partir du fils droit du noeud courant
      - Sinon, on considère qu'on a trouvé le noeud comportant l'identifiant recherché et on arrête la recherche
  - Dans notre cas, on comparait un identifiant /id/ avec un noeud délimité par /id1/ et /id2/ tels que
    - /id1/ est de la forme /{ base: [ random1, site1, clock1], last: 0 }/
    - /id2/ est de la forme /{ base: [ random1, site1, clock1], last: 10 }/
    - /id/ est de la forme /{ base: [ random1, site1, clock1, 5, random2, site2, clock2 }, last: 0/
  - Ainsi, on a /id1/ < /id/ < /id2/, /searchPos()/ considère alors qu'on a trouvé le bon noeud
  - Alors que les bases des 2 identifiants sont différentes
  - Modification de /searchPos()/ pour comparer les bases lorsque /id1/ < /id/ < /id2/ pour s'assurer d'avoir trouvé le bon noeud
*** Planned
**** DONE MUTE : Checker le log du document /ct44/ fourni par Victorien avec l'insertion foireuse
- Une opération *LogootSAdd* présente dans ce log d'opération semble avoir mal été générée
- On aurait /begin/ > /end/
- Ce qui viole une assertion lors de son application au document
- Vérifier que l'assertion levée correspond bien au cas où /begin/ > /end/
- Si c'est le cas, trouver l'origine de cette opération malformée
**** DONE MUTE : Modifier la méthode /delBlock()/ pour gérer le cas où certains identifiants ont déjà été retirés du bloc
- Il est possible que plusieurs opérations de suppression concurrentes essaient de supprimer la même partie d'un bloc
- À l'heure actuelle, cela entraîne un /split()/
**** DONE MUTE : Modifier la méthode /delBlock()/ pour ne pas effectuer de suppression dans le cas où le bloc n'existe pas
- Comme remarqué dans [[bug-ct44]], si un bloc est introuvable lorsqu'on essaie de le supprimer, il s'avère que /delBlock()/ effectue une suppression dans un autre bloc
- Ceci rend inconsistent le modèle
- Il est donc nécessaire de modifier /delBlock()/ pour ne plus effectuer de suppression si la recherche du bloc n'aboutit pas
** Semaine du <2017-05-09 mar.> au <2017-05-12 ven.>
*** Done
- TVPaint : Implémenter le prototype orchestrant TVPaint server et Bonita
  - <<tvpaint-frontend-transaction>>Comme me l'a fait remarqué Quentin, la robustesse du front-end est primordiale
    - C'est lui qui pilote les /transactions/
      - Exemple avec la création d'un film:
	- Requête *TVPaint Server* pour créer la ressource
	- Récupère l'identifiant de film contenu dans la réponse du serveur
	- Requête *Bonita* pour instancier le processus avec en paramètre l'identifiant du film
    - Actuellement si une erreur survient au cours de l'échange, la transaction n'est pas annulée
    - Des incohérences peuvent donc apparaître en cas de panne
      - Présence dans la BDD de films associés à aucun processus par exemple
  - Plusieurs philosophies possibles pour le front-end
    - [ ] S'efface au maximum, minimise son rôle
      - Agit uniquement comme un proxy quand possible
	- Par exemple lors d'une requête pour récupérer une ressource
      - Ne comprend pas les données qui transitent
	- Pas de notion de *Movie* et autres
      - Mais parser les données s'avère nécessaire dans certains cas
	- Besoin de lire la réponse de *TVPaintServer* pour extraire l'identifiant lors de la création d'une nouvelle ressource
      - Finalement son comportement est bâtard
    - [X] Connaît en détail la logique de l'application
      - Connaît le type des données qui transitent, ou du moins une version allégée
	- Notion de *Movie* et autres
	- Capable d'instancier ces objets à partir des réponses de TVPaint Server
	- Capable de réécrire ces objets sous un autre format
      - Mais dans ce cas, il est plus fortement couplé à TVPaint Server
        - Modifier le type *Movie* implique une mise à jour du front-end
  - Pour le prototype, j'ai choisi la 2nde option
    - Me paraît plus cohérent comme fonctionnement
  - Ajout d'un client REST générique *RestClient*
    - Construit à partir du /hostname/ et du /port/ du service interrogé et du /name/ de la ressource
    - Pour une ressource d'un type *T* donné, permet de
      - récupérer la liste des identifiants des objets de type *T* avec /getResources(): string[]/
      - récupérer le détail d'une ressource avec /getResource(id: string/): T/
      - créer une nouvelle ressource et récupérer son identifiant avec /post(body: any): string/
  - Ajout d'une extension de ce client REST générique pour interagir spécifiquement avec le serveur de TVPaint, *TVPaintClient*
    - Fournit une implémentation par défaut des méthodes de *RestClient*
    - Requiert une /factory/ pour instancier un objet *T* à partir de la réponse XML, provenant du le serveur de TVPaint, dans /getResource(id)/
  - Mais certaines ressources disposent d'actions supplémentaires
    - On peut associer des *Shots* à un *Movie* et des *Clips* à un *Shot*
  - Il est nécessaire de fournir une nouvelle extension du client REST
  - De nouveau, un choix de conception se pose
    - [ ] Faut-il contraindre avec /append()/ le type de la donnée ajoutée
      - /append(obj: T1, appendee: T2)/
      - Dans ce cas, il faut réussir à exprimer le lien entre *T1* et *T2*
	- Que *T2* est /appendable/ à *T1*
      - Et il faut s'assurer que les objets fournis au front-end lors de cette requêtes soient bien du bon type
	- S'assurer que l'objet /obj/ correspond bien à un *T1* au niveau du serveur TVPaint
    - [X] ou juste se contenter de manipuler des identifiants
      - /append(id1: string, id2: string)/
      - On délègue au serveur TVPaint de vérifier que les objets manipulés sont du bon type
	- Puisque dans tous les cas, il faudra effectuer des vérifications sur les données manipulées au niveau du serveur TVPaint
  - Moyen de récupérer l'ensemble des tâches pour un utilisateur
    #+BEGIN_SRC
$ curl http://localhost:8728/bonita/API/bpm/humanTask?p=0&c=10&f=user_id=4
[
  {
    "displayDescription": "",
    "executedBy": "0",
    "rootContainerId": "14001",
    "assigned_date": "",
    "displayName": "Add shots",
    "executedBySubstitute": "0",
    "dueDate": "2017-05-12 11:40:35.199",
    "description": "",
    "type": "USER_TASK",
    "priority": "normal",
    "actorId": "1601",
    "processId": "8562487203032783503",
    "caseId": "14001",
    "name": "addShots",
    "reached_state_date": "2017-05-12 10:40:35.216",
    "rootCaseId": "14001",
    "id": "280002",
    "state": "ready",
    "parentCaseId": "14001",
    "last_update_date": "2017-05-12 10:40:35.216",
    "assigned_id": ""
  }
]
    #+END_SRC
  - Moyen de récupérer une variable d'un /case/
    #+BEGIN_SRC
$ curl http://localhost:8728/bonita/API/bpm/caseVariable/14001/movieId
{
  "case_id": "14001",
  "name": "movieId",
  "description": "",
  "type": "java.lang.String",
  "value": "1a60e1ad-d14e-4b64-a088-7cc3c63c4bdd"
}
    #+END_SRC
- MUTE : Étudier les logs du document /ct25/ pour trouver l'origine de la divergence
  - En rejouant le log d'opérations /chamber-bazooka-mercy/, pas de problème de causalité
  - Par contre, avec les logs /patron-user-arcade/ et /trapeze-arnold-sheriff/, on en rencontre
    - L'opération 3523 essaie de supprimer un bloc n'existant pas encore dans le cas de /patron-user-arcade/
    - L'opération 1849 essaie de supprimer un bloc n'existant pas encore dans le cas de /trapeze-arnold-sheriff/
  - Il s'agit donc à 1ère vue d'un problème de causalité
*** Planned
**** DONE MUTE : Étudier les logs du document /ct25/ pour trouver l'origine de la divergence
- Une divergence a été constatée à la fin de la réunion du /ct25/
- Comparer les logs pour déterminer son origine
** Semaine du <2017-05-15 lun.> au <2017-05-19 ven.>
*** Done
- PIDR : Étudier et commenter la v2 du rapport
  - Formulation trop familière, vocabulaire trop vague
  - I. Intro
    - A. Contexte
      - Parle de /tests à effectuer sur les éditeurs collaboratifs/, lesquels ?
    - D. Motivations
      - Parle de /travail interdisciplinaire/, pourquoi insister sur le /interdisciplinaire/ ?
      - Revoir le paragraphe sur les différences entre les éditeurs collaboratifs
        - Semble incomplet (parle d'OT mais pas de CRDT)
        - OT ne scale pas, même en pair-à-pair
        - Bien faire la distinction entre algorithmes de réplication et architecture des applications
      - La conclusion de cette partie ne me paraît pas clair
        - Manque une transition avec le reste de la partie
        - Insister sur l'hétérogénéité des applications
        - La réponse ne doit pas "s'adapter", elle doit être générique
      - Finalement l'objectif n'apparaît pas encore clairement
  - II. Etat de l'art
    - A. Différents types d'écriture collaborative
      - Est-ce que les comportements observés dépendent du type d'outil (synchrone ou asynchrone) ?
      - Justifier la citation
      - Intérêt de parler des système d'éditions collaboratifs asynchrones ?
      - Manque la citation vers Docuviz ou autre document illustrant ces comportements
    - C. Représentation du comportement d'un utilisateur
      - 1. Nécessité de cette représentation
	- Pourquoi cette partie existe toujours ?
	- Fusionner avec *Motivations*
      - 2. Réprésentation à l'aide de grammaires
	- Si la figure a été récupérée d'un document, indiquer sa source
    - Manque finalement de recontextualisation
      - Présente des choses (comportements, actions...) mais sans dire comme cela va vous être utile
  - III. Contribution
    - B. Modélisation de la session de travail collaborative
      - Mauvaise position dans l'article
	- Interrompt la réflexion sur les grammaires proposées
      - Pas assez claire
      - Insister sur la notion d'/orchestration/ des bots dans la 1ère approche
        - Le comportement des bots est déterminé par le chef d'orchestre
	- Les bots se contentent de suivre un comportement prédéfini
      - Insister sur la notion de /décentralisation/ des bots dans la 2nde approche
	- Les bots sont capables de déterminer les comportements à employer pour effectuer la tâche
	- Ils sont capables de se répartir le travail
    - C. Ecriture d’une grammaire qui modélise un automate à états finis
      - Des limites à cette nouvelle grammaire ?
  - IV. Validation
    - A. Implémentation de la solution via Python
      - Justification des critères choisis pour la comparaison des AST ?
      - D'après ces critères, recommandez-vous un outil plutôt que l'autre ?
    - Pourquoi une seule sous-partie ?
  - V. Perspectives
    - Est-ce que l'application /permet de voir comment l'éditeur gère les conflits/ ?
    - Pourquoi ces actions /lire/ et /communiquer/ ? Qu'est-ce qu'elles apportent ?
  - VI. Conclusion
    - Pas besoin d'être exhaustif sur les implémentations
    - Revenir sur les contributions en mettant en valeur la principale (la grammaire v2)
    - Le reste a déjà été énoncé dans problématique
- TVPaint: Implémenter le prototype orchestrant TVPaint server et Bonita
  - Modification de GET /film
    - Auparavant, récupérer l'ensemble des films de la BDD
    - Maintenant, liste seulement les films pour lesquels l'utilisateur a des tâches en cours/disponibles
    - Format de la réponse:
      #+BEGIN_SRC
      [ { caseId: '16001',  movieId: 'c803d583-f4b3-47ea-be3d-555ba2dc0da8' } ]
      #+END_SRC
  - Ajout d'une route GET /film/:movieId/task
    - Nécessite de passer en paramètre le /caseId/ qui correspond au /movieId/
    - Permet de récupérer la liste des tâches concernant ce film/cette instance de process pour l'utilisateur courant
    - Format de la réponse:
      #+BEGIN_SRC
      [ { displayDescription: '',
          executedBy: '0',
          rootContainerId: '16001',
          assigned_date: '',
          displayName: 'Add shots',
          executedBySubstitute: '0',
          dueDate: '2017-05-17 12:34:29.730',
          description: '',
          type: 'USER_TASK',
          priority: 'normal',
          actorId: '1901',
          processId: '7285702430994004787',
          caseId: '16001',
          name: 'addShots',
          reached_state_date: '2017-05-17 11:34:29.747',
          rootCaseId: '16001',
          id: '320002',
          state: 'ready',
          parentCaseId: '16001',
          last_update_date: '2017-05-17 11:34:29.747',
          assigned_id: '' } ]
      #+END_SRC
  - Ajout d'un script simulant un client
    - Crée un film
    - Récupère la liste des films
    - Récupère les tâches concernant le film précédemment créé
    - S'assigne la tâche /addShots/
    - Récupère les shots
    - Complète la tâche /addShots/
  - Comportements à discuter
    - GET /film
      - Retourne l'ensemble des films ?
      - Retourne les films en cours de l'utilisateur ?
	- Interroge *Bonita* pour récupérer les tâches associés à l'utilisateur pour savoir quels films le concernent
    - GET /shot et GET /clip
      - Retourne l'ensemble des ressources ?
      - Retourne un sous-ensemble jugé "accessible" par l'utilisateur ?
	- Quels critères utiliser ?
    - Mécanisme de transaction
      - voir [[tvpaint-frontend-transaction]]
*** Planned
**** DONE PIDR : Étudier et commenter la v2 du rapport
** Semaine du <2017-05-22 lun.> au <2017-05-24 mer.>
*** Done
- PIDR : Noter le rapport des étudiants de PIDR
  - Des éléments de fonds intéressants
  - Éléments regrettables
    - La notion de grande échelle de l'expérience est manquante dans l'introduction
      - Il faut attendre la fin de la motivation pour voir apparaître cet aspect
      - Du coup, on ne comprend moins la nécessité de simuler les utilisateurs
    - La liste des actions élémentaires est aussi absente
      - Besoin d'attendre la 1ère grammaire pour connaître ces actions
  - Entachés par la forme
    - Quelques paragraphes mal organisé
      - 1er paragraphe de Contribution
    - Discours trop familier, trop oral
  - Quelques confusions sur le fond semblent aussi persistées
    - Exemples
      - CRDT et P2P
      - L'expérience permettra de voir comment l'éditeur gère les conflits
      - Différents types d'écriture collaborative et Différents types de comportements
    - Est-ce à cause d'une mauvaise maitrise de ces éléments ?
    - Ou juste est-ce qu'ils se sont mal exprimés ?
  - On ressent un manque de rigueur
    - Au niveau du langage utilisé
    - Mais aussi sur le fond présenté
      - Donne des chiffres sur le nombres d'actions par état sans raison apparente
- PIDR : Noter le travail des étudiants de PIDR
  - Points positifs
    - Idée de la grammaire pour représenter l'automate
  - Points négatifs
    - Ressenti un manque d'implication dans le projet
      - Plusieurs semaines, le travail fourni semblait léger par rapport à nos attentes
      - Quand interrogés sur la quantité de travail fourni, les étudiants répondaient qu'ils avaient dû travailler d'autres projets
      - Lors des réunions, du moins au début, la prise de notes était limitée
	- Besoin de nous-même prendre en photo et de leur envoyer l'automate réaliser au tableau au cours d'une réunion
      - Lorsque demandés de chercher des parsers-lexers pour Python, les résultats fournis étaient les 1ers retournés par Google
	- Un d'entre eux ne correspondait absolument pas au projet (API de Python pour modifier le parser du langage)
*** Planned
**** DONE PIDR : Noter le rapport des étudiants de PIDR
**** DONE PIDR : Noter le travail des étudiants de PIDR
**** DONE TVPaint : Implémenter le prototype orchestrant TVPaint server et Bonita
- Devrait orchestrer les 2 serveurs pour jouer les tâches suivantes :
  - Créer un film
  - Associer des shots au film
    - Besoin potentiellement de créer les shots
  - Associer des clips au shot
    - Besoin potentiellement de créer les clips
**** DONE TVPaint : Mener une refléxion sur l'implémentation ou non d'un mécanisme de transaction
- Voir [[tvpaint-frontend-transaction]]
- Est-ce qu'un mécanisme de transaction doit être implémenté ?
- Ou est-ce que l'on peut s'en passer ?
  - En designant le système pour être tolérant aux pannes par exemple
**** DONE TVPaint : Définir un workflow correspondant au scénario de test
**** DONE Thèse : Préparer le dossier de candidature pour la thèse
- Doit fournir les pièces suivantes
  - [X] CV
    - Retravailler la section sur *MUTE* dans *Projets* pour parler de *OpenPaas::NG* à la place
    - Ajouter une section *Logiciels* indiquant la participation aux logiciels
      - Se baser sur [[file:~/T%C3%A9l%C3%A9chargements/softwarecriteria-ce_2011-08-01.pdf][ce document]] pour spécifier l'état de maturité des logiciels
  - [X] Lettre de motivation
  - [X] Lettres de recommandation
  - [X] Sujet de thèse
  - [X] Mémoire d'ingénieur
  - [X] Diplôme TN
  - [X] Notes TN
  - [X] Diplôme DUT
  - [X] Notes DUT
  - [X] Diplôme BAC
  - [X] Notes BAC
** Semaine du <2017-05-29 lun.> au <2017-06-02 ven.>
*** Done
- TVPaint : Rédiger README pour Bonita
  - [X] Décrire la version à installer
    - 7.3
  - [ ] Décrire le rôle des différents diagrammes
  - [X] Décrire comment changer
    - [X] Le port utilisé par Bonita
    - [X] L'utilisateur par défaut
- TVPaint : Rédiger README pour front-end
  - [X] Décrire le processus d'installation
  - [X] Documenter le scénario joué par le script simulant client
  - [ ] Récapituler les questions existantes
    - [ ] Gestion des transactions
    - [ ] Gestion des droits d'accès aux ressources
      - Plus précisement, aux shots et clips
    - [ ] Technologies à utiliser
      - Inciter à regarder du côté de Go
** Semaine du <2017-06-19 lun.> au <2017-06-23 ven.>
*** Done
*** Planned
**** DONE TVPaint : Rédiger README pour Bonita
**** DONE TVPaint : Rédiger README pour front-end
**** CANCELLED MUTE : Débugger la liste des documents
- Lorsqu'on souhaite re-afficher la liste des documents alors que nous étions sur la page d'un document, la liste ne se génère pas dans tous les cas
- La liste de *DocsComponent* est générée à partir de la valeur /activeFile/
  - S'il s'agit d'un *Folder*, récupère et affiche la liste de ses documents
  - Sinon ne fait rien
- La valeur de /activeFile/ est mise à jour à plusieurs endroits
  - Lorsque l'utilisateur sélectionne un nouveau dossier dans *NavComponent*
    - Dans ce cas, /activeFile/ prend pour valeur ce dossier
  - Lorsqu'on accède à un document
    - Alors /activeFile/ prend pour valeur ce document
- Cependant, comme *NavComponent* n'est jamais détruit, il se "souvient" du précédent dossier selectionné
- Ainsi, si on sélectionne le même, aucun changement n'est détecté
  - La valeur de /activeFile/ n'est donc pas mise à jour
- Ainsi, comme /activeFile/ correspond toujours au dernier document ouvert, *DocsComponent* ne génère pas de liste
- Corriger ce comportement
**** CANCELLED TVPaint : Développer la tâche compositing
- La tâche /compositing/ est une activité complexe
- La décomposer en plusieurs sous-tâches
  - Revoir les posts du forum qui y sont dédiés
** Semaine du <2017-07-03 lun.> au <2017-07-07 ven.>
*** Done
- Suivi la formation NVIDIA sur Deep Learning
  - Présentation de l'écosystème NVIDIA
  - Présentation de NVIDIA Digits
    - Environnement d'apprentissage en ligne
  - Formation s'est déroulée sur NVIDIA Digits
    - Bases du Machine Learning
      - Génération d'un dataset
      - Génération d'un réseau de neurones à partir d'un modèle pré-existant
      - Sélection des hyperparamètres
      - Entraînement du modèle
      - Validation
    - Intéressant de revoir les bases mais je pensais qu'on allait aborder des sujets plus bas niveaux
- Suivi la formation NVIDIA sur OpenACC
  - Présentation de l'écosystème NVIDIA
  - Présentation de OpenACC
    - Pour langages C/C++ et Fortran principalement
    - Permet d'ajouter des directives pour que le compilateur rende parallèle des portions du code et les exécutent sur le GPU
      - Pas de refactoring du code
    - Ressemble de fait à OpenMP
  - Suivi d'un tutoriel pour prendre en main OpenACC
    - Mise en évidence du problème de transfert des données de la mémoire du système vers le GPU
      - Transférer inutilement des données peut ralentir le programme au point qu'il soit moins performant que sa version séquentielle tournant sur le CPU
    - Étapes du tuto
      - Détection d'une zone parallélisable
      - Profiling du résultat de la parallèlisation
      - Correction des problèmes de parallélisation initiaux
	- Par exemple, transfert de données inutiles entre le CPU et le GPU
      - Optimisation du réglage des paramètres de parallélisation en fonction de l'environnement cible
	- Par exemple, réglages spécifiques pour un GPU NVIDIA
- MUTE : Ajouter des tests d'intégration se basant sur les logs d'opérations
  - On a finalement peu de logs sur lesquels se baser pour ce genre de tests
  - Généralement, je récupère un log par digest pour observer et comprendre les différences
  - Je n'ai donc peu de logs de différents utilisateurs qui convergent
  - Écriture du test d'intégration
    - Création d'une macro de test /everyLogsConvergeMacro/
      - À partir d'un set de fichiers de log, extrait les opérations et les rejoue pour obtenir le modèle de chaque utilisateur
      - Compare ensuite les digests et contenus des modèles entre eux
      - Permet de vérifier si les documents convergent ou non, en fonction du résultat attendu
    - Génération de 3 tests à partir de cette macro
      - L'ensemble de ces tests reposent sur des logs issus du document /ct3/
      - 1er set : les logs de Claudia et Long convergent
      - 2nd set : les logs de Le et Philippe convergent
      - 3eme set : les logs de Claudia et Philippe ne convergent pas
- MUTE : Corriger /hasPlaceAfter/Before()/ dans le cas où /last/ approche d'une borne
  - Modification de /hasPlaceAfter/Before()/ pour prendre en compte la valeur de /last/
  - Ajout de tests unitaires pour ces cas
*** Planned
**** DONE MUTE : Ajouter des tests d'intégration se basant sur les logs d'opérations
- Puisqu'on dispose de traces d'utilisation sur MUTE, nous pouvons récupérer plusieurs logs d'opérations pour ajouter des tests supplémentaires
- Ces tests consisteraient à rejouer des logs d'opérations différents mais convergents pour s'assurer qu'ils convergent toujours après nos modifications
  - Comment choisir ces logs ?
- Des logs supplémentaires divergents pourraient être ajoutés pour s'assurer que ces scénarios divergent toujours
**** DONE MUTE : Corriger /hasPlaceAfter/Before()/ dans le cas où /last/ approche d'une borne
- /hasPlaceAfter/Before()/ sont utilisées avant un append/prepend pour vérifier qu'on peut effectuer cette opération
- Cependant, ces fonctions ne vérifient pas si append/prepend à ce bloc ne déclencherait pas un over/underflow
** Semaine du <2017-07-10 lun.> au <2017-07-13 jeu.>
*** Done
- MUTE : Refactorer la génération des identifiants par *IdFactory*
  - Modification de la méthode /createBetweenPosition()/
  - Pour le moment, se contente de recopier les 4 éléments du tuple si on ne peut pas générer un nombre aléatoire entre les 2 1ers éléments des tuples
*** Planned
**** DONE MUTE : Refactorer la génération des identifiants par *IdFactory*
- À l'heure actuelle, *IdFactory* implémente la version /optimisée/ de génération des identifiants
- Concrètement, dès qu'un intervalle suffisant est détecté pour générer un nombre aléatoire, *IdFactory* insère le tuple <rnd, replicaNumber, clock, offset>
- Par exemple, avec id1 = [rnd1, replicaNumber1, clock1, offset1] et id3 = [rnd3, replicaNumber3, clock3, offset3], *IdFactory* génère :
  - id2 = [rnd2, replicaNumber2, clock2, last2] si rnd3 - rnd1 > 2
  - id2 = [rnd, rnd2, replicaNumber2, clock2, last2]  si replicaNumber3 - replicaNumber1 > 2
  - id2 = [rnd, replicaNumber1, rnd2, replicaNumber2, clock2, last2] si clock3 - clock1 > 2
  - id2 = [rnd, replicaNumber1, clock1, rnd2, replicaNumber2, clock2, last2] si last3 - last1 > 2
  - id2 = [rnd, replicaNumber1, clock1, last1, rnd2, replicaNumber2, clock2 last2] sinon
- Par la suite, nous allons donc potentiellement comparer des éléments de types différents (rnd avec replicaNumber par exemple)
- Ceci fonctionne car nous utilisons le même type de données pour chacun de ces éléments
- Ceci peut être amené à évoluer
- Il ne faudait qu'effectuer la comparaison sur rnd, et le cas échéant, recopier l'ensemble du préfixe
** Semaine du <2017-07-17 lun.> au <2017-07-21 ven.>
*** Done
- MUTE : Setup Travis CI pour /mute-structs/
  - Pour release facilement la nouvelle version, besoin d'ajouter la clé d'API
  - Pour la chiffrer et l'ajouter directement à la configuration de Travis
    - travis encrypt api_key="myAPIKey" --add deploy.api_key
*** Planned
** Semaine du <2017-07-24 lun.> au <2017-07-28 ven.>
*** Done
- Mettre à jour la version d'un projet via npm
  - npm version major | minor | patch -m "chore: Update version number to %s"
- Mute : Étudier la fusion de /last/ avec /base/
  - Création de *IdentifierTuple*, objet composé de /random/, /replicaNumber/, /clock/ et /offset/
  - Modification de *Identifier* pour remplacer /base/ et /last/ par /tuples: IdentifierTuple[]/
- MUTE : Ajout de *SafeAny*
  - On a remarqué que le type *any* contourne totalement le compilateur de TypeScript, notamment pour la gestion des /null/
  - Exemple :
      #+BEGIN_SRC
      let id: Identifier
      let toto: any = null
      id = toto // Le compilateur devrait indiquer que toto est p-e null
      id.compareTo(...) // Déclenche une NullPointerException
      #+END_SRC
  - Comme *any* ne se comporte pas comme on le souhaite, on a ajouté *SafeAny*
  - Ce type nous permet d'identifier une variable comme *any* mais permet de conserver les indicateurs du compilateur lorsqu'on la manipule
- MUTE : Nettoyage de *RopesNode*
  - Renommage de /offset/ en /actualBegin/ pour rendre plus clair le code
  - Refonte de /maxOffset()/ en /actualEnd/ pour rendre plus clair le code
- MUTE : Nettoyage de *IteratorHelperIdentifier*
  - Renommage de /id1/ et /id2/ en /idInterval1/ et /idInterval2/ pour éviter une confusion sur le type de ces propriétés
- MUTE : Nettoyage de *LogootSBlock*
  - Renommage de /id/ en /idInterval/ pour éviter une confusion sur le type de cette propriété
  - Suppression des paramètres /begin/ et /end/ de /delBlock()/ qui étaient inutilisés
- MUTE : Amélioration des tests effectués sur les logs d'opérations existants
  - Jusqu'à maintenant, on ne vérifiait pas si le log contenait une opération sérialisée incorrectement
  - Ainsi, le test pouvait planter à l'exécution à cause d'une *NullPointerException*
  - Modification du test pour /fail/ proprement si on détecte une opération sérialisée incorrectement
  - Modification du test pour /fail/ proprement si on détecte un log vide
*** Planned
** Semaine du <2017-07-31 Mon> au <2017-08-04 Fri>
*** Done
- MUTE : Ajouter des tests pour *IteratorHelperIdentifier*
  - Ajout d'une méthode /compareBaseMacro()/ permettant d'appeler /compareBase()/ sur 2 *IdentifierInterval* et de comparer le résultat à la valeur attendue
  - Implémentation de tests se basant sur cette macro pour vérifier le comportement de /compareBase()/ pour les différents cas possibles
*** Planned
**** DONE MUTE : Ajouter des tests pour *IteratorHelperIdentifier*
- Cette partie du code est critique puisque c'est elle qui détermine où on insère un bloc par rapport à un autre
- Cependant, aucun test n'est écrit pour /compareBase()/
- Les ajouter
** Semaine du <2017-08-07 Mon> au <2017-08-11 Fri>
*** Done
- MUTE : Ajouter l'intégration continue dans /mute-core/
  - Modification de l'architecture du repo pour coller à celle de /mute-structs/ et /mute/
  - Difficulté avec les fichiers de /Protobuf/
    - À l'origine, les dossiers /src/, /test/ et /proto/ sont au même niveau
    - Mais une fois le code transpilé, on obtient les répertoires /proto/, /dist/src/ et /dist/test/
    - L'import des fichiers de /Protobuf/ échoue donc, le chemin relatif ne correspondant plus
    - Pour le moment, se contente de /cp -r proto dist/proto/
  - Ajout de tests pour *SyncMessageService*
    - [X] Test la sérialisation, envoi puis désérialisation d'une liste de *RichLogootSOperation*
    - [X] Test de la sérialisation, envoi puis désérialisation d'une *QuerySync*
    - [X] Test que le *ReplySyncEvent* en réponse à une *QuerySync* est bien destiné au bon utilisateur
    - [X] Test la sérialisation, envoi puis désérialisation d'un *ReplySyncEvent*
- Soutenance blanche - Quentin TARDIVON
  - "De janvier à août 2017"
    - On ne sait pas que tu as le fait le PIDR, et t'es censé parlé du stage uniquement non ?
  - Slide 6: On veut surtout illustrer nos travaux
  - Slide 7 et 9: Écrire les objectifs ?
  - Slide 12: Mettre la(es) référence(s) ?
  - Slide 15:
    - Reformuler "Mise en place de cette API"
  - Slide 16:
    - Animer le schéma ?
    - Grossir la taille des flèches ?
  - Slide 19:
    - À mon sens, pas clair dans ton discours la différence entre /signaling/ et /P2P/
*** Planned
**** DONE MUTE : Ajouter l'intégration continue dans /mute-core/
- Il serait temps d'ajouter des tests dans /mute-core/
- Ajouter la configuration pour Travis de façon à les exécuter fréquemment
** Semaine du <2017-08-22 Tue> au <2017-08-25 Fri>
*** Done
- MUTE : Ajout de *LogootSOperation* et de *TextOperation*
  - Ajout de ces nouveaux types
  - Pas pu les déclarer dans des fichiers /.d.ts/
  - Ils n'étaient alors pas exportés
  - Il a donc été nécessaire de les déclarer dans des fichiers /.ts/
- MUTE : Amélioration de la génération du /digest/ et du /tree/
  - Création d'un flux /updateSubject/
    - Ce flux indique quand un nouveau /digest/ et un nouveau /tree/ doivent être émis
  - /subscribe/ à ce flux, couplé à l'opérateur /debounceTime/
  - Suppression des /subscribes/ en double liés aux fluxs de *TextOperations* ou de *LogootSOperations*
  - Modification des /subscribes/ aux fluxs de *TextOperations* ou de *LogootSOperations* pour aussi émettre une nouvelle valeur via /updateSubject/
- MUTE : Suppression de /docValueSubject/
- MUTE : Ajouter des tests pour *DocService*
  - Ajout du test /textOperation-correct-send-and-delivery/
    - Connecte 2 instances de *DocService*, /docServiceIn/ et /docServiceOut/
    - Fournit des *TextOperations* locales à l'instance /docServiceIn/
    - Vérifie que /docServiceOut/ émet bien les *TextOperations* distantes correspondantes
*** Planned
**** DONE MUTE : Ajout de *LogootSOperation* et de *TextOperation*
- Actuellement, plusieurs variables sont du type *LogootSAdd | LogootSDel* ou *TextDelete | TextInsert*
- Ces unions de types alourdissent le code
- Ajouter de nouveaux types correspondant à ces unions
**** DONE MUTE : Amélioration de la génération du /digest/ et du /tree/
- Actuellement, le /digest/ et le /tree/ correspondant sont générés suite à la réception d'une *TextOperation* locale ou d'une *LogootSOperation* distante
- Pour éviter de générer des valeurs inutiles, on utilise l'opérateur /debounceTime/ pour attendre que le document se stabilise
- On a donc plusieurs /subscribes/ pour un même flux
  - Un premier appliquant chaque opération reçue au modèle et émettant la ou les opérations résultantes
  - Un second, agrémenté de l'opération /debounceTime/ pour générer le /digest/
- Le fait de /subscribe/ plusieurs fois au même flux à pour effet de dupliquer ce flux, et donc les traitements qui sont appliqués aux données
  - On a pu observer ce comportement étrange via des logs qui se sont retrouvés dupliqués
- Aussi, on observe que les /debounceTime/ n'étant pas liés entre eux, on génère tout de même des /digests/ intermédiaires inutiles
- Améliorer ce comportement
**** DONE MUTE : Suppression de /docValueSubject/
- Cet attribut est utilisé pour émettre le texte correspondant au modèle
- Cette valeur est émise à l'initialisation du document
- Ceci nous permet de réinitialiser le contenu de l'éditeur lorsque l'utilisateur change de document
- Mais le modèle étant vide à son initialisation, la chaîne de caractère l'est aussi
- On peut donc simplifier le comportement de l'éditeur pour réinitialiser son contenu
- Ce flux n'a donc plus d'utilité
- Le supprimer
**** DONE MUTE : Ajouter des tests pour *DocService*
** Semaine du <2017-08-28 Mon> au <2017-09-01 Fri>
*** Done
- Commandes pour la démo
  - Effectuer le build de la démo
    - ~npm run build -- -e demo~
  - Uploader l'appli
    - ~scp -r /path/to/source pi@192.168.0.101:/home/pi/html~
- MUTE : Identifier l'origine des digests différents pour un contenu identique
  - On rejouant les logs, labellés avec des digests différents, on obtient bien un seul et même digest
  - Le contenu des documents s'avère aussi identique
  - En listant les digests intermédiaires des logs, on ne retrouve pas les digests obtenus au cours de la session collaborative
  - En jouant un rapide scénario, j'ai pu obtenir des digests différents pour un même document
    - Utilisateur 1 insère "a\n" en 0
    - Utilisateur 2 insère "c" en 2
    - Une partition se produit
    - Utilisateur 1 insère "d" en 3
    - Utilisateur 2 insère "b" en 1
    - Résolution de la partition
  - Les arbres sont en fait équilibrés différement
  - Mais en rejouant le log (en rechargeant la page), cette fois-ci les digests convergent
    - Ce qui est troublant, pourquoi les digests ne continuent-ils pas de diverger ?
- MUTE : Génération du build correspondant à la nouvelle version de MUTE
  - Installation de https://github.com/google/zopfli
  - Modification de la valeur de DIR dans /scripts/brotli_build_compression.js/
  - Installation de https://github.com/google/brotli
*** Planned
** Semaine du <2017-09-11 Mon> au <2017-09-15 Fri>
*** Done
- MUTE : Identifier l'origine des digests différents pour un contenu identique
  - Je n'ai pas réussi à reproduire ce problème à l'aide du scénario précédent
  - Les digests obtenus sont égaux, même si les arbres sont équilibrés différemment
    - Ce nouveau résultat s'avère tout aussi troublant
  - Ajout d'un test /convergent-trees/
    - Permet de vérifier qu'on obtient un arbre balancé de la même manière en exécutant des opérations dans un ordre différent
    - Échoue à l'heure actuelle
    - Permet de vérifier si https://github.com/coast-team/mute-structs/issues/11 est résolue
  - Ajout d'un test /non-convergent-balanced-trees-different-digests/
    - Permet de vérifier qu'on obtient un digest différent pour des arbres équilibrés de manière différente
    - Échoue à l'heure actuelle
    - Permet de vérifier si https://github.com/coast-team/mute-structs/issues/12 est résolue
- MUTE : Séparer *StateVector* de *SyncService*
  - Déplacement de l'implémentation du vecteur d'état dans *StateVector*
  - Ajout de tests pour *StateVector*
    - Constructeur
    - set
  - Mise à jour de *SyncService* pour utiliser *StateVector*
*** Planned
**** DONE PLM : Implémenter un script monitorant les juges
- /WebPLM/ est utilisée de nouveau à TELECOM Nancy
- Cependant, nous avons toujours un problème avec les juges
  - Ils peuvent devenir des /zombies/ après avoir exécuté le code d'un étudiant
  - Dans cet état, ils se comportent d'une des manières suivantes
**** DONE MUTE : Séparer *StateVector* de *SyncService*
- À l'heure actuelle, l'implémentation du vecteur d'état est faite au sein du composant *SyncService*
- Afin de tester l'implémentation du vecteur d'état (son initialisation, sa mise à jour, le calcul des opérations manquantes), il est nécessaire de les séparer
- Implémenter *StateVector*
** Semaine du <2017-09-20 Wed> au <2017-09-22 Fri>
*** Done
- TEACHING : Notes sur le cours 2
  - Slide 7 : confusion possible avec la notation des fonctions
- MUTE : Utiliser *StateVector* dans *SyncMessageService*
  - Mise à jour des *Subject* concernés dans *SyncMessageService* et *SyncService*
  - Mise à jour des méthodes /generateQuerySyncMsg()/ et /handleQuerySyncMsg()/
- MUTE : Compléter les tests pour *StateVector*
  - Ajout des tests pour :
    - /isAlreadyDelivered()/
    - /isDeliverable()/
    - /computeMissingIntervals()/
- MongoDB : Pense-bête
  - Lister les databases: /db.adminCommand( { listDatabases: 1 } )/
  - Lister les collections: /show collections/
  - Lister les documents d'une collection: /db.<collection>.find({})/
  - Faire une requête dans une collection: /db.<collection>.find({ <fieldName>: "<value>"}/)
  - Faire une requête dans une collection en utilisant une regexp: /db.<collection>.find({ <fieldName>: /^regexp/ })/
- MUTE : Identifier l'origine des digests différents pour un contenu identique
  - J'ai rejoué le scénario de la démo pour essayer de produire ce bug
  - Je n'ai pas réussi à le reproduire à l'aide du scénario de test retranscrit dans /convergent-trees/
  - Ce scénario semble donc ne pas correspondre
  - En modifiant le scénario, j'ai finalement *réussi à reproduire le bug*
    - Le scénario reprend les différentes étapes du précédent : /création d'un groupe, collaboration, partition, travail séparé, reconnexion, resynchronisation/
    - La modification concerne la partie /reconnexion/
    - Au cours de la /reconnexion/, un pair émet de nouvelles opérations
  - Le document *testABCDEFGHIJKLMN* est une reproduction de ce nouveau scénario
    - Les opérations générées au cours de la phase de /reconnexion/ sont les opérations /29/ à /38/ de l'utilisateur /-600040289/
    - Elles correspondant au texte "Ayé la reconnexion va se produire..."
  - On constate un *problème lié au mécanisme de synchronisation*
    - Dès que la reconnexion est effectuée, les opérations nouvellement générées sont transmises aux autres pairs
    - Mais la synchronisation n'a pas encore eu lieu
    - Ces opérations ne sont donc pas encore délivrables, elles sont bufferisées
    - Elles sont ensuite délivrées (lors de la resynchronisation probablement)
    - Mais elles sont de nouveau bufferisées par la suite (toujours lors de la synchronisation ?)
  - On constate un *problème lié au modèle*
    - On observe un saut dans le déplacement du curseur lorsqu'on arrive à la position "Ayé la reconnex|ion va se produire..."
    - Le saut observé est différent selon l'utilisateur
    - Ceci indiquerait un problème aux niveaux des identifiants au sein de la structure de données
  - Après un rechargement de la page par le Chromebook, les digests convergent
  - Il est nécessaire de creuser plusieurs points :
  - Pourquoi certaines opérations sont bufferisées plusieurs fois ?
    - Probablement, au cours de la synchronisation, l'opération /28/ est délivrée
    - On délivre alors en cascade les opérations en attente
    - Puis on continue de traiter le message de synchronisation
    - Voir pourquoi ces opérations sont rebufferisées
  - Pourquoi ce saut de curseur ?
    - Pourquoi les modèles divergent ?
  - Pourquoi en rechargeant la page, les digests convergent ?
    - Comparer les logs du Chromebook avant/après reload pour voir s'ils diffèrent
    - Comparer les arbres du Chromebook avant/après reload pour voir s'ils diffèrent
- Meeting:
  - Spend most of the summer working on /mute-structs/
    - Start to refactor the identifiers
    - Since we rely heavily on it, had to refactor many parts of the library
    - Clean the code and add tests and documentation
    - Still not merge
  - Also work on /mute-core/
    - A intern told us it would be neat to have tests in /mute-core/
    - Not a bad idea
    - Specially helpful for the update to the next version of /mute-structs/
    - So setup continuous integration and add tests
  - Finally investigating a bug with the digests
    - Not the same digests for same content
    - Was able to reproduce the bug
    - Retrieve as much data as possible (logs, trees, console.log...)
*** Planned
**** DONE MUTE : Utiliser *StateVector* dans *SyncMessageService*
- Auparavant, on transmettait des *Map<number, number>* lors de /querySync/ et /replySync/
- Transmettre des *StateVector* permettrait de plus contraindre les données envoyées
**** DONE MUTE : Compléter les tests pour *StateVector*
- Ajouter des tests pour :
  - /isAlreadyDelivered()/
  - /isDeliverable()/
  - /computeMissingIntervals()/
** Semaine du <2017-09-25 Mon> au <2017-09-29 Fri>
*** Done
- TEACHING : Notes sur le cours 3
  - Slide 3
    - "Mauvais pratique" d'associer 1 évènement JS à un élément HTML
      - Pourquoi ?
      - Comment faire alors ?
  - Slide 9
    - Mettre un lien vers une doc pour la syntaxe des queries ?
  - Slide 20
    - "Il faut être sûr que le dom est entièrement chargé pour enregistrer un handler"
      - Pour être sûr que le noeud existe ?
  - Slide 24
    - Faute de frappe "onlick"
- MUTE : Identifier l'origine des digests différents pour un contenu identique
  - Pourquoi ce saut de curseur ?
    - On comparant les arbres récupérés, on s'aperçoit que les arbres divergent
      #+BEGIN_SRC
                                #
                        Id[2139784055,-600040289,1, 0 .. 0]
                                #
                Id[1534008470,931389836,0, 0 .. 0]
                                #
                        Id[-233297242,-600040289,3, 11 .. 32]
                                        #
                                Id[-233297242,-600040289,3, 0 .. 10]
                                        #
        Id[-1537848274,-600040289,0, 1 .. 5]
                                #
                        Id[-1537848274,-600040289,0,0,-460848852,931389836,1, 0 .. 0]
                                #
                Id[-1537848274,-600040289,0, 0 .. 0]
                        #
----------------------------------------------
                                #
                        Id[2139784055,-600040289,1, 0 .. 0]
                                #
                Id[1534008470,931389836,0, 0 .. 0]
                                #
                        Id[-233297242,-600040289,3, 0 .. 32]
                                #
        Id[-1537848274,-600040289,0, 1 .. 5]
                                #
                        Id[-1537848274,-600040289,0,0,-460848852,931389836,1, 0 .. 0]
                                #
                Id[-1537848274,-600040289,0, 0 .. 0]
                        #
      #+END_SRC
    - Le bloc /<-233297242,-600040289, 3, [0..32]>/ est coupé en deux parties chez le collaborateur qui a reçu ces contributions
    - Les contenus sont donc identiques, mais les structures différentes
    - Les logs ne présentent aucune raison justifiant ce résultat
      - Les opérations sont correctements ordonnées, ne sont pas dupliquées
    - L'ordre des opérations dans le log ne correspond donc pas à l'ordre des opérations réellement joué
      - Ceci explique pourquoi recharger la page permet de faire converger les logs
    - Écriture d'un test pour vérifier l'ordre dans lequel les opérations sont effectivement transmises au *DocService* par le *SyncService*
      - Test disponible ici: https://github.com/coast-team/mute-core/blob/69a7ac541289e99c7d489989a15365a79e3c1fb6/test/SyncService.test.ts#L38-L66
      - Il s'avère que les opérations bufferisées sont finalement délivrées dans l'ordre inverse
      - Modification de *SyncService* pour corriger ce bug
  - Pourquoi certaines opérations sont bufferisées plusieurs fois ?
    - Il s'avère qu'on bufferise une opération si /isDeliverable()/ renvoie /false/
    - Cependant une opération n'est pas /isDeliverable()/ si elle a déjà été délivrée
    - Modification de *SyncService* pour ne bufferiser uniquement les opérations n'étant ni délivrables ni délivrées
- MUTE : Améliorer la gestion de la position des curseurs
  - /mute-core/
    - Déclaration d'une interface *Position* représentant la position dans un bloc d'un curseur
    - Renommage de /idFromIndex()/ en /positionFromIndex()/
    - Déclaration du package /sync/ dans /sync.proto/
      - Nécessaire de déclarer un package pour pouvoir importer les messages définis
  - /mute/
    - Suppression et remplacement de *MuteCorePosition* par *Position*
    - Modification de *PositionMsg* pour utiliser *IdentifierMsg*
- MUTE : Étudier la fusion de /last/ avec /base/
  - /mute-structs/
    - Ajout du getter /base()/ dans *Identifier* et *IdentifierInterval* pour préserver /mapBaseToBlock/ dans *LogootSRopes*
    - Mise à jour du code de *LogootSRopes* pour correspondre à la nouvelle implémentation de la librairie
    - Export de *IdentifierTuple* pour rendre ce type accessible aux librairies/applications externes
    - Modification du build pour seulement exclure les fichiers de tests portant sur les /logs/ et les /trees/
    - Il est finalement temps de déployer cette nouvelle version
    - Il faut donc mettre à jour /mute-core/ et /mute/
  - /mute-core/
    - Mise à jour de /generateRichLogootSOps()/ de *Helpers*
    - Mise à jour de /positionFromIndex()/ de *DocService*
    - Mise à jour de /sync.proto/
  - /mute/
    - Mise à jour des fichiers générés à partir /cursor.proto/
      - Le message *PositionMsg* dépend de *sync.IdentifierMsg*
      - Les champs de *IdentifierMsg* ayant été modifiés, il est nécessaire de regénérer les fichiers /cursor_pb.js/ et /cursor_pb.d.ts/ pour qu'ils correspondent à la nouvelle implémentation
  - Réalisation de tests
    - Les utilisateurs collaborent au travers de différents scénarios
      - On cherche à vérifier que les copies convergent
	- Observation du digest
      - On cherche à vérifier que les curseurs distants fonctionnent correctement
      - Récupération de logs si convergence, les trees en plus si divergence
    - Scénario 1
      - Tout le monde connecté tout au long de la session de collaboration
      - Document https://www.coedit.re:8080/doc/hKib6coBIh
      - A convergé
      - Digest obtenu : /clark-total-disco/
    - Scénario 2
      - Des membres du groupe se déconnecte/reconnecte au cours de la session de collaboration
      - Document https://www.coedit.re:8080/doc/3ShRFwGD0f
      - A convergé
      - Digest obtenu : /regular-chant-samba/
    - Scénario 3
      - Collaboration perturbée par des partitions
      - Document https://www.coedit.re:8080/doc/HtCcFpETan
      - A convergé
      - Digest obtenu : /classic-penguin-magic/
    - Bug observé au niveau des curseurs lors du 1er test
      - Les curseurs des autres collaborateurs n'étaient pas affichés
      - Aucune erreur n'était répertoriée dans les logs
      - Pas réussi à le reproduire
- Présentation Quentin
  - Slide 3
    - Besoin des sous-points ?
    - Tu te contentes de les lire
  - Slide 4
    - Churn -> "Random connections/disconnections"
    - Pas plutôt "Frequent connections/disconnections" ?
  - Slide 5
    - Manque la légende non ?
  - Slide 7
    - Nécessaire ?
    - J'ai l'impression qu'elle casse le rythme
  - Slide 8
    - Le numéro de la slide déconne
    - "Newcomer" tient en un seul mot
  - Slide 14
    - Pas compris ce que tu voulais mettre en avant avec les données confidentielles
  - Slide 16
    - J'ai l'impression que le schéma porte à confusion
    - Entre données accessibles et données répliquées
  - Slide 18
    - Donne des noms aux pairs pour faciliter les explications
*** Planned
**** DONE MUTE : Identifier l'origine des digests différents pour un contenu identique
- On a obtenu plusieurs fois des digests différents alors que le contenu du document semblait identique
- Recharger la page permettait de regénérer le digest attendu
- Vérifier les logs
**** DONE MUTE : Améliorer la gestion de la position des curseurs
- Pour représenter la position des curseurs distants dans /mute/, nous utilisons la position du curseur de l'utilisateur dans un bloc
- Pour obtenir cette position au sein du bloc, /mute/ interagit avec /mute-core/
- Cependant, les structures de données utilisées ne sont pas explicitement liées
  - L'interface *MuteCorePosition*, déclarée dans /cursors.directive/, n'est pas explicitement sensée correspondre au type de retour de /idFromIndex()/ de *DocService*
  - Les messages definis dans /cursor.proto/ déclarent des structures de données équivalentes à celles définies dans /sync.proto/
- Ces structures de données étant modifiées dans la nouvelle version de /mute-structs/, les lier permettrait d'effectuer la mise à jour plus aisément
**** DONE MUTE : Étudier la fusion de /last/ avec /base/
- Actuellement, dans un *Identifier*, nous conservons séparé la /base/ de /last/
- Cependant, dès que nous avons besoin de comparer des identifiants, nous concaténons /last/ à /base/
- Voir si fusionner ces deux paramètres pose un problème particulier
** Semaine du <2017-10-02 Mon> au <2017-10-06 Fri>
*** Done
- TEACHING : Notes sur le cours 4
  - Pas de mentions du système de module intégré en ES6 ?
- TEACHING : Notes sur le cours 5
  - Slide 5
    - Faire un lien entre les fonctions utilitaires de jQuery et /filter()/ et /map()/ ?
  - Slide 20
    - Retirer la zone de titre ?
- TEACHING : Notes sur le TD 1
  - Exercice 3.2
    - Leur faire utiliser /reduce()/ plutôt ?
  - Exercice 4.7
    - Pourquoi /dateNaiss.getMonth() === month-1/ dans la correction ?
- ECSCW 2017 : Payer la facture
  - Appeler le +44 114 225 5668 pour régler la facture
  - Fait
  - Pas reçu de confirmation de paiement de leur part
  - Mais le virement a du moins bien été effectué
  - Reste à apporter la preuve de paiement à Sylvie
- <<perspective-cap-theorem>> DISTRIBUTED SYSTEMS : Lire *Perspectives on the CAP Theorem*
  - La consistence est une propriété classique de /safety/
  - La disponibilité est une propriété classique de /liveness/
  - À partir du moment où les communications entre pairs sont asynchrones, il n'est pas possible de garantir la /safety/ et la /liveness/ du système
  - Exemple du registre répliqué
    - Un ensemble de serveurs /{p1, p2, ..., pn}/ permettent de manipuler un registre répliqué (lire sa valeur / modifier sa valeur)
    - Si une partition se produit, on est obligé de sacrifié la /safety/ ou la /liveness/ du système
    - Pour garantir la /liveness/ lors d'une requête de lecture, un serveur doit fournir une réponse
      - Mais comme le serveur /pi/ traitant la requête de lecture peut être coupé des autres, il ne peut être sûr de la consistence de la valeur du registre
      - Il doit alors retourner une valeur qui peut ne pas être consistente
    - Pour garantir la /safety/ lors d'une requête de lecture, un serveur doit attendre que la partition soit résolue
      - Mais la partition peut ne jamais se résoudre
      - Il ne répondrait donc jamais à la requête
  - Si les communications sont asynchrones, un pair ne peut pas faire la distinction entre le retard d'un message ou l'apparition d'une partition
  - Passe au résultat du /FLP theorem/ : le consensus est impossible dans un système pouvant avoir des pannes avec des communications asynchrones
  - Exemple du consensus
    - Le consensus et la validité sont des propriétés de /safety/
    - La terminaison est une propriété de /liveness/
    - Plus complexe que le problème du registre répliqué
    - Donc pas possible d'assurer la /safety/ et la /liveness/ en cas de partition
    - Le /FLP theorem/ montre aussi que les algorithmes de consensus garantissant la /safety/ boucle indéfiniement dans certains scénarios ou si un pair ne répond plus : perte de la /liveness/
  - 2 pistes de réflexions
    - À quel point le réseau doit-il être fiable pour pouvoir assurer la /safety/ et la /liveness/ ?
    - Quel niveau de consistence peut-on assurer si le réseau n'est pas fiable ?
  - Fiabilité du réseau
    - Utilisation d'un réseau synchrone
      - À creuser, je ne comprends pas exactement ce qu'est un réseau synchrone et comment cela fonctionne
      - Cependant, un système de détection d'erreurs offrirait les mêmes garanties qu'un réseau synchrone
      - Un système d'élection de leader équivaudrait à un système de détection d'erreurs
    - /eventual synchrony/ : un réseau peut alterner entre des phases asynchrones et des phases synchrones
    - /f + 2/ rounds (où /f/ est le nombre de noeud pouvant crasher) sont nécessaires avec un réseau synchrone pour atteindre un consensus
    - Dans un système où le réseau est /eventual synchronous/, on peut résoudre le consensus si moins de /n ÷ 2/ noeuds crashent (où /n/ est le nombre de noeuds)
  - Niveau de consistence
    - Introduction du problème du /set agreement/
      - Plutôt que d'arriver à un consensus, on renvoie ici un /k-set/ de valeurs, /k/ étant un nombre compris entre 1 et /n/ (où /n/ est le nombre de noeuds)
    - Il a été démontré que, pour résoudre le problème du /k-set/, seulement /k - 1/ erreurs ne peuvent se produire
    - Il a aussi été démontré que pour résoudre le problème du /k-set/, /t ÷ k + 1/ rounds sont nécessaires (où /t/ est le nombre d'erreurs)
  - Insiste sur la possibilité d'effectuer le compromis entre consistence et disponibilité au cas par cas dans une application selon plusieurs dimensions
    - Type de données
      - Certaines données peuvent être critiques tandis que d'autres négligeables
      - On peut donc nécessiter une forte consistence pour les données critiques et préférer une grande disponibilités pour les autres données
    - Type d'opérations
      - Même raisonnement que pour les données
      - Les opérations de lectures peuvent nécessiter une forte disponibilité tandis que les opérations de modifications requièrent une forte consistence
    - Décomposition fonctionnelle
      - On peut décomposer l'applications en sous-services, chacun effectuant son propre compromis entre consistence et disponiblité
    - Décomposition géographique / par utilisateurs
      - Idée de faire des data-centers proches des utilisateurs
      - Les noeuds d'un data-center étant proches, on peut faire des suppositions sur la fiabilité du réseau et mettre l'accent sur la consistence offerte
- <<dottedb>> DISTRIBUTED SYSTEMS : Lire *DottedDB: Anti-Entropy without Merkle Trees, Deletes without Tombstones*
  - *DottedDB* est un  /Dynamo-like key-value store/
  - Les données sont répliquées parmi un certain nombre de noeud en fonction du facteur de réplication
  - Les clients ne possèdent pas une réplique des données, ils y accèdent et les modifient par le biais des noeuds
  - Répond à 3 problèmes des bases de données répliquées
    - La croissance du /version vector/ liée au /node churn/
      - À chaque fois qu'un noeud rencontre une erreur, il est remplacé
      - Mais on conserve dans le /version vector/ l'entrée du noeud défaillant et on ajoute une nouvelle entrée pour le noeud
    - La nécessité de conserver des /tombstones/
      - Pour empêcher un objet de "ressurgir" après sa suppression, à cause de la relivraison d'une opération précédente, les systèmes actuels conservent une /tombstone/
      - Ainsi, l'espace de stockage utilisé ne peut que croître puisque supprimer un objet laisse quand même des méta-données
    - L'utilisation "lourde" de Merkle Trees pour le système d'anti-entropie
      - /Bloom Filter/ et /Merkle Trees/ sont présentées comme étant les structures de données les plus communément utilisées dans un mécanisme d'anti-entropie
      - /Bloom Filter/ est dit comme ne scalant pas en fonction du nombre de données
      - /Merkle Trees/ permet d'effectuer un compromis entre la précision du mécanisme d'anti-entropie et la quantité de méta-données échangées
	- Le mécanisme d'anti-entropie va comparer les racines des arbres des différents noeuds pour détecter une différence
	- Si une différence est détectée, on va comparer en profondeur les /Merkle Trees/ pour en trouver l'origine
	- Mais la hauteur de l'arbre dépend du nombre d'objets stockés par feuille
	- Si on stocke un objet par feuille, on aura une précision de 100% mais il faudra beaucoup de rounds pour déterminer l'origine de la différence
	- Si on stocke plusieurs objets par feuille, le nombre de rounds nécessaires est réduit mais on va potentiellement renvoyer plusieurs objets inutilement
  - Propose le framework /Node-wide Dot-based Clocks (NDC)/
    - L'idée principale est de factoriser/compacter les méta-données normalement ajoutées à chaque objet stocké en les déplaçant sur le noeud
    - Ajoute à chaque version d'un objet
      - Un /dot/ : un couple /(nodeId, nodeClock)/ identifiant la version de façon unique
      - Un /causal context/ : les dots des versions précédentes de l'objet
	- Le /causal context/ d'un objet peut être supprimé si le noeud possède toutes les versions précédentes de l'objet
    - Ajoute au niveau du noeud 4 structures de données
      - /Node Clock (NC)/
	- Liste des /dots/ (et donc versions des objets) connus par le noeud
      - /Dot-Key Map (DKM)/
	- Map associant un /dot/ à la clé d'un objet
	- Permet de retrouver l'objet divergent à partir d'un de ses /dots/ au cours du mécanisme d'anti-entropie
	- Une fois le /dot/ connu par l'ensemble des pairs, il peut être retiré de cette map
      - /Watermark (WM)/
	- Matrice des /NC/ de chaque noeud
	- Au cours du déroulément du mécanisme d'anti-entropie, un noeud envoie son /NC/ à un autre noeud
	- Celui-ci le stocke alors son /NC/ avant de pouvoir déterminer quand retirer un /dot/ de /DKM/
      - /Non-Stripped Keys (NSK)/
	- Liste des objets dont le /causal context/ n'est pas vide
	  - Possible si on a loupé des versions de l'objet
      - /Storage (ST)/
	- Map associant une clé à un objet
  - Évaluation
    - L'évaluation a été réalisé en comparant *DottedDB* à *MerkleDB*
      - *MerkleDB* un fork de *DottedDB* utilisant un /Merkle Tree/ pour le mécanisme d'anti-entropie et /Dotted Version Vectors/ comme mécanisme de traçage de la causalité
    - Taille des méta-données
      - Mécanisme de causalité
	- La taille de /NC/ de *DottedDB* augmente principalement lors de la perte de messages
	  - On peut compacter les /dots/ contigus d'un noeud en ne stockant que la /nodeClock/ la plus élevée
	  - Lorsqu'un message non-contigu est reçu, on doit alors stocker sa /nodeClock/ séparément
	  - Ces méta-données supplémentaires sont supprimées dès que les noeuds convergent
	- Tandis que la taille du /Dotted Version Vector/ dans le cas de *MerkleDB* croît avec le nombre noeuds vus, et donc avec le /node churn/
      - Anti-entropie
	- Avec *MerkleDB*, la taille des méta-données liées au système d'anti-entropie croît avec le nombre de clés (les feuilles de l'arbre)
	- Avec *DottedDB*, la taille des méta-données augmente dans le cas de divergences entre noeuds mais diminue à chaque synchronisation
	  - Une fois le système stable, seuls /NC/ (un version vector) et /WM/ (une matrice de version vectors) ne sont pas vides
	- L'empreinte réseau semble plus faible avec *DottedDB* (de 10 à 100 KB/s) comparé avec *MerkleDB* (de 100 à 700 KB/s)
  - Remarques
    - Dans ce contexte d'utilisation, il n'y a pas besoin d'obtenir toutes les versions d'un objet
    - Seule la dernière version nous intéresse
    - Comparer leur mécanisme à /causal barrier/ n'est donc pas adapté
      - On ne veut pas imposer une livraison causale des opérations
- Meeting
  - Last week
    - Solved issue in /mute-core/ which resulted in the different digests for same content
    - Caused by the delivery mechanism
    - Was delivering messages in reverse order in some particular cases
    - Deployed the version to test with 6-7 users
  - This week
    - Start the PhD !
    - Had a reunion this morning with Olivier & Gérald to discuss where to start, how to start
    - Start reading *Perspectives on the CAP Theorem*
      - Some interesting results about consensus in eventually synchrone network
	- How many failures it can support
	- How many rounds does it need
      - Some trouble to understand /synchrone network/
	- Which properties does it need to respect ?
	- How does it behave ?
	- How does it recover ?
	- Need to dig deeper on it
    - Also start reading *DottedDB: Anti-Entropy without Merkle Trees, Deletes without Tombstones*
      - Dynamo-like key-value store
      - Instead of adding all the metadata to each object, they put it in the node to be able to factorize/compact it
	- Only add a dot (a couple made of the /nodeId/ and the /nodeClock/) per version of the object
      - Compare to version vector instead of causal barrier, which is weird
	- It blames version vector for its ever-growing size
	- Which is a flaw of version vector addressed by causal barrier
*** Planned
**** DONE DISTRIBUTED SYSTEMS : Lire *DottedDB: Anti-Entropy without Merkle Trees, Deletes without Tombstones*
- Disponible ici : http://haslab.uminho.pt/tome/files/dotteddb_srds.pdf
**** DONE DISTRIBUTED SYSTEMS : Lire *Perspectives on the CAP Theorem*
- Disponible ici : https://groups.csail.mit.edu/tds/papers/Gilbert/Brewer2.pdf
** Semaine du <2017-10-09 Mon> au <2017-10-13 Fri>
*** Done
- TEACHING : Notes sur le TD1
  - Je viens de remarquer que les exercices 3 et 4 du TD1 portent sur les notions abordées dans le cours 2
  - Les retirer du TD1 ?
  - Oui, il s'agit d'un oubli
  - [X] Déplacer les exercices 3 et 4 du TD1 au TD2
  - [X] Mettre à jour le sujet du TD1 sur Arche
  - [X] Mettre un placeholder pour /min()/ et /max()/ dans e1.js
  - [X] Mettre à jour le squelette HTML sur Arche
  - [X] Déposer le sujet du TD2 sur Arche
- <<dynamo>> DISTRIBUTED SYSTEMS: Lire *Dynamo: amazon’s highly available key-value store*
  - *Dynamo* est un key-value store décentralisé fortement disponible
    - Sacrifie la consistence pour assurer cette disponibilité
  - Laisse à l'application la possibilité de tweaker le compromis entre consistence et disponibilité
  - Les données sont partitionnées et répliquées en utilisant /consistent hashing/
  - Un /version vector/ est attaché à chaque version d'un objet
  - *Dynamo* permet de répondre aux besoins suivants
    - Système simple de requêtes
      - Généralement besoin de récupérer ou de mettre à jour une valeur associée à une clé
      - Pas besoin d'un système relationnel ou de pouvoir effectuer une requête sur un ensemble d'objets
      - Pas besoin non plus d'un mécanisme de transactions
	- Ceci nuirait à la disponibilité du système, mais offrirait une plus grande consistence
    - Hautes performances
      - Les services reposant sur *Dynamo* devant fournir une réponse rapide aux clients, *Dynamo* se doit d'être efficace pour ne pas nuire aux performances des applications
      - C'est d'autant plus vrai que la réponse à la requête d'un client peut être composée des résultats de plus de 150 services
    - Flexible
      - Ajouter/retirer un noeud doit pouvoir être fait facilement et ne pas impacter les performances du système
    - Symétrie
      - Chaque noeud doit avoir le même rôle, afin de ne pas complexifier le système
    - Compatible avec l'hétérogénité des noeuds
      - Les noeuds peuvent disposer d'une puissance de calcul différente
      - Il faut donc que *Dynamo* permette de répartir la charge efficacement sur les différents noeuds en fonction de leurs ressources
    - Hypothèses
      - /Amazon/ déployant et manageant ses instances de *Dynamo*, on considère que l'environnement est non-hostile
  - Pour augmenter la disponibilité du système, repose sur des mécanismes de réplication optimiste
  - Mais nécessité de résoudre les conflits à un moment donné, lors du /read/ ou du /write/
  - Ils expliquent que le mécanisme de résolution de conflits peut faire échouer l'opération si il est executé lors du /write/, notamment dans le cas d'une partition réseau
    - De quel mécanisme de résolution de conflits parlent-ils ?
  - Pour ne pas perdre d'opérations d'utilisateurs, ils déplacent donc la résolution de conflits sur l'opération de /read/
  - Nécessité aussi de déterminer qui se charge de résoudre les conflits : l'application ou le système
    - *Dynamo* propose des mécanismes de résolution de conflits par défaut (LWW par exemple)
    - Mais permet à l'application d'utiliser son propre mécanisme à la place
  - API du système
    - /get(key)/
      - Détermine les noeuds possédant une réplique de l'objet
      - Récupère chaque version de l'objet ainsi que leur contexte respectif
      - Renvoie la ou les versions de l'objet ainsi que les contextes
    - /put(key, context, object)/
      - Détermine les noeuds auxquels ils faut fournir une réplique de l'objet
      - Stocke la nouvelle version de l'objet ainsi que le contexte attaché dans chacun de ces noeuds
  - Partitionnement des données
    - Repose sur /consistent hashing/
    - Les noeuds sont placés sur un anneau
    - Les clés, grâce à une fonction de hash, sont mappés à une position /p/ sur cette anneau
    - Les /N/ premiers noeuds se trouvant après la position de la clé vont se voir assigner l'objet à répliquer, /N/ étant le /replication factor/
    - Lorsqu'un nouveau noeud est démarré
      - Son arrivée décale le rang/classement des autres noeuds par rapport à une position donnée et donc par rapport à une clé
      - Les noeuds qui "perdent" la responsabilité de clés et d'objets suite à ce déclassement transmettent ces données au nouveau noeud
    - Possibilité d'utiliser des noeuds virtuels
      - Possibilité de générer un ou plusieurs noeuds virtuels par noeud physique
      - Permet ainsi de répartir la charge plus équitablement entre des noeuds ayant des ressources différentes
    - Notion de /coordinator/
      - Le noeud le plus proche de la position d'une clé est le /coordinateur/
      - C'est lui qui se charge de répliquer l'objet sur les /N-1/ noeuds suivants
    - Notion de /preference list/
      - La /preference list/ répertorie les noeuds en charge de stocker un objet
      - Chaque noeud du système peut générer/obtenir cette liste pour une clé donnée
      - La /preference list/ contient en fait plus que /N/ noeuds, afin de résister aux pannes
  - Versionnement
    - Pour un même objet, plusieurs versions peuvent être stockés
      - Exemple du panier d'un client (/v0/)
      - Si un client met à jour son panier (/v1/) mais qu'une partition réseau empêche les noeuds de se synchroniser
      - Il est possible que la prochaine lecture renvoie une version dépassée (/v0/)
      - Puisqu'on souhaite ne perdre aucune modification effectuée par le client, le client doit pouvoir continuer de mettre à jour le panier (/v1'/)
      - L'ensemble de ces versions pourront être récupérées lors d'une prochaine opération /get()/, si la partition réseau est resolue
    - Un /vector clock/ est attaché à chaque version de l'objet (dans son contexte)
    - En comparant les /vector clocks/, le système est capable de déterminer si des versions sont causalement dépendantes ou concurrentes
    - Le système peut ainsi rejeter une version dépassée si elle est tout de même retournée par /get()/
    - Pour éviter que le /vector clock/ ne croisse indéfiniement, sa taille est limitée à 10 entrées
      - À chaque pair /node, clock/, un timestamp est associé
      - Lorsque le /vector clock/ atteint sa taille limite, on retire l'entrée correspondante au timestamp le plus ancien
      - Peut perdre des informations de causalité à cause de ce troncage
      - Mais ce risque est mitigé, puisque ce sont les /coordinators/ qui sont chargés normalement de faire les mises à jour de l'objet
      - Les entrées les plus anciennes ont donc de grandes chances de correspondre à des noeuds de back-up
  - Mécanisme de cohérence
    - *Dynamo* utilise un protocole similaire à ceux utilisé pour les quorums, d'après le papier
    - Ce protocole possède deux variables
      - /R/: Le nombre de noeuds minimum nécessaire pour effectuer une opération de lecture
      - /W/: Le nombre de noeuds minimum nécessaire pour effectuer une opération d'écriture
    - Si on a /R + W > N/ (où /N/ est le nombre de noeuds), on obtient un système /quorum-like/
    - Pour des raisons de performances, généralement /R/ et /W/ sont inférieurs à /N/
  - /Hinted Handoff/
    - Afin de tolérer les pannes, une écriture ne se fait pas sur les /N/ premiers noeuds de la /preference list/ mais les /N/ premiers noeuds en vie (où /N/ est le /replica factor/)
    - Si un noeud de back-up reçoit une écriture (à cause d'une panne par exemple), une méta-donnée indiquant le destinataire initial y est ajoutée
    - Périodiquement, ce noeud va vérifier s'il peut transmettre au destinataire initial l'écriture
  - Anti-entropie
    - Repose sur un /Merkle Tree/
    - Chaque noeud possède un /Merkle Tree/ contenant les objets appartenant à un /key range/, pour chaque /key range/ auquel il appartient
    - Puisqu'on repose sur /consistent hashing/, ce nombre correspond au /replication factor/
  - Membership
    - Démarrer/Arrêter un noeud sont des opérations manuelles
    - Chaque noeud a la liste des noeuds du système
    - Lorsqu'un nouveau noeud est démarré, un noeud est chargé de mettre à jour la liste des noeuds du système
    - Via un algorithme de /gossiping/, cette modification est transmises aux autres noeuds
    - Les données indiquant à quelle partition de l'anneau un noeud appartient sont aussi transmises en parallèle via le même mécanisme
  - Seed
    - Pour éviter que des partitions logiques ne soient créées (démarrage de 2 noeuds en concurrence), des noeuds font jouer le rôle de seed
    - Les seeds sont découverts par un moyen alternatif
  - Détection de panne
    - Dès qu'un noeud B ne répond plus aux messages du noeud A, A en déduit que B rencontre une panne
    - A va ensuite recontacter B périodiquement pour vérifier s'il la panne est résolue
  - Stratégies de partitionnement avec /consistent hashing/
    - Pour assurer une répartition uniforme de la charge sur les différents noeuds, /Amazon/ a étudié plusieurs méthodes de partitionnement de l'anneau
    - Stratégie 1 : /T random tokens per node and partition by token value/
      - Stratégie naïve décrite précédemment
      - Problème du bootstrapping
	- Au démarrage, un noeud doit "voler" des clés aux autres noeuds
	- Mais pendant ce temps, ces noeuds doivent toujours assurer leurs tâches
	- Cet échange de clé doit donc se faire en tâche de fond et avec une faible priorité
	- Ceci a conduit à des scénarios où un noeud mettait 1 journée pour démarrer
      - Problème de la regénération du /Merkle Tree/
	- Lors de l'arrivée ou du départ d'un noeud, les groupes de clés gérés par l'ensemble des noeuds changent
	- Il faut donc regénérer les /Merkle Trees/ en conséquence
	- Cette tâche peut s'avérer gourmande en ressource
      - Problème de l'archivage
	- Les clés étant éparpillés sur les différents noeuds de façon aléatoire, il n'y avait pas de moyen simple de faire un snapshot
	- Le seul moyen consistait à contacter chacun des noeuds pour récupérer les clés
      - Problème du couplage entre /data partitioning/ et /partition placement/
	- Insérer des noeuds modifient le partitionnement de l'anneau et provoquent des transferts de données, ce qui génère de la charge supplémentaire
    - Stratégie 2 : /T random tokens per node and equal sized partitions/
      - Divise l'anneau en /Q/ partitions de même taille
	- Avec /Q >> N/ où /N/ est le /replication factor/
	- Avec /Q >> S*T/ où /S/ est le nombre de noeuds et /T/ le nombre de tokens par noeud
      - Permet de découpler le nombre de partitions de leur placement
      - Des partitions peuvent ne pas avoir de noeud d'assigné
    - Stratégie 3 : /Q/S tokens per node, equal-sized partitions/
      - Divise l'anneau en /Q/ partitions de même taille
      - Chaque noeud se voit attribuer /Q / S/ tokens au démarrage
	- Il peut les voler aux autres noeuds
      - Ces tokens sont redistribués aux autres noeuds à son départ
      - Offre les meilleures performances de /load balancing/
      - Puisque les partitions sont connues, peut facilement conserver la liste des clés pour chacune d'entre elles
      - Permet un bootstrapping plus performant (pas besoin de récupérer la liste des clés en contactant chaque noeud)
      - Permet du coup de faire des snapshots du système pour archiver l'ensemble des données
      - Par contre, plus difficile à gérer pour maintenir les bonnes propriétés
  - Remarques / Questions
    - Méta-données
      - /vector clock/
	- *Dynamo* ajoute un /vector clock/ est attaché à chaque version d'un objet
	- À chaque entrée du /vector clock/, un timestamp est aussi associé
	- Sa taille est limitée à 10
	  - Dès qu'elle dépasse 10, l'entrée la plus ancienne est retirée
      - /Merkle Trees/
	- *Dynamo* doit conserver un /Merkle Tree/ pour chaque /key range/ auquel il appartient
	- Ce nombre correspond au /replication factor/
	- La taille de chaque /Merkle Tree/ dépend directement du nombre d'objets stockés dans le système
      - Membership
	- Chaque noeud doit conserver la liste des noeuds du système
	- Il doit aussi pouvoir récupérer la /preference list/ pour chaque clé
    - /Garbage collection/
      - Ne mentionne pas de mécanisme de /garbage collection/
      - Mais qu'y aurait-il à supprimer ?
    - Mécanisme de résolution de conflits
      - Ils expliquent que le mécanisme de résolution de conflits peut faire échouer l'opération si il est executé lors du /write/, notamment dans le cas d'une partition réseau
      - De quel mécanisme de résolution de conflits parlent-ils ?
    - Ajout/Suppression de noeud
      - Le papier explique qu'il faut ajouter un round de confirmation à la suite du transfert de clés lors de l'ajout d'un noeud pour éviter que des objets ne soient transférés en double
      - Comment ce scénario est-il possible ?
      - Voir si /consistent hashing/ aborde ce problème
    - Tombstones
      - Il n'y a aucune mention de tombstones dans le papier
      - D'un autre côté, il n'y a pas d'opération /delete()/
      - Pour supprimer un objet, est-ce qu'ils ne génèrent pas une nouvelle version vide de l'objet avec /put()/ ?
*** Planned
**** DONE DISTRIBUTED SYSTEMS: Lire *Dynamo: amazon’s highly available key-value store*
- *DottedDB* ([[dotteddb]]) est une base de données clé-valeur /Dynamo-like/
- Lire ce papier me permettrait p-e de mieux comprendre *DottedDB*
- Disponible ici : https://dl.acm.org/citation.cfm?id=1294281
** Semaine du <2017-10-16 Mon> au <2017-10-20 Fri>
*** Done
- <<dotted-version-vector>> DISTRIBUTED SYSTEMS : Lire *Scalable and Accurate Causality Tracking for Eventually Consistent Stores*
  - Propose une nouvelle /logical clock/ : /Dotted Version Vectors/
  - Modèle du système
    - /dynamo-like key-value store/
    - API du système
      - /get(key)/
	- Renvoie un tuple /(version(s), context)/
      - /put(key, value, context)/
	- Le /context/ doit contenir suffisamment d'informations pour pouvoir établir la relation /happen-before/ entre 2 opérations
    - Système distribué où les noeuds communiquent par le biais de messages asynchrones
    - Nb clients >> Nb noeuds
    - Nb noeuds >> /replication factor/
    - Pas d'affinités entre clients et noeuds
      - Les requêtes successives d'un client peuvent s'exécuter sur des noeuds différents
    - Pas de /byzantine failures/
      - Les noeuds peuvent rencontrer une panne mais arriveront par la suite à se rétablir dans un état consistent
  - *Les structures de données présentées correspondent qu'à une seule clé du /key-value store/*
    - Il faut en construire et maintenir une *pour chaque objet* du système
  - Problèmes adressés
    - Besoin d'attacher une horloge logique aux écritures pour détecter la causalité et la concurrence des différentes opérations
    - Les mécanismes d'horloges logiques existants ne scalent pas
      - Par exemple, dans /version vectors/, on stocke une entrée par replicas
      - La taille du vecteur croît donc de façon linéaire avec le nombre de replicas
    - Pour pallier à ce problème, certains systèmes choisissent de retirer au cours du temps des informations de l'horloge afin de conserver une taille constante
      - Voir [[dynamo]]
  - /Dotted Version Vectors/
    - Notée /dvv/
    - /dvv = ((i, n), v)/ où
      - /i/ représente l'identifiant du replica
      - /n/ représente la valeur du compteur du replica /i/
      - /v/ représente le /version vector/ correspondant au contexte causal de l'opération
	- Pour /dvv = ((i, n), v)/, /v[i] = n - 1/
    - Indique ainsi l'entrée du /version vector/ qui a été mise à jour
    - Permet de conserver les informations de causalité nécessaires pour comparer 2 versions et déterminer si elles sont concurrentes ou si une l'emporte sur l'autre
    - Permet de comparer deux horloges en temps constant (au lieu d'en temps linéaire pour les /version vectors/)
      - /((i, n), u) < ((j, m), v)/ si /n <= v[i]/)
      - si /!(dvv < dvv') && !(dvv' < dvv)/, les deux évènements sont concurrents
  - Cependant, dans les applications, on va se retrouver à conserver et à traiter plusieurs versions concurrentes d'un même objet
  - Chacune de ces versions concurrentes va conserver un /dvv/
    - /{ (dvv1, vers1), (dvv2, vers2), ... }/
  - Pour éviter de dupliquer inutilement des informations, ils proposent une structure adaptée pour gérer ce cas de figure : /Dotted Version Vectors Set/
    - Notée /dvvs/
    - /dvvs = { (i, n, [vers1, vers2]), (j, m, [vers3]), ... }/
    - Permet de factoriser les dots des opérations concurrentes effectuées sur le même noeud
    - La position de la /vers/ dans la liste permet de déterminer son /dot/
      - Dans l'exemple précédent, on a :
	- le /dot/ de /vers1/ est /(i, n)/
	- le /dot/ de /vers2/ est /(i, n-1)/
	- le /dot/ de /vers3/ est /(j, m)/
  - Propose un framework pour traiter les opérations /get()/ et /put()/ en se basant sur les horloges logiques
    - Ce framework propose 4 opérations
      - /sync()/ :
	- Prend en paramètres deux sets de clocks
	- Renvoie un nouveau set composé uniquement des clocks n'étant pas obsolètes
      - /join()/ :
	- Prend en paramètre un set de clocks
	- Renvoie une nouvelle clock correspondant au contexte commun de toutes les clocks du set initial
      - /discard()/ :
	- Prend en paramètre un set de clocks /S/ et une clock /C/
	- Supprime de /S/ toutes les clocks qui sont couvertes par /C/
      - /event()/ :
	- Prend en paramètre un set de clocks /S/, une clock /C/ et un identifiant de noeud /r/
	- Renvoie une nouvelle clock (ne rentrant pas en conflit avec S), l'emportant sur C, représentant la nouvelle version
    - Traitement de /get(key)/
      - Récupère les différentes versions de l'objet auprès des replicas
      - Les fusionne au besoin en appliquant /sync()/ 2 à 2
      - Ne conserve que leur contexte causal commun avec /join()/
      - Renvoie un tuple /(version(s), context)/
    - Traitement de /put(key, value, context)/
      - Le noeud traitant la requête /put()/ effectue les opérations suivantes
	- Il supprime ses versions de l'objet rendues obsolètes par le nouveau contexte
	- Génère une nouvelle clock /c/ grâce à /event()/
	- Ajout de l'entrée /(c, value)/ dans le set des versions courantes de l'objet
      - Il obtient en résultat de ce traitement un nouveau set /S/ des versions courantes de l'objet
      - Il transfère alors /S/ aux autres réplicas
      - Ces derniers utilisent alors /sync()/ pour mettre à jour leur(s) version(s) de l'objet
  - Évaluation
    - Ils ont comparé /Dotted Version Vectors/ et /Dotted Version Vectors Set/ avec d'autres mécanismes (/LWW/, /VV/)
      #+CAPTION: Évaluation de Dotted Version Vectors
      #+NAME:   fig:dotted-vv-evaluation
      [[file:img/dotted-vv-evaluation-org.png]]
    - Intéressant de noter que la complexité de /dvv/ et de /dvvs/ croît linéairement avec le nombre de réplicas /R/ et le nombre de versions concurrentes /V/
    - Alors que /vv/ croît de façon linéaire avec le nombre de clients /C/ et de façon quadratique avec le nombre de versions concurrentes /V/
- Réunion mécanismes de gestion de clés de groupe
  - n-party DH
    - Dispose en anneau les noeuds
    - Les noeuds conviennent d'un générateur /g/
    - Les noeuds disposent d'un secret
    - 1er round
      - Les noeuds mettent successivement à l'exponentielle le générateur
	- Le noeud A va calculer /g^a/ puis va transmettre la valeur au noeud B qui va calculer /g^ab/
      - Lorsque le dernier noeud E reçoit la valeur intermédiaire, on passe au round 2
    - 2nd round
      - Le noeud E broadcast la valeur /g^abcd/
      - Chaque noeud va retirer son exponentielle de la valeur et la retourner à E
	- Le noeud A va renvoyer /g^bcd/ par exemple
    - 3ème round
      - Le noeud E va mettre à l'exponentielle toutes les valeurs reçues dans le round précédent et renvoyer la valeur au noeud correspondant
	- Il va calculer /g^bcde/ et envoyer cette valeur au noeud A
      - Le noeud A peut alors remettre à l'exponentielle cette valeur avec son secret pour obtenir la clé de groupe
  - Version centralisée
    - Génère une clé de groupe via une fonction /f(K1, K2)/
    - /K1/ n'est connue que des membres du groupe
    - Ajoute un serveur tiers qui a pour responsabilité de générer /K2/
    - Les membres de groupe ont la possibilité de récupérer /K2/ en effectuant une requête à ce serveur
    - Le serveur peut récupérer les clés
    - Lors d'un changement du groupe, /K2/ doit être modifiée pour assurer la confidentialité des prochains messages
    - Le serveur ne doit jamais avoir accès à /K1/ pour pas qu'il ne puisse obtenir la clé de groupe
    - Nécessaire de mettre en place un mécanisme de /membership/
      - Pour que le serveur puisse s'assurer qu'un utilisateur ait le droit de récupérer /K2/
      - Par exemple, un utilisateur peut obtenir /K1/ en étant invité à une collaboration sur un document
      - Si il est exclus par la suite, il ne doit plus pouvoir générer la clé de groupe
      - Il doit donc ne plus avoir accès aux valeurs de /K2/ pour ce document
- Meeting
  - Read *Scalable and Accurate Causality Tracking for Eventually Consistent Stores* (DAIS, 2014)
    - Introduce /Dotted Version Vector (dvv)/
      - Logical clock to track causality of the versions of an object
      - Achieve better scaling than /Version Vectors/ without sacrifying causality
    - Introduce /Dotted Version Vector Set (dvvs)/, an optimized data structure to manage several concurrent versions of an object
      - Since applications usually have to keep several concurrent versions
    - Propose a framework to serve /get/ and /put/ requests in /Dynamo-like key-value stores/
      - Composed of several kernel operations relying on a logical clock
      - Implement these operations for /dvv/ and /dvvs/
*** Planned
**** DONE DISTRIBUTED SYSTEMS : Lire *Scalable and Accurate Causality Tracking for Eventually Consistent Stores*
- Ce papier propose une nouvelle /logical clock/, /Dotted Version Vectors/, permettant de capturer la causalité des opérations dans un système distribué
- Cette clock serait plus scalable que les solutions existantes telles que les /version vectors/ sans sacrifier les informations de causalité
** Semaine du <2017-10-23 Mon> au <2017-10-27 Fri>
*** Done
- TEACHING : TD3
  - [X] Préparer le TD3
    - [X] Mettre à jour la correction pour ES6
    - [X] Utiliser des noms plus explicites pour les classes
    - [X] Faire un squelette pour les étudiants
    - [X] Voir si certaines consignes d'exercices doivent être retravaillées
      - Ajout d'un exercice pour commencer à ajouter des handlers avant de manipuler les classes
      - Ajout de /rappels/ pour leur donner des indices
  - [X] Voir si certaines slides ont besoin d'être retravaillées
    - Modification de l'ordre des slides sur la sélection d'élements dans le *DOM*
      - Déjà avec /getElementById(), .../, ensuite avec /querySelector()/
    - Ajout d'une slide dédiée aux /CSS Selectors/
    - Découpage de la slide sur le parcours du *DOM* en plusieurs
  - [X] Déposer les ressources sur Arche (Cours, TD, Squelette)
- <<interval-tree-clock>> DISTRIBUTED SYSTEMS : Lire *Interval Tree Clocks: A Logical Clock for Dynamic Systems*
  - Propose une nouvelle /logical clock/ : /Interval Tree Clock/
  - Problèmes adressés
    - Dans les systèmes distribués dynamiques, le groupe de participant n'est pas fixe
    - Au fur et à mesure, de nouveaux participants vont rejoindre le groupe tandis que d'autres vont le quitter
    - Les mécanismes de causalité existants gèrent mal ce /churn/
      - /Version Vector/ va conserver ad vitam æternam une entrée pour chaque noeud
      - Certains systèmes comme [[Dynamo]] tronquent les /version vectors/ pour conserver une taille fixe
      - Mais ceci entraîne une perte d'informations de causalité qui peut ainsi conduire à la répétition d'une ancienne opération
      - Des travaux ont tenté de répondre au problème de la suppression des noeuds inactifs, sans succès
	- Certains mécanismes utilisent un /agreement/ au niveau du groupe pour déterminer si l'on peut supprimer une entrée de l'horloge
	- Mais il ne suffit alors que d'un seul noeud défaillant pour qu'on ne puisse plus supprimer d'entrées
  - /Fork-Event-Join Model/
    - Représente les mécanismes de causalité à l'aide des opérations /fork/, /event/ et /join/ qui s'appliquent sur des /stamps (logical clocks)/
    - /logical clock/
      - De la forme /(i, e)/ où
	- /i/ représente l'identifiant de l'utilisateur et de son horloge logique
	- /e/ représente les informations de causalités connues
      - Pour comparer 2 horloges logiques, on compare leurs informations de causalité
	- Un ordre partiel doit être établi pour comparer 2 contexte causal : /(E, ≤)/
    - /fork/
      - Permet de générer une nouvelle /clock/ à partir d'une autre
      - /fork(i, e) = ((i1, e), (i2, e))/ avec /i1 ≠ i2/
	- Généralement /i1 = i/
	- /i2/ est une nouvelle identité
    - /peek/
      - Cas particulier de /fork/
      - Permet de créer un snapshot d'une clock
      - Génère une clock anonyme immutable
      - /peek(i, e) = ((i, e)(0, e))/ où /0/ est une identité "null"
      - Permet d'attacher cette clock à des messages ou faire des snapshots pour débugger
    - /event/
      - Permet de faire avancer une clock en faisant évoluer son contexte causal /e/
      - /event(i, e) = (i, e')/ avec /e < e'/
      - Le nouveau contexte causal /e/ ne doit ni dominé ni être dominé par des contextes concurrents
	- si /e1 ≰ e2/ alors /e1' ≰ e2/
	- si /e2 ≰ e1/ alors /e2 ≰ e1'/ avec /e1' ≠ e2/
    - /join/
      - Fusionne deux clocks en une nouvelle
      - /join((i1, e1), (i2, e2)) = (i3, e3)/ avec
	- /e1 ≤ e3/ et /e2 ≤ e3/
	- /e3/ ne doit ni dominé ni être dominé par des contextes concurrents
      - L'identité obtenue doit être fonction des identités fournies et doit de nouveau être unique
	- /i3 = f(i1, i2)/
	- Généralement, on se contente de réutiliser une des identités fournies en paramètre
	  - /f(i1, i2) = i1/ par exemple
	- Mais on peut utiliser une fonction plus complexe, notamment si on souhaite pouvoir recycler les identifiants
      - Cas particuliers
	- /join((i1, e1), (0, e2)) = (i1, e3)/ représente la réception d'un message
	- /join((0, e1), (0, e2)) = (0, e3)/ représente l'aggrégation de messages
    - Les opérations classiques des systèmes peuvent ainsi être composées à partir de ces opérations élémentaires
    - /send/
      - Se décompose en un /event/ suivi d'un /fork/
      - /send(i, e) = ((i, e'), (0, e'))/
    - /receive/
      - Se décompose en un /join/ suivi d'un /event/
      - /receive((i, e1), (0, e2)) = (i, e3')/
	- /event(join((i, e1), (0, e2))) = event(i, e3)/
    - /sync/
      - Se décompose en un /join/ suivi d'un /fork/
      - /sync((i1, e1), (i2, e2)) = ((i1, e3), (i2, e3))/
	- /sync((i1, e1), (i2, e2)) = fork(join((i1, e1), (i2, e2)) = fork(f(i1, i2), e3) = ((i1, e3), (i2, e3))/
  - /Function space based Clock Mechanisms/
    - On dispose d'une fonction O tel que /O(x) = 0/
    - L'idée est d'utiliser une fonction charactéristique /i/ comme identité
      - /i(x) = 1 ∀x ∈ A, A ⊂ dom(f)/
      - /i(x) = 0 sinon/
    - L'identité permet de déterminer l'ensemble des entrées du contexte causal que l'on peut incrémenter lors d'un évènement
      - Les entrées d'un /vector clock/ par exemple
    - La fonction servant d'identité doit donc satisfaire plusieurs contraintes
      - /∀i1 ≠ i2, i1 * i2 = O/
      - Concrètement, aucun autre utilisateur ne doit pouvoir modifier la même entrée que moi dans le contexte causal
    - On peut ainsi redéfinir les opérations élémentaires avec cette nouvelle fonction servant d'identité
    - /join/
      - /join((i1, e1), (i2, e2)) = (i1 + i2, e1 ∪ e2)/
      - Fusionner 2 clocks permet d'obtenir une nouvelle identité correspondant à la composition de /i1/ et /i2/
      - Au cours d'un prochain /event/, on pourra donc incrémenter une ou plusieurs entrées du contexte couvertes par /i1/ et /i2/
    - /fork/
      - /fork(i, e) = ((i1, e), (i2, e))/ avec
	- /i = i1 + i2/
	- /i1 * i2 = O/
      - On répartit la responsabilité des éléments du contexte entre les nouvelles identités
      - On s'assure qu'aucun élément du contexte ne peut être modifié par chaque nouvelle identité
    - /peek/
      - /peek((i, e)) = ((O, e), (i, e))/
      - Comme /O/ renvoie 0 pour n'importe quelle valeur, la clock /(O, e)/ ne peut donc pas produire d'évènements
    - /event/
      - /event((i, e)) = (i, e + f * i)/
	- Avec /f/ une fonction telle que /f * i ⊃ O/
	- C'est à dire que /range(f * i) = {0, 1}/
	  - /f ⊃ g/ signifie que /range(f) ⊃ range(g)/
  - /Interval Tree Clocks/
    - Représente /id/ à l'aide d'un arbre
      - /(1, (0, 1)/ est un exemple d'identité valide
    - Représente /e/ à l'aide un arbre binaire valué
      - /(0, (0, 0, 0), 1) est un exemple de contexte valide
    - Dispose d'une fonction /norm/ permettant de simplifier les arbres binaires
      - Essaie de remonter les valeurs des feuilles dans les noeuds supérieurs pour pouvoir à terme représenter l'arbre à l'aide d'un entier
      - Exemples
	- /norm((2, 1, 1)) = 3/
	- /norm((2, (2, 1, 0), 3)) = (4, (0, 1, 0), 1)/
    - Essaie au maximum de limiter la taille des arbres
      - Lors d'un /event/, en fonction de l'identité de l'utilisateur
	- Essaie de combler les "trous" de l'arbre de façon à pouvoir le normaliser
	- Ou alors incrémente un des noeuds les plus proches possibles de la racine
      - Lors d'un /join/, normalise l'arbre
  - Remarques
    - Faiblesses du système d'identités
      - Le mécanisme d'identité repose sur un espace qui va être au fur et à mesure divisé et partagé entre les participants
      - Il est nécessaire qu'un utilisateur divise l'espace qui lui est alloué pour qu'un autre utilisateur puisse obtenir une identité
      - Concrètement, plusieurs façons de fournir l'identité au nouveau participant
	- Un utilisateur doit être présent au moment où le nouveau participant se connecte pour lui donner une identité
	  - Problème de disponibilité, un utilisateur doit toujours être présent
	- L'identité est fournie dans le lien de l'invitation
	  - Problème d'usabilité, chaque utilisateur doit être invité via un lien unique
      - Nécessaire de répartir la responsabilité d'attribuer une identité
	- À chaque attribution d'identité à un nouvel utilisateur, un ancien utilisateur disponible divise en 2 son espace d'identifiants et en donne la moitié au nouvel arrivant
	- En fonction de l'espace utilisé pour les identifiants, on peut rapidement arriver à un point où un utilisateur n'a plus la possibilité de diviser son identité
	- Si un utilisateur devient indisponible, il scelle tout un espace d'identifiants et réduit le nombre de participants possibles
	- C'est d'autant plus vrai si l'utilisateur fait partie des premiers participants
    - Pour normaliser l'arbre des évènements et ramener sa représentation à un entier
      - Il est nécessaire que chaque utilisateur effectue le même nombre d'opérations depuis le dernier /fork/
      - Plus le nombre d'utilisateurs est conséquent, plus cela semble difficilement atteignable
    - Différences entre /vector clocks/ et /version vectors/
      - /vector clock/ identifie un évènement
      - /version vector/ identifie l'état sur lequel s'est appliqué l'évènement
    - Du mal à voir à quoi on pourrait transposer ce mécanisme de récupération des identifiants et ce que ça apporterait
    - Dans *LogootSplit*, récupérer des identifiants nous permettrait de pouvoir réutiliser blocs existants
      - Plutôt que de générer de nouveaux blocs lors d'insertions, on pourrait effectuer des appends/prepends
      - Le gain semble alors plutôt faible comparé au coût nécessaire pour mettre en place la solution
	- L'utilisation et la gestion d'un arbre binaire pour représenter l'identité des utilisateurs
      - Si on arrive à mettre en place un mécanisme de fusion des blocs basé sur l'ownership, ça pourrait devenir intéressant
    - À voir si d'autres CRDTs profiteraient davantage de ce mécanisme
- Meeting
  - Read *Interval Tree Clocks: A Logical Clock for Dynamic System*
    - Present a new logical clock : /Interval Tree Clock/
    - Adress several issues of logical clocks
      - No need for a global id
      - Can retire id and reuse them
      - Size of the data structure grows and shrinks according to the numbers of users
    - Use binary trees as identity and the actual clock
      - Increase the depth of the identity tree when adding a user
      - Decrease it when a user leave
      - Each user can only update a precise part of the clock tree according to its identity
    - Some questions left
      - On which conditions does the clock shrink ?
      - Can we determine the numbers of events separating two clocks ?
	- Would be useful to compare my clock to the one attached to a message
	- If yes, could be use as it is in operation-based systems
	- Otherwise, would have to store the last seen ITC of each user and replay the inflation to ensure FIFO delivery
	- Anyway can use it in state-based systems
*** Planned
**** DONE DISTRIBUTED SYSTEMS : Lire *Interval Tree Clocks: A Logical Clock for Dynamic Systems*
- Disponible ici : http://gsd.di.uminho.pt/members/cbm/ps/itc2008.pdf
** Semaine du <2017-11-02 Thu> au <2017-11-03 Fri>
*** Done
- MUTE : Préparer la démo pour la réunion avec Marius Shekow
  - Répétition du scénario pour ECSCW 2017
    - Des utilisateurs répartis sur 2 réseaux collaborent sur un document
    - Une partition se produit, coupant le groupe en 2 sous-groupes
    - Ils continuent à collaborer en local
    - Puis la partition se résout
    - L'ensemble des modifications est partagé entre les sous-groupes
    - Tout le monde converge
  - Fonctionne toujours
- CONSENSUS : Lire *The part-time parliament*
  - J'ai commencé à lire le papier
  - Il s'avère plutôt compliqué
  - Guillaume m'a suggéré de chercher des articles traitant de Paxos plutôt que d'essayer de décortiquer le papier
  - Ça me paraît être une bonne idée
- <<2pc>> CONSENSUS : Two-phase commit (2PC)
  - En parcourant des articles sur [[paxos]], je suis tombé sur des articles traitant de 2PC
    - 2PC s'avère être un cas particulier de Paxos
  - Autant prendre notes sur le sujet tant que j'y suis
  - Problème adressé
    - Problème du consensus
      - Faire en sorte qu'un ensemble de noeuds d'un système distribué s'accordent sur une valeur, une action ou autre
    - Possibles utilisations
      - Décider de valider ou d'abandonner une transaction dans une base de données distribuée
      - Élire un leader
      - Avancer à la prochaine étape d'un algorithme distribué (/replicated state machine/ approach)
    - Mais le consensus est connu comme étant impossible à obtenir dans le cas d'un système avec réseau asynchrone si les noeuds peuvent tomber en panne
      - Voir FLP theorem
  - Formalisation
    - Safety properties
      - Agreement : Chaque noeud du système choisit la même valeur
      - Validity : La valeur choisie a été proposée par un des noeuds
    - Liveness property
      - Termination : Chaque noeud prend finalement une décision
  - Protocole
    - Un noeud a le rôle de coordinateur
      - C'est lui qui va s'assurer du bon déroulement du protocole
      - Le noeud coordinateur n'a pas besoin d'être élu, n'importe quel noeud peut spontanément démarrer un 2PC
    - Les autres noeuds jouent le rôle de participants
    - Le protocole se décompose en 2 étapes
    - 1. Proposition
      - Le coordinateur propose une valeur à l'ensemble des participants
      - Les participants renvoie au coordinateur leur réponse
	- Un simple booléen pour indiquer si oui ou non le noeud accepte cette valeur
    - 2. Validation ou abandon
      - Si le coordinateur reçoit une réponse favorable de la part de chaque participant
	- Il indique à l'ensemble des participants que la valeur a été choisie
      - Sinon abandonne le 2PC
  - Limites
    - Comme dit précédemment, le consensus n'est pas possible si un des noeuds peut tomber en panne
    - Ce résultat s'applique ici aussi
    - On rencontre plusieurs problèmes, principalement de terminaison, en fonction du rôle du noeud qui tombe en panne et du moment de la panne
    - Le coordinateur tombe en panne au cours de la phase 1, alors qu'il envoyait les propositions
      - Seulement un sous-ensemble des participants reçoivent la proposition et votent
      - Ces derniers se retrouveront alors bloqués, attendant le résultat du vote
      - Ils ne peuvent pas timeout de façon sûre puisqu'il existe (pour eux) la possibilité que le coordinateur se réveille et passe à l'étape de validation
    - On retrouve le même problème dans le cas d'une panne du coordinateur durant la phase 2
    - Pour contourner problème, on peut ajouter un 3ème type de noeud jouant le rôle fallback en cas de panne du coordinateur
      - Reprend la gestion de la transaction dans le cas d'une panne du coordinateur
      - Recontacte chaque noeud pour récupérer de nouveau son vote effectué lors de la phase 1
	- Nécessité pour les noeuds de conserver une trace de leurs votes
      - Cependant, si un participant vient à crasher à ce moment, on ne peut plus résoudre le consensus
	- Peut pas annuler car p-e que le participant a lui validé
	- Peut pas valider car p-e que le participant a lui refusé lors de la phase 1
  - Ressources
    - http://the-paper-trail.org/blog/consensus-protocols-two-phase-commit/
- <<3pc>> CONSENSUS : Three-phase commit (3PC)
  - Il s'agit d'une évolution de [[2pc]]
  - Vise à fournir un protocole plus résistant aux défaillances pour obtenir le consensus
  - Ajoute pour cela une phase intermédiaire à 2PC
  - Protocole
    - 1. Proposition
      - Même étape que dans 2PC
    - 2. Préparation à validation
      - Le coordinateur envoie ce message à tous les participants s'ils ont voté unanimement "oui"
      - Permet d'informer les participants du vote de son résultat
      - Permet aux participants de verrouiller la transaction, mais sans modifier de façon irréversible leur état
      - Les participants notifient ensuite le coordinateur qu'ils sont prêts à valider la transaction
      - Ainsi, si n'importe quel noeud rencontre une panne, l'état du protocole sera toujours disponible via un des noeuds
    - 3. Validation ou abandon
      - Même étape que dans 2PC
  - Lors de la récupération d'un crash
    - Si tous les noeuds disponibles indiquent avoir reçu le message 2 alors on peut poursuivre et valider la transaction
    - Sinon, on peut annuler la transaction de façon sûre puisque le coordinateur ne serait pas passé à l'étape 3
  - Limites
    - Une panne du coordinateur + une partition des participants peuvent provoquer une divergence
      - Si l'ensemble des noeuds d'une partition ont passé l'étape 2, alors le mécanisme de recovery va poursuivre et valider la transaction
      - Alors qu'il suffit qu'un seul noeud du second sous-groupe n'ait pas reçu le message de l'étape 2 pour que le mécanisme de recovery décide d'annuler la transaction
      - La fusion des sous-groupes lors de la résolution de la partition entraînera donc l'apparition d'une divergence entre les participants
    - Une divergence est possible dans un autre scénario où le coordinateur récupère d'une panne et interfère avec le coordinateur de fallback
      - Si le coordinateur plante après avant d'avoir reçu toutes les réponses au message "prepare-to-commit"
      - Le coordinateur de fallback va prendre la main, récupérer l'état de la transaction et la poursuivre jusqu'à sa validation
      - Cependant, si le coordinateur initial recouvre de sa panne, il va annuler la transaction (n'ayant pas reçu les réponses au "prepare-to-commit")
      - Les participants vont donc valider ou annuler la transaction en fonction du message qu'ils reçoivent en 1er
  - Ressources
    - http://the-paper-trail.org/blog/consensus-protocols-three-phase-commit/
*** Planned
**** DONE MUTE : Préparer la démo pour la réunion avec Marius Shekow
- Dans le cadre de la rencontre avec Marius Shekow, nous allons présenter les travaux de l'équipe
- Une de ces présentations va consister en une démo de MUTE
- Vérifier que le scénario de la démo de ECSCW 2017 fonctionne toujours
**** CANCELLED CONSENSUS : Lire *The part-time parliament*
- *Spanner* a l'air de reposer fortement sur des /Paxos state machines/
- Lire le papier sur *Paxos* permettrait p-e de faciliter la compréhension de *Spanner*
- Disponible ici : https://dl.acm.org/citation.cfm?id=279229
** Semaine du <2017-11-06 Mon> au <2017-11-09 Thu>
*** Done
- <<paxos>> CONSENSUS : Paxos
  - L'approche Paxos se décompose en plusieurs protocoles
    - Basic Paxos qui adresse le problème du consensus
    - Multi Paxos qu combine plusieurs rounds de Basic Paxos pour obtenir un consensus sur plusieurs valeurs et sur leur ordre
  - Basic Paxos
    - Assez proche de [[2pc]]
    - Requirements
      - Safety
	- Une seule valeur est choisie
	- Aucun noeud n'obtient une valeur qui n'a pas été choisie
      - Liveness
	- Hypothèses : une majorité de noeuds sont disponibles et peuvent communiquer dans des délais raisonnables
	- Une valeur est finalement choisie
	- Si une valeur est choisie, tous les noeuds l'obtiennent en finalité
    - Rôles
      - Proposer
	- Gère la requête du client
	- Va soumettre au vote des Acceptors une valeur candidate
	- Va connaître la valeur choisie
      - Acceptors
	- Se contente de voter sur la valeur transmise par le Proposer
	- Va conserver des informations sur les propositions reçues, les réponses effectuées et les valeurs choisies
	- Ne participe pas forcément à tous les votes
	- Va donc chercher à obtenir la valeur choisie
      - Un noeud peut potentiellement cumuler ces rôles
    - Ordonnancement des proposals
      - Le réseau étant asynchrone, l'ordre de réception des propositions peut être perturbé
      - Ceci peut conduire à des divergences
      - Les propositions doivent être ordonnables de façon à pouvoir accepter que la plus récente
      - Donne un identifiant unique à chaque proposition
	- Permet de comparer et d'ordonner les propositions avec leur identifiant
	- 2 noeuds ne doivent pas pouvoir générer le même identifiant
	- Un noeud doit toujours pouvoir générer un identifiant plus grand pour pouvoir écraser une ancienne proposition
      - Identifiant de la forme /<round, serverId>/ où
	- /round/ est le numéro du round actuel
	- /serverId/ est l'identifiant unique du noeud
      - Chaque noeud stocke /maxRound/ qui est la plus grande valeur de /round/ observée
      - Quand un noeud génère un nouvel identifiant, il génère le couple /<maxRound + 1, server>/
    - Protocole
      - Données stockées par noeud
	- /minProposal/ : Le numéro de la plus petite proposition que ce noeud va accepter, 0 s'il n'a toujours pas reçu de proposition
	- /acceptedProposal/ : Le numéro de la dernière proposition acceptée, 0 initialement
	- /acceptedValue/ : La valeur associée à la dernière proposition acceptée, null initialement
	- /maxRound/ : Le numéro du plus grand round observé
      - Le protocole se décompose en 2 étapes
      - 1. Proposition
	- Le Proposer
	  - génère un nouveau proposal number /n/
	  - broadcast un message /Prepare(n)/ à tous les noeuds
	- Les Acceptors recevant ce message
	  - Mettent à jour leur variable /minProposal/ si /n > minProposal/
	  - Répondent avec /<acceptedProposal, acceptedValue>/
      - 2. Validation
	- Quand le Proposer reçoit une majorité de réponses positives des Acceptors
	  - Récupère la valeur /acceptedValue/ pour laquelle /acceptedProposal/ est maximum
	  - Broadcast le message /Accept(n, value)/
	- Les Acceptors recevant ce message
	  - Si /n ≥ minProposal/
	    - /acceptedProposal = n/
	    - /minProposal = n/
	    - /acceptedValue = value/
	  - Dans tous les cas, renvoie ensuite /Return(minProposal)/
	- Quand le Proposer reçoit une majorité de réponses des Acceptors
	  - Si une seule réponse renvoie une valeur /result/ tel que /result > n/, alors on recommence le protocole
	  - Sinon, la valeur est choisie
      - Représenté slide 12 de [[file:resources/paxos.pdf]]
    - Limites
      - Le protocole peut ne pas finir dans certains cas
      - Notamment le cas où deux Proposers se battent pour avoir le /proposalNumber/ le plus élevé
	- Si leurs messages /Prepare/ s'entrecroisent, chaque /Prepare/ d'un Proposer va déprécier le message /Accept/ de l'autre Proposer
	- Tant que les deux Proposers ne se seront pas observés et qu'un d'entre eux n'aura pas céder sa place, aucune valeur ne sera choisie
	- Voir slide 16 de [[file:resources/paxos.pdf]]
      - Finalement, seul le Proposer sait de manière sûre si une valeur a été choisie
      - Pour obtenir cette information, chaque Acceptor doit exécuter /Basic Paxos/ à son tour
  - Multi Paxos
    - Pas spécifié dans la littérature, contrairement à Basic Paxos
    - Il n'y a donc pas de preuve non plus
    - Utilise plusieurs rounds de Basic Paxos pour sélectionner une valeur pour chaque entrée d'un log
    - Apporte plusieurs changements à Basic Paxos afin de le rendre utilisable et plus performant dans ce scénario
    - Peut exécuter en concurrence le protocole pour des entrées différentes
      - Ajoute un index aux messages /Prepare/ et /Accept/ pour indiquer l'entrée du log concernée par ce round
    - Protocole
      - Lorsqu'une requête d'un client est reçue
	- Détermine la 1ère entrée du log qui n'est pas choisie
	  - Mais on peut déjà posséder une valeur pour cette entrée
	- Exécute /Basic Paxos/ pour cette entrée avec la valeur du client
	- Si une des réponses au message /Prepare/ contient une /acceptedValue/
	  - Choisit cette valeur pour cette entrée
	  - Recommence le protocole afin de traiter la requête du client
	- Sinon poursuit le protocole l'exécution de Basic Paxos avec la valeur du client
      - Décrit slide 20 de [[file:resources/paxos.pdf]]
    - Élection de leader
      - Utiliser Basic Paxos tel quel est inefficace
	- Possible d'avoir plusieurs Proposers concurrents qui vont générer des conflits
	- Besoin de 2 rounds de query/response pour chaque valeur (/Prepare/, /Accept/)
      - Élire un leader permet
	- De réduire à 1 le nombre de Proposer à un moment donné, et donc limiter les possibilités de conflits
	- D'éliminer la nécessité de messages /Prepare/ dans la majorité des cas
      - Protocole d'élection
	- Le serveur avec l'identifiant maximum à un moment donné obtient le rôle de leader
	- Chaque serveur envoie un heartbeat de façon périodique à tous les autres serveurs
	- Si un serveur ne reçoit aucun heartbeat d'un autre serveur possédant un ID supérieur depuis un certain temps, il devient le leader
	- Présenté slide 23 de [[file:resources/paxos.pdf]]
    - Suppression de messages /Prepare/
      - /Prepare/ permet de
	- Bloquer les anciennes propositions
	- Obtenir les valeurs potentiellement choisies
      - On peut ainsi éliminer /Prepare/ si
	- Les numéros de propositions ne sont pas par entrée mais pour le log entier
	- On ajoute à la réponse à /Prepare/ un booléen /noMoreAccepted/
	  - Indique si pour toutes les entrées suivantes, aucune proposition n'a été acceptée
      - Ainsi, si un Acceptor répond à /Prepare/ avec le flag /noMoreAccepted/
	- Plus besoin de /Prepare/ avec cet Acceptor
      - De plus, si une majorité d'Acceptors ont répondu avec ce flag
	- Plus besoin de /Prepare/ pour l'ensemble des noeuds
    - Partage des informations
      - Plusieurs données ne sont pas partagées avec l'ensemble des noeuds
	- Seulement une majorité des noeuds reçoit la valeur choisie pour une entrée, et non pas tous les noeuds
	- De plus, seul le Proposer sait si cette entrée a été choisie
      - Dans le cas d'une /Replicated State Machine/, les commandes composant le log doivent être appliquées dans l'ordre
      - Les slides 25 à 27 de file:resources/paxos.pdf décrivent comment répliquer ces informations
  - Ressources
    - http://the-paper-trail.org/blog/consensus-protocols-paxos/
    - https://www.quora.com/In-distributed-systems-what-is-a-simple-explanation-of-the-Paxos-algorithm
    - https://www.youtube.com/watch?v=JEpsBg0AO6o
    - https://ramcloud.stanford.edu/~ongaro/userstudy/
- PHD DAY : Rédiger un abstract sur le sujet de thèse
  - Disponible à https://github.com/MatthieuNICOLAS/phd-day-2017/blob/master/abstract/main.pdf
*** Planned
**** DONE ADMINISTRATIF : Remplir le formulaire *Charges d’enseignement pour Doctorant contractuel*
**** DONE PHD DAY : Rédiger un abstract sur le sujet de thèse
     SCHEDULED: <2017-11-15 Wed>
- Doit fournir le sujet de thèse et un abstract (environ 200 mots) pour le PhD Day
  - Emphasize on what is your research problem, who else are working on the same/similar problem, what is your specific approach, and what is/are your expected results
** Semaine du <2017-11-14 Tue> au <2017-11-17 Fri>
*** Done
- <<raft>> CONSENSUS : Raft
  - Adresse le problème du consensus pour répliquer un log
    - Permet de répliquer une machine à état
  - Conçu pour être simple à comprendre
  - Tout en offrant les mêmes garanties et performances que Paxos
  - Afin de simplifier son fonctionnement, Raft repose sur l'utilisation d'un leader
    - Supprime les conflits
  - Rôles
    - Leader
      - Gère les requêtes des clients
      - Envoie des messages /AppendEntries/
	- Permet de répliquer son log
	- Sert aussi de /heartbeat/ pour maintenir son leadership
    - Candidate
      - État intermédiaire
      - Envoie des messages /RequestVote/ afin d'être élu comme leader
    - Follower
      - Se contente de traiter et de répondre aux différents messages qu'il reçoit
    - Dès qu'un noeud découvre un noeud avec un terme supérieur, il redevient un Follower
    - Représenté slide 10 de https://raft.github.io/slides/uiuc2016.pdf#page=10
  - Termes
    - L'exécution du protocole se fait au cours de termes successifs
    - Un terme est composé
      - D'une phase d'élection
      - D'une phase d'opérations normales
    - Si l'élection échoue, le terme n'a pas de leader
      - Aucune requête ne peut être traité durant ce terme
    - Chaque noeud conserve la valeur du terme courant
      - Joint à chaque message
      - Si un noeud reçoit un message contenant un identifiant de terme plus grand, redevient un follower
      - Si un noeud reçoit un message contenant un identifant de terme plus petit, répond une erreur
    - Permet d'identifier les messages obsolètes
    - Représenté slide 11 de https://raft.github.io/slides/uiuc2016.pdf#page=11
  - Propriétés du log
    - Si différents noeuds possèdent une entrée du log avec le même index et le même terme
      - Ces entrées correspondent à la même commande
      - Les entrées précédentes des logs sont identiques
    - Si une entrée du log est /committed/
      - Toutes les entrées précédentes le sont aussi
  - Protocole
    - Le protocole se décompose en plusieurs sous-problèmes
    - 1. Leader election
      - Décrit slide 12 de https://raft.github.io/slides/uiuc2016.pdf#page=12
      - Propriété de safety
	- Au maximum un seul leader peut être élu par terme
	- Pour assurer cette propriété
	  - Un noeud ne peut voter qu'une fois par terme
	  - Un noeud a besoin d'une majorité de votes positifs pour remporter l'élection
      - Propriété de liveness
	- Un candidat doit être élu finalement
	- Pour assurer cette propriété
	  - Le délai observé par les noeuds avant de passer au terme suivant n'est pas le même pour chacun
	  - Ainsi, dans le cas où une élection échoue à cause de l'absence d'une majorité, un noeud démarre une nouvelle élection avant les autres et parvient généralement à être élu
    - 2. Normal operation (basic log replication)
      - Le leader traite les requêtes envoyées par le client
      - Ajoute la commande à son log
      - La partage avec les autres noeuds via un message /AppendEntries/
      - Si l'entrée /e/ et l'entrée suivante /e+1/ sont connues par une majorité de noeuds, alors /e/ est dite /committed/
      - Une fois l'entrée /committed/
	- Le leader exécute la commande sur sa machine à état et renvoie le résultat au client
	- Le leader indique via les prochains messages /AppendEntries/ que l'entrée est /committed/
	- Les followers peuvent à leur tour exécuter la commande /committed/ à la réception d'un des prochains messages
    - 3. Safety and consistency after leader changes
      - Une fois une opération /committed/, tous les leaders futurs devront posséder cette entrée
	- Permet d'assurer qu'un nouveau leader ne va pas rentrer en conflit avec le log
      - Pour empêcher les noeuds en retard d'être élu
	- Chaque candidat inclut l'index et le terme de sa dernière entrée du log dans les messages /RequestVote/
	- Lorsqu'un noeud reçoit un message /RequestVote/ avec un terme ou un index obsolète, il le rejette
	- Ainsi, seul un noeud possédant la dernière opération /committed/ peut être élu
      - Le log du leader est considéré comme le log véritable
      - Les logs inconsistents vont être corrigés par le biais des messages /AppendEntries/
	- Le message contient le couple <index, terme> de l'entrée précédante les nouvelles
	- Si le noeud ne possède pas l'entrée correspondante, il rejecte la requête
	- Le leader va remonter dans le log jusqu'à trouver la dernière opération commune et va lui envoyer le log à partir de celle-ci
	- Algorithme décrit slide 18 de  https://raft.github.io/slides/uiuc2016.pdf#page=18
    - 4. Neutralizing old leaders
      - Un leader peut perdre son rôle autrement qu'à cause d'un crash
      - Notamment dans le cas d'une partition réseau
      - Pendant ce temps, le groupe élit un nouveau leader et traite les requêtes des clients
      - À la reconnexion de l'ancien leader, il faut l'empêcher de rentrer en conflit avec le reste du groupe
      - Utilise la valeur de son terme courant
	- Joint à chaque message
	- Un noeud recevant un de ses messages va donc lui répondre que sa valeur de terme est obsolète
	- L'ancien leader va redevenir un follower et va mettre à jour sa valeur de terme
    - 5. Client interactions
      - Envoie ses requêtes au leader
      - Si une requête timeout
	- Par exemple si le leader crash
	- Contacte un autre noeud
	- Va éventuellement être redirigé vers le nouveau leader
	- Va pouvoir resoumettre sa requête
      - Mais une requête peut timeout après que la commande ait été /committed/ et exécutée mais avant que la réponse ne soit envoyée au client
	- Afin d'éviter d'exécuter 2 fois la même commande, le client ajoute un id unique à chaque commande
	- Cet id est conservé dans l'entrée du log
	- Lorsque le leader reçoit une requête, il vérifie que l'id de la commande n'est pas déjà présent dans le log
	- Si oui, se contente de renvoyer le résultat de cette entrée
      - Permet d'assurer une /exactly-once delivery/
    - 6. Configuration changes
      - Voir slides 27 à 30 de https://ramcloud.stanford.edu/~ongaro/userstudy/raft.pdf#page=27
  - Ressources
    - https://raft.github.io
    - https://ramcloud.stanford.edu/~ongaro/userstudy/
    - https://www.infoq.com/presentations/raft
    - https://raft.github.io/slides/uiuc2016.pdf
*** Planned
** Semaine du <2017-11-20 Mon> au <2017-11-24 Fri>
*** Done
- <<spanner>> DISTRIBUTED SYSTEMS : Lire *Spanner: Google’s Globally Distributed Database*
  - Distributed multiversion database
    - General-purpose transactions (ACID)
    - SQL query language
    - Schematized tables
    - Semi-relational data model
  - Allow to shard and replicate the data
  - Achieve lock-free distributed read transactions
    - Able to do so thanks to Spanner's property : distributed transactions are externally consistent
  - External consistency
    - Commit order of the transactions is the same as the order in which you observe the transactions
  - Use 2 Phase-Locking (2PL) to ensure serializability of the write on the database
  - Add a timestamp to each transaction
  - Synchronizing snapshosts
    - Use a global wall-clock time
      - Equivalent to the External Consistency
      - Commit order respects global wall-time order
      - Use timestamp and maintain timestamp order === commit order
  - TrueTime
    - Global wall-clock time with bounded uncertainty
    - /TT.now().latest/ returns the maximum timestamp given /now()/ and the bounded uncertainty
    - /TT.now().earliest/ returns the minimum timestamp given /now()/ and the bounded uncertainty
  - Generating timestamps
    - Assign timestamp while two-phase locking is ongoing
    - At the beginning, once the locks acquired, pick /s = TT.now().latest/
    - Do not release the locks until /TT.now().earliest > s/
  - Able to mask the commit wait by performing the consensus or the 2PC meanwhile
  - Ressources
    - https://www.youtube.com/watch?v=NthK17nbpYs
- CRDT : Idée pour le renommage
  - Modèle du système
    - Système distribué à large échelle
    - Réseau asynchrone
    - Partition-tolerant
    - Eventual consistent
    - Préservation de l'intention des utilisateurs
  - Opération de renommage
    - Fusionne tous les éléments existants d'un état donné en un seul nouvel élément ayant pour identifiant /id'/
    - /rename(state) = (state', id')/
      - L'état peut être associé à /version vector/
    - Génère donc un nouvel état de la structure de donnée avec le même contenu mais des méta-données différentes et compactées
    - Un seul noeud peut effectuer l'opération de renommage
    - Des noeuds peuvent être déconnectés lors de la génération de cette opération
    - Nécessite une livraison causale
      - Ne peut effectuer l'opération de renommage que si on possède toutes les opérations précédentes
    - Marque le début/fin d'une époch
      - Permet de filtrer les opérations obsolètes ou trop avancées pour notre copie
  - Application de l'opération de renommage
    1. Dépile/Undo les opérations connues en local qui sont concurrentes avec l'opération de renommage, récupère les opérations textes correspondantes
    2. Obtient alors l'état sur lequel a été effectué l'opération de renommage
    3. Remplace le modèle courant par celui de l'opération de renommage
    4. Rempile/Redo les opérations textes sur le nouvel état
    5. Propage les opérations ainsi générées
  - Problèmes
    - Si chaque noeud se contente uniquement de rejouer ses opérations, on peut perdre au cours du renommage des opérations
      - Potentiellement, un noeud peut ne jamais se reconnecter et donc jamais rejouer ses opérations
      - L'opération de renommage pourrait aussi être interprétée par les utilisateurs comme plusieurs opérations de suppression, puisque des éléments vont disparaître momentanément
      - Ce qui peut entraîner des réactions provoquant une duplication de l'intention
	- Ré-insertion d'un mot qui a été "supprimé" au cours du renommage
    - Si chaque noeud rejoue les opérations de tous les utilisateurs, on risque de dupliquer l'intention
      - Si plusieurs noeuds ont observé la même opération concurrente à l'opération de renommage, ils vont chacun la ré-appliquer
  - Idée
    - On peut modifier la stratégie de génération de l'identifiant lorsqu'on rejoue les opérations concurrentes
    - Si on génère de façon déterministe l'identifiant obtenu en rejouant l'opération, on ne duplique plus l'intention
      - Chaque utilisateur va générer la même opération distante pour une opération concurrente donnée
  - Reformulation du problème de recherche
    - Peut-on proposer une ou des stratégies déterministes de génération des identifiants pour une opération rejouée ?
  - Générer de manière déterministe un identifiant pour une opération donnée
    - Données communes
      - État commun
	- Commence à rejouer les opérations sur un état commun (état obtenu après le renaming)
      - Ancien identifiant de l'élément
	- Peut tout utiliser ou juste une partie
    - Données pouvant varier
      - La séquence d'opérations
	- Potentiellement, des opérations communes à plusieurs noeuds peuvent avoir été observées dans des ordres différents
	- La séquence peut aussi des comporter des opérations n'apparaissant pas chez tous les noeuds
    - À partir de ces données, doit définir une stratégie déterministe de génération du nouvel identifiant
  - Formalisation
    - Étant donné
      - un état S
      - une opération /view(S)/ permettant de récupérer le contenu de la structure de données pour un état donné
    - Peut-on définir des opérations /undo/ et /redo/ tels que
      - /undo(S, remoteOp) = (S', redoOp)/
	- Annuler une opération distante change l'état et renvoie une opération locale enrichie de façon à pouvoir la ré-appliquer
      - /redo(S, redoOp) = (S', remoteOp)/
	- Ré-appliquer une opération locale enrichie
      - Vérifiant les invariants suivants
	1. /undo/ puis /redo/ une opération doit préserver le contenu de la structure de données
	   - Permet de s'assurer qu'on ne perd pas l'intention au cours du /undo/ /redo/
	   - Par contre, l'état final ainsi que l'opération regénérée peuvent être différent de l'état de départ et de l'opération annulée
	   - /view(S) = view(S')/ où
	     - /(S_temp, redoOp) = undo(S, op)/
	     - /(S', _) = redo(S_temp, redoOp)/
	2. L'état obtenu après avoir /undo/ une séquence d'opérations ne doit pas dépendre de l'ordre
	   - Permet de remplacer l'état obtenu par l'état fourni par l'opération de renommage de façon sûre
	   - /S = S'/ où
	     - /(S1, _) = undo(Sinit, op_1)/
	     - /(S2, _) = undo(Sinit, op_2)/
	     - /S, _) = undo(S1, op2)/
	     - /S', _) = undo(S2, op1)/
	3. L'état final et les opérations regénérées après avoir /undo/ une séquence d'opérations puis les avoir /redo/ ne doivent pas dépendre de l'ordre de la séquence
           - Permet de s'assurer que l'état final est le même pour chaque noeud et que les opérations communes aux noeuds sont regénérées de manière déterministe
	   - /S = S'/ où
	     - /(S_1, redoOp_1) = undo(S_init, op_1)/
	     - /(S_2, redoOp_2') = undo(S_init, op_2)/
	     - /S_before-rename, redoOp_2) = undo(S_1, op_2)/
	     - /S_before-rename, redoOp_1') = undo(S_2, op_1)/
	     - /view(S_before-rename) = view(S_rename)/
	     - /(S_3, op_2') = redo(S_rename, redoOp_2)/
	     - /(S_4, op_1') = redo(S_rename, redoOp_1')/
	     - /(S, op1') = redo(S3, redoOp_1)/
	     - /(S', op2') = redo(S4, redoOp_2')/
      - Est-ce suffisant ?
	- C'est pas sur /undo/ et /redo/ séparément que doivent porter les contraintes
	- Mais sur leur combinaison
  - Points négatifs
    - Besoin de conserver le log des opérations ou du moins une partie
      - Afin de pouvoir undo les opérations en respectant l'ordre imposée par la couche livraison
      - Peut retirer de façon sûre des opérations du log une fois qu'elles sont dans le contexte causal
    - Résoudre plusieurs opérations de renommage concurrentes me paraît difficile
      - Pour le moment, se contente d'éliminer la possibilité d'avoir des opérations de renommage concurrentes
      - Dans le système décrit ici, on établit comme hypothèse qu'un seul noeud peut effectuer une opération de renommage (owner ? bot dédié ?)
      - Single Point Of Failure
      - Peut suggérer l'utilisation de rôles et d'un méchanisme de consensus pour permettre de décentraliser la responsabilité
	- En dehors du scope pour le moment
  - Réflexions
    - La complexité est proportionnelle au nombre d'opérations concurrentes à l'opération de renommage
    - En fonction de la stratégie de génération des identifiants choisie, les identifiants des opérations concurrentes peuvent grossir par rapport à leur identifiants initiaux
      - Peut argumenter que ces derniers seront réduits lors du prochain renommage
    - Pas forcément gourmand pour le réseau
      - Opération de renommage consiste juste en un identifiant associé à une version du modèle
      - L'état du document est obtenu lors de la phase 2
      - Taille de l'opération de renommage proportionnel au nombre de noeuds
- Meeting
  - Study the past weeks consensus algorithms
    - Paxos
    - Raft
  - Also took a look at Spanner, Google's Globally Distributed Database
    - Distributed multiversion database
    - Achieve lock-free distributed read transactions
    - Thanks to a global wall-clock time
  - Start writing down some ideas for the renaming problem
    - One of them seems to be a good lead
    - Will discuss about it with Gérald and Olivier to see if it is actually a good idea
*** Planned
**** DONE DISTRIBUTED SYSTEMS : Lire *Spanner: Google’s Globally Distributed Database*
- Disponible ici : https://dl.acm.org/citation.cfm?id=2491245
** Semaine du <2017-11-27 Mon> au <2017-12-01 Fri>
*** Done
- PHD DAY : Préparer une présentation sur le sujet de thèse
  - Disponible ici : https://github.com/MatthieuNICOLAS/phd-day-2017/blob/master/presentation/presentation.pdf
  - Réalisation d'une 1ère version
  - Réunion avec Olivier et Gérald
    - Ajouter logos LORIA et CNRS
    - Slide 2
      - Remplacer les utilisateurs par des noeuds
      - Griser un noeud pour le faire apparaître comme déconnecté
    - Entre slide 2 et 3
      - Ajouter une slide avec un réseau plus complexe de noeuds, avec partitions et/ou noeuds déconnectés
    - Slide 3
      - Ajouter contrainte d'unicité
      - Remplacer "..." par "Many others"
    - Slide 4
      - Retravailler le "research problem" sous l'angle de immutabilité/mutabilité
      - Immutabilité nous a permis d'avoir des identifiants globaux permettant des opérations concurrentes tout en assurant la convergence
      - Mais nous a donné des identifiants à taille non-bornée
      - On voudrait pouvoir renommer les identifiants pour réduire leur taille
      - Mais cela viendrait à réinsérer une notion de mutabilité dans les identifiants
      - Est-ce une bonne idée ?
    - Slide 5
      - La supprimer
- CRDT : Rédiger un rapport sur l'idée pour le renommage
*** Planned
**** DONE PHD DAY : Préparer une présentation sur le sujet de thèse
     SCHEDULED: <2017-12-07 Thu>
- Dans le cadre du PhD Day, je dois effectuer une présentation de 5min
  - Emphasize on what is your research problem, who else are working on the same/similar problem, what is your specific approach, and what is/are your expected results
** Semaine du <2017-12-04 Mon> au <2017-12-08 Fri>
*** Done
- PHD DAY : Préparer une présentation sur le sujet de thèse
  - Prise en compte des retours de Olivier et Gérald
  - Répétition avec les autres doctorants de l'équipe
  - Retours
    - Les couleurs des schémas sont p-e un peu faibles et peuvent gêner la lecture (surtout pour les gens daltoniens)
  - Modification des couleurs utilisées
- CRDT : Rédiger un rapport sur l'idée pour le renommage
  - Refonte de la partie sur les états, identifiants et /add/
  - Complétion de la section /Discussion/
  - Trouvé un contre-exemple pour l'algorithme proposé en 2.4
    - Si /op2/ et /op3/ en concurrence et que /id2 < id3/
    - Noeud B va obtenir l'état suivant avant la réception de l'opération renommage : /[(id1, elt1), (id2, elt2), (id3, elt3)]/
    - Mais jouer l'opération de renommage va conduire à l'état /[(id'1, elt1), (id'3, elt3), (id'2, elt2)]/
    - Puisqu'on va rejouer l'opération /addLocal(1, elt3)/
    - On vient donc de perturber l'ordre initial des éléments
  - Le mécanisme des /undo/ permettait de /transformer/ l'opération locale par rapport à l'état courant
- ECSCW2017 : Ajouter le papier sur HAL
  - François s'en est chargé
*** Planned
**** CANCELLED ECSCW2017 : Ajouter le papier sur HAL
**** DONE CRDT : Rédiger un rapport sur l'idée pour le renommage
**** DONE CRDT : Ajouter le contre-exemple au rapport sur le renommage
** Semaine du <2017-12-11 Mon> au <2017-12-15 Fri>
*** Done
- CRDT : Mettre à jour rapport sur le mécanisme de renommage
  - Nouvel algorithme
    - Si on possède une opération /renameRemote(mapIds, causalContext)/, il est possible d'effectuer le renommage de la façon suivante
      - Pour chaque opération concurrente /remoteOp/
	- Si /id/ n'est pas présent dans /mapIds/
	  - Trouver son prédecesseur /prevId/ et son image /prevId'/ dans /mapIds/
	  - Générer /id'/ à partir de /prevId'/ (une simple concaténation de /prevId'/ et de /id'/ suffit)
	  - Ajouter /id -> id'/ dans /mapIds/
	  - Propager /remoteOp'/ (nécessaire ?)
      - Pour chaque /(id, elt)/ de l'état
	- Remplacer /id/ par /id'/ (un simple parcours de la structure suffit)
    - Discussion
      - Comment gérer les opérations concurrentes à l'opération de renommage lorsqu'on a déjà appliqué l'opération de renommage
	- Soit on rejette les opérations concurrentes et on attend qu'un autre pair nous envoie la version modifiée de l'opération
	  - Si un pair nous l'envoie, il va probablement pouvoir nous envoyer sa transformée
	  - Mais rajoute du délai
	- Soit on accepte l'opération et on la transforme nous-même
	  - Pour ça, besoin de récupérer la /mapIds/
	    - Besoin de la stocker ou de la regénérer
      - Quelles versions des opérations stocker dans le log ?
	- Est-ce qu'on stocke les opérations initiales ?
	- Ou les opérations transformées ?
	- Ou un mix des 2 ?
      - Peut réduire la quantité d'information contenue dans l'opération de renommage au prix de calcul supplémentaire
	- À partir du contexte causal, un noeud peut regénérer /mapIds/
	  - En rejouant les opérations appartenant au contexte causal, on récupère l'état sur lequel a été appliqué l'opération de renommage
	  - En effectuant une opération de renommage local sur cet état, on obtient /mapIds/
	  - Ceci fonctionne tant que l'opération de renommage local est déterministe pour un état donné
    - Limites
      - Nécessité d'une livraison causale de l'opération de renommage
      - Ne gère pas les renommages en concurrence
	- Un noeud peut avoir un rôle particulier lui permettant de déclencher cette opération
	- Ce rôle peut être attribué de manière fixe
	- Ou un mécanisme d'élection de leader peut être utilisé pour déterminer qui possède ce rôle
  - Mise à jour du rapport
    - Suppression du contenu relatif à la proposition initiale
      - Figures
      - Discussion
      - Reformulation du problème
      - Contre-exemple
    - Ajout du nouvel algorithme pour /renameLocal/
    - Ajout du nouvel algorithme pour /renameRemote/
  - Nouvel discussion avec Gérald
    - Les algorithmes ont l'air de fonctionner
      - On a revu les algorithmes proposés
      - On a pas pu trouver de contre-exemple aboutissant à une divergence
    - Le problème porte sur /mapIds/
      - Cette map est volumineuse et coûteuse, notamment à broadcast
      - Elle contient tous les anciens identifiants (gros) et les nouveaux (petits)
    - L'optimiser améliorerait la solution
      - Les autres noeuds ont besoin de pouvoir la regenérer de leur côté, peu importe leur état courant
	- Pour ça, ils ont juste besoin de la liste des identifiants à renommer et de leur index
	- Un identifiant peut être compressé pour ne conserver que son /id_site/ et sa /clock_site/
      - Au lieu de /mapIds/, on peut donc envoyer une séquence de couple /(id_site, clock_site)/
    - Prochaines étapes
      - Rédiger partie sur l'optimisation du mécanisme en terme de bande passante
      - Adapter le mécanisme pour les blockwise CRDTs
      - Adapter le mécanisme pour un système distribué
	- Supprimer la contrainte du super-noeud étant responsable du renommage
    - Questions restantes sur la solution actuelle
      - Gestion des opérations concurrentes à un renommage lorsqu'on a déjà effectué le renommage
	- Peut juste les refuser et attendre qu'un utilisateur nous envoie leur version modifiée
	- Ou peut effectuer soi-même la transformation
	  - Besoin de conserver la map pour cela
	  - Quand peut-on garbage collect la map de façon sûre ?
	    - Dès qu'on a, pour chaque utilisateur, une opération qui est de la nouvelle /epoch/ et qu'on a reçu toutes ses opérations précédentes
      - État du log
	- En fonction de la gestion des opérations concurrentes
  - Mise à jour du rapport
    - Ajout de la partie sur l'optimisation du mécanisme
*** Planned
**** DONE CRDT : Mettre à jour rapport sur le mécanisme de renommage
**** DONE CRDT : Ajouter la partie sur l'optimisation de la solution dans le rapport
** Semaine du <2017-12-18 Mon> au <2017-12-22 Fri>
*** Done
- CRDT : Adaptation du mécanisme de renommage aux blockwise-CRDTs
  - Ajout d'une section détaillant *Identifier* et *IdentifierInterval* dans les blockwise-CRDTs
  - Ajout des algorithmes adaptés pour les blockwise-CRDTs
  - Ajout des explications de chaque algorithme
*** Planned
**** DONE CRDT : Adaptation du mécanisme de renommage aux blockwise-CRDTs
** Semaine du <2018-01-08 Mon> au <2018-01-12 Fri>
*** Done
- MUTE : Corriger l'assertion sur l'append vide
  - Ajout d'un test /append-replayed-as-insert/ violant cette assertion
  - Modification de /addBlockRec()/ pour ne plus tenter d'append un texte vide à un bloc
  - Ajout d'un test /prepend-replayed-as-insert/ violant cette assertion
  - Modification de /addBlockRec()/ pour ne plus tenter de prepend un texte vide à un bloc
- MUTE : Corriger /createBetweenPosition()/
  - Modification de la méthode de génération du /random/ pour que /random ∈ ]tuple1.random, tuple2.random[/
  - Ajout d'un commentaire expliquant pourquoi /tuple2.random/ est exclue de l'interval
- MUTE : Corriger l'export du log et de l'arbre d'un document
  - Modification de *StorageService* pour ajouter /getDocBodyAsBlob()/, fonction permettant de récupérer le log d'un document
  - Modification de *DevLabelComponent*
    - Pour utiliser /getDocBodyAsBlob()/ pour récupérer le log du document courant
    - Déclencher correctement le téléchargement du log ou de l'arbre
- MUTE : Réflexion sur /replicaNumber/, /clock/ et identité de l'utilisateur
  - On peut, grâce au mécanisme d'authentification, obtenir de façon déterministe un /replicaNumber/ pour une identité
  - On pourrait donc partager ce /replicaNumber/ entre plusieurs machines
  - Mais la /clock/ pose problème
  - Celle-ci va évoluer en fonction de mes opérations
  - Si je change d'appareil, je peux récupérer via le système d'authentification mon /replicaNumber/
  - Mais je ne suis pas capable de récupérer la dernière valeur de ma /clock/ dans un environnement entièrement distribué
    - Les collaborateurs connectés à ce moment n'ont pas forcément observés mes dernières opérations
  - Pour assurer l'unicité des identifiants générés et pour assurer la disponibilité du système, *je ne peux pas conserver mon /replicaNumber/ d'une machine à l'autre*
  - On peut par contre mettre en place et gérer une *Map* liant mon identité à la liste de mes /replicaNumbers/
    - Cette *Map* devrait être répliquée chez chaque utilisateur et devrait être fusionnable avec celles des autres
- Meeting
  - Before holidays, present a first draft of a renaming mechanism to Gérald
  - It seems to work
  - Will now implement it to evaluate it
  - So have been working on MUTE to prepare its prototyping
  - Have branch corresponding to the refactoring of identifiers
  - Was never merged
    - Were not able to test it because of the eduroam issue
  - Updated it
  - Fixed parts of the code which triggered assertions
  - Deployed it on dev
  - Will organize a session to perform some user testing next week
- Réplication et cohérence de données : Cours 1
  - Reliability
    - La durée qu'un système fonctionne sans tomber de panne
  - Availability
    - Probabilité que le système soit accessible à un moment donné
  - Depandability
    - Reliability * Availability
  - Sequential Consistency
    - À partir des observations de tous les sites, on peut construire un entrelacement des opérations qui
      - Respecte l'ordre des opérations locales
      - Respecte le résultat des opérations
    - et qui serait exécuté par tous les sites
    - Coûteuse à assurer
      - Besoin de donner la priorité aux opérations d'écriture
      - Les lectures sont mises en attente pendant que les écritures sont effectuées globalement
      - Diminue la disponibilité du système
  - Linearizability
    - Modèle de cohérence reprenant Sequential Consistency, mais en plus strict
    - Ajoute un timestamp aux opérations
    - Les opérations doivent être ordonnées dans la séquence telles que les timestamps des opérations soit croissants
  - Modèles de cohérence vs. protocoles de cohérence
    - Les protocoles décrivent une implémentation d'un modèle de cohérence donné
  - Remarques
    - Slide 32 : faire apparaître qu'on a plus de dépendance/d'ordre entre /R(x)a/ et /W(x)b/ ?
    - Slide 34 : les 2 processus ne peuvent pas aussi se tuer mutuellement avec la causalité ?
*** Planned
**** DONE MUTE : Corriger l'assertion sur l'append vide
- L'assertion suivante déclenche dans un cas une erreur : https://github.com/coast-team/mute-structs/blob/rework-identifiers/src/ropesnodes.ts#L154
- On essaie donc d'append un texte vide
- Ce scénario arrive dans le cas suivant :
  1. Un utilisateur A créé un bloc
  2. Il append du texte à ce bloc
  3. Il split le bloc à l'endroit du append
  4. Un utilisateur B reçoit les opérations dans l'ordre 1, 3 puis 2
- Modifier le code pour ne plus essayer d'ajouter un texte vide à un bloc
**** DONE MUTE : Corriger /createBetweenPosition()/
- On a récemment retravailler /createBetweenPosition()/ de façon à autoriser la valeur de /tuple2.random/ comme valeur de random pour le nouveau tuple
- Cette modification entraîne la possibilité de générer un nouvel identifiant /newId/ à partir de /id1/ et /id2/ tel que /id1 < id2 < newId/
  - Puisqu'on garantit que /newId.random <= id2.random/
  - Mais potentiellement /newId.replicaNumber > id2.replicaNumber/ ou /newId.replicaNumber === id2.replicaNumber && newId.clock > id2.clock/
- Corriger cette fonction
**** DONE MUTE : Corriger l'export du log et de l'arbre d'un document
- Les fonctionnalités d'export du log et de l'arbre d'un document ne fonctionnent plus
- Vu qu'on souhaite tester la nouvelle version des identifiants, pouvoir récupérer les logs en cas de bugs est indispensable
- Corriger cette
** Semaine du <2018-01-15 Mon> au <2018-01-19 Fri>
*** Done
- MUTE : Mettre en place *Protractor* pour réaliser des tests E2E
  - Le projet était déjà configuré pour utiliser *Protractor* pour réaliser des tests E2E
  - Ajout de tests
    - Stockage du document
      - Créé un document
      - Modifie le document
      - Refresh la page
      - Vérifie qu'on a bien récupéré le contenu du document
    - Broadcast temps réel des opérations
      - Créé un document avec un premier pair
      - Ouvre le document avec un second pair
      - Modifie le document avec le premier pair
      - Vérifie que le second pair observe les modifications
      - Modifie le document avec le second pair
      - Vérifie que le premier pair observe les modifications
  - Modification de la config pour démarrer le navigateur utilisé pour les tests en mode headless
    - Voir les exemples de configuration
      - http://www.protractortest.org/#/browser-setup#using-headless-chrome
      - http://www.protractortest.org/#/browser-setup#using-headless-firefox
  - Ajout de Travis comme système de CI
    - Ajout du fichier /.travis.yml/ contenant la configuration requise pour exécuter ces tests
    - Par défaut, si Travis détecte un fichier /yarn.lock/, il utilise *Yarn* comme gestionnaire de dépendances
    - Dans notre cas, on avait un fichier /yarn.lock/ mais qui n'était pas utilisé et donc pas à jour
    - Des hooks permettant de build le projet n'étaient pas non plus déclenchés par *Yarn*
    - On obtenait l'erreur suivante en résultat
      #+BEGIN_BLOCK
        ERROR in ./node_modules/css-loader?{"sourceMap":false,"import":false}!./node_modules/postcss-loader/lib?{"ident":"postcss","sourceMap":false}!./node_modules/sass-loader/lib/loader.js?{"sourceMap":false,"precision":8,"includePaths":["/home/travis/build/coast-team/mute/src/assets"]}!./src/styles.scss
        Module build failed: Error: Can't resolve '~normalize.css/normalize.css' in '/home/travis/build/coast-team/mute/src'
          at onError (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/Resolver.js:61:15)
          at loggingCallbackWrapper (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/createInnerCallback.js:31:19)
          at runAfter (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/Resolver.js:158:4)
          at innerCallback (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/Resolver.js:146:3)
          at loggingCallbackWrapper (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/createInnerCallback.js:31:19)
          at next (/home/travis/build/coast-team/mute/node_modules/tapable/lib/Tapable.js:252:11)
          at /home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/UnsafeCachePlugin.js:40:4
          at loggingCallbackWrapper (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/createInnerCallback.js:31:19)
          at runAfter (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/Resolver.js:158:4)
          at innerCallback (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/Resolver.js:146:3)
          at loggingCallbackWrapper (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/createInnerCallback.js:31:19)
          at next (/home/travis/build/coast-team/mute/node_modules/tapable/lib/Tapable.js:252:11)
          at innerCallback (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/Resolver.js:144:11)
          at loggingCallbackWrapper (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/createInnerCallback.js:31:19)
          at next (/home/travis/build/coast-team/mute/node_modules/tapable/lib/Tapable.js:249:35)
          at resolver.doResolve.createInnerCallback (/home/travis/build/coast-team/mute/node_modules/enhanced-resolve/lib/DescriptionFilePlugin.js:44:6)
          @ ./src/styles.scss 4:14-191
          @ multi ./src/styles.scss
      #+END_BLOCK
    - Suppression du fichier /yarn.lock/
    - On arrivait toujours pas à exécuter les tests E2E
      - On obtenait les erreurs suivantes
	- /E/runner - Unable to start a WebDriver session./
	- /E/launcher - Error: WebDriverError: unknown error: Chrome failed to start: crashed/
    - Afin de mieux diagnostiquer ces erreurs, utilisation des images Docker de Travis pour effectuer des tests
      - Les images Docker sont disponibles ici : https://docs.travis-ci.com/user/common-build-problems/#Troubleshooting-Locally-in-a-Docker-Image
    - Réalisation de tests en local
      - L'erreur était dûe à l'utilisation de Chrome au sein d'un conteneur
      - En lançant Chrome, on obtient l'erreur suivante
	- /Failed to move to new namespace: PID namespaces supported, Network namespace supported, but failed: errno = Operation not permitted/
      - Cette erreur m'a permis de trouver la page suivante
	- https://hub.docker.com/r/armbues/chrome-headless/
      - Bien tenté d'utiliser le profil de sécurité indiqué, mais sans succès
      - Ajout de l'option /--no-sandbox/ pour le moment
    - Redéploiement des tests sur Travis
    - Cette fois-ci, on démarre bien un navigateur et on le manipule pour effectuer les tests E2E
    - Mais le résultat n'est pas déterministe
      - Le ou les tests qui échouent ne sont pas les mêmes après plusieurs exécutions du même job
    - Test avec Firefox au lieu de Chrome
      - Le *GeckoDriver* n'a pas l'air de fonctionner avec la version de *Protractor* du projet
	- Voir https://github.com/angular/protractor/issues/4253
      - Possible de mettre à jour *Protractor*
      - Mais on obtient une nouvelle erreur
	- POST /session/ac0e051d-adc7-8247-b983-635cad11933d/keys did not match a known command
      - Celle-ci semble lié à *WebDriver* et *Selenium*
- MUTE : Supprimer la boucle de rafraîchissement infinie de Angular
  - Ajout de tests où on se contente d'ouvrir Mute dans le navigateur et d'appeler /waitForAngular()/
  - Ce test fonctionne sur la page /docs/
  - Ce test échoue sur la page /doc/
  - La boucle de rafraîchissement est donc dûe à un des *Components* ou *Services*
  - Voir si on peut mocker les composants pour essayer d'identifier plus précisement l'origine de cette boucle
- MUTE : Organiser une session de test sur mute-structs@0.4.0
  - Malgré quelques problèmes de connectivité, a quand même pu collaborer et récupérer des logs
  - Des divergences ont encore eu lieu
  - Dûes semblerait aux problèmes de causalité
  - N'ayant pas détecter d'autres erreurs, a mergé le modèle
- Réplication et cohérence de données : Cours 2
  - Exemple de Not Strong Eventual Consistency
    - Une fois toutes les opérations délivrées, une copie contacte un tier (autre copie ou arbitre) pour résoudre certains conflits
  - Remarques
    - Slide 14 : Une légende des schémas peut être utile
    - Slide 15 : C(b) = 40.2 (et pas C(a))
    - Slide 30 : On appelle ça un ordre lexicographique ?
    - Slide 35 : Tu peux pas simplifier le schéma avec juste 2 sites ?
- Meeting
  - Crash test session
    - Thanks again for your participation
    - Was able to gather some test samples
    - Did not find any other errors that the causality-related ones
    - So was finally able to release the new model
    - PLEASE EXPORT YOUR MUTE DOCUMENTS since the new model is not backward compatible
  - Related to the causality issue
    - Victorien proposed a simple way to add a lightweight causality tracking mechanism to MUTE
    - Implemented it
  - While i was still on MUTE
    - Worked on adding E2E tests using Protractor (automatically open a browser and interact with MUTE and check that a feature is still working)
    - Implement a few of them
    - Tricky part was to run them on the CI tool Travis (weird behavior of browser in container)
    - Unfortunately, tests are not deterministic
    - No way currently to wait for asynchronous task to end before moving to the next one
    - So wait using timeout
    - Works great on dev environment, not so much on Travis
*** Planned
**** DONE MUTE : Mettre en place *Protractor* pour réaliser des tests E2E
- *Protractor* permet d'effectuer des tests E2E
- On pourrait l'utiliser afin d'automatiser certains tests que nous faisons actuellement manuellement (connexion des pairs, broadcast des opérations, stockage du log)
- Voir pour setup l'outil
**** DONE MUTE : Organiser une session de test sur mute-structs@0.4.0
- Afin de pouvoir implémenter le mécanisme de renommage sur de bonnes bases, il est nécessaire de tester la validité de cette branche
**** DONE MUTE : Enrichir *SyncService* pour assurer une livraison causale
- Disclaimer: algo de Victorien
- Algorithme
  - Ce mécanisme suppose qu'on a déjà une livraison FIFO
  - On pourrait, au moment où l'on supprime un élément, ajouter à l'opération de suppression /op2/ un couple <replicaNumber, networkClock>
  - Ce couple serait utilisé pour représenter la dernière opération /op1/ que l'on a reçu du pair dont on supprime un bloc
  - En recevant /op2/, il faudrait vérifier si on a déjà délivré /op1/
    - On peut vérifier cela simplement en checkant le *StateVector*
  - Si on l'a déjà reçue et délivrée, on peut délivrer /op2/
  - Sinon, on met l'opération en attente
- Remarques
  - Délivre pas les messages de façon optimale
  - Puisque on va potentiellement faire attendre la livraison d'une opération qui n'a aucun lien avec l'opération de suppression
  - Mais au moins assure une livraison causale des suppressions
** Semaine du <2018-01-22 Mon> au <2018-01-26 Fri>
*** Done
- MUTE : Implémenter le mécanisme de renommage
  - Implémentation de /generateRenamingSequence()/
  - Implémentation de /renameLocal()/
  - Implémentation des tests correspondants
    - Ajout de /generateStateA()/, /generateStateB()/ et de /generateStateC()/
    - A correspond au scénario où 2 utilisateurs écrivent à tour de rôle
    - B correspond au scénario où 1 utilisateur insère au sein de son dernier bloc de façon répétée
    - C correspond au scénario où 2 utilisateurs écrivent à tour de rôle mais avec des suppressions
    - Renvoie l'état du document, mais aussi la séquence de *DottedInterval* correspondante
  - Implémentation de /recomputeMapBlocks()/
- Réplication et cohérence de données : Cours 3
  - Slide 57 : besoin d'un ordre causal nécessairement ? On parle pas plutôt d'un ordre partiel de livraison ? (Potentiellement FIFO donc)
  - Slide 69 : pourquoi la version optimisé de LogootSplit ?
*** Planned
** Semaine du <2018-01-29 Mon> au <2018-02-02 Fri>
*** Done
- MUTE : Supprimer la boucle de rafraîchissement infinie de Angular
  - Philippe a réussi à trouver et à patcher l'origine de la boucle
- MUTE : Implémenter le mécanisme de renommage
- MUTE : Intégration des tests E2E
  - La méthode /waitForAngular()/ fonctionne donc désormais correctement
  - Ré-écriture des tests E2E pour l'utiliser plutôt que /sleep()/
  - Mais les tests ne sont toujours pas déterministes dans l'environnement Travis
  - /waitForAngular()/ retourne avant que le stockage ait eu lieu
  - Pour simplifier l'implémentation des tests liés au stockage, devrait émettre un évènement lorsqu'une nouvelle version du document est stocké
  - En attendant, re-utilise /sleep()/
  - Obtient des erreurs dont je ne comprends pas l'origine
    #+BEGIN_SRC
      mute App should broadcast updates to peers
      Failed: unknown error: Cannot read property 'CodeMirror' of null
    #+END_SRC
  - Ceci intervient après /waitForAngular()/
  - Cela signifierait que cette fonction retourne avant même que l'éditeur ne soit chargé
  - Si finalement /waitForAngular()/ n'attend pas qu'Angular ait fini de render l'application, je ne sais pas quoi faire
  - Laisse tomber personnellement les tests E2E pour le moment, perd trop de temps dessus
- DISTRIBUTED SYSTEMS : Se documenter sur IPFS
  - Whitepaper disponible à https://github.com/ipfs/papers/blob/master/ipfs-cap2pfs/ipfs-p2p-file-system.pdf
  - InterPlanetary File System
  - Un système de fichiers distribué
  - Adresse des problèmes similaires à nos travaux
    - Partition réseau
    - Disparition du endpoint
    - Censure
  - Vise à remplacer HTTP par un protocole plus puissant
  - Identifie dorénavant les données grâce à leur contenu
  - Overview
    - Une application web cherche à utiliser une ressource
    - Un service de nommage IPNS permet d'obtenir à partir du nom human-readable de la ressource son identifiant
    - L'identifiant de la ressource permet de récupérer son Merkle DAG
    - Le Merkle DAG permet d'identifier la version de la ressource à récupérer
    - La version de la ressource est échangée en utilisant BitTorrent
    - Des DHTs sont utilisées pour déterminer les noeuds disposant de la ressource
      - http://www.scs.stanford.edu/%7Edm/home/papers/kpos.pdf
  - Une ressource est donc répliquée chez les noeuds qui sont intéressés par celle-ci
  - Permet facilement d'assurer la disponibilité de sites statiques par exemple
  - Mais encore du mal à imaginer le fonctionnement avec des données dynamiques
  - Une discussion a justement eu lieu concernant ce type de données qui a conduit à une étude des CRDTs
  - Ressources utiles
    - Discussion initiale: https://github.com/ipfs/notes/issues/40
    - Notes sur les CRDTs: https://github.com/ipfs/research-CRDT
    - Pourquoi utiliser des CRDTs avec IPFS: https://www.youtube.com/watch?v=2VOF-Z-nLnQ
    - Construire un éditeur collaboratif reposant sur IPFS: https://www.youtube.com/watch?v=-kdx8rJd8rQ
    - Éditeur collaboratif temps réel reposant sur IPFS: https://peerpad.net/
    - Librairie de réseau P2P: https://libp2p.io/
- MUTE : Ajouter des tests pour *SyncService*
  - Était déjà fait depuis quelques temps, mais n'avait pas marqué la tâche comme complétée
- PLM
  - Annulation des tâches liées à PLM qui traînaient depuis des années
*** Planned
**** CANCELLED MUTE : Intégration des tests E2E
- Maintenant que la boucle Angular est supprimée, on peut reprendre les tests E2E pour les rendre déterministes
**** CANCELLED PLM : Gérer les exercices n'ayant pas d'entité solution dans le langage de programmation par défaut
- Actuellement, on considère que l'ensemble des exercices possèdent une entité solution en Java
- Lors de leur instanciation à partir des sources, on essaie de calculer le(s) monde(s) objectif(s) à partir de cette entité solution
- Ajouter un mécanisme de fallback vers un autre langage si l'entité solution Java n'est pas trouvée
- Déclencher une erreur si aucune entité solution n'est trouvée
**** CANCELLED PLM : Ajouter des tests d'intégration pour vérifier la sérialisation JSON
- Semblerait que la sérialisation JSON foire de temps en temps
  - Le JSON généré ne contient pas les opérations de la solution
- Implémenter des tests d'intégration
  - Vérifier si la sérialisation JSON existe
  - Vérifier si la sérialisation JSON peut être désérialiser correctement
  - Vérifier si l'instance obtenue possède des opérations solutions
  - Vérifier si les opérations solutions permettent bien d'atteindre l'état objectif ?
    - Je ne suis pas sûr qu'on puisse rejouer les opérations côté serveur actuellement
**** CANCELLED PLM : Corriger l'exercice Polygon360
- L'exercice Polygon360 ne peut pas être résolu actuellement
- Lorsqu'on soumet le code de la correction, on n'arrive pas à atteindre le monde objectif
  #+BEGIN_SRC
  Le monde 'Polygon360' diffère: x1 diffère. (trouvé Line (x263.445 y135.028 / x264.177 y149.000 / black) au lieu de Line (x263.968 y154.996 / x264.177 y149.000 / black) )
  #+END_SRC
- L'erreur a été reportée ici : https://github.com/BuggleInc/webPLM/issues/130
**** CANCELLED PLM : Trouver l'origine du crash de webPLM du <2016-10-12 mer.>
- L'application a de nouveau eu un crash le <2016-10-12 mer.>, de 17:54 jusqu'à 18h:26
- Il a fallu que je redémarre manuellement le container de webPLM
  - Pour une raison inconnue, il n'arrivait pas à redémarrer correctement
  - Suppression du container et déploiement d'un nouveau
- Voici les métriques récupérées par New Relic au moment du crash
  #+CAPTION: Informations sur les transactions web au moment du crash
  #+NAME:   fig:transactions.png
  [[file:img/crash-webplm-2016-10-12T17:54/transactions.png]]
  #+CAPTION: Informations sur les ressources utilisées par le serveur au moment du crash
  #+NAME:   fig:server.png
  [[file:img/crash-webplm-2016-10-12T17:54/server.png]]
  #+CAPTION: Informations sur les ressources utilisées par les différents processus au moment du crash
  #+NAME:   fig:processes.png
  file:img/crash-webplm-2016-10-12T17:54/processes.png
  #+CAPTION: Informations sur les ressources utilisées par les différents containers au moment du crash
  #+NAME:   fig:dockers.png
  [[file:img/crash-webplm-2016-10-12T17:54/dockers.png]]
- Les logs ne montrent aucune erreur expliquant le crash, seulement des requêtes d'exécution
  #+BEGIN_SRC
  2016-10-12 15:53:11 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8700 - Received a message
  2016-10-12 15:53:11 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8700 - {"cmd":"runExercise","args":{"lessonID":"recursion.logo", "exerciseID":"recursion.logo.koch.Koch","code":"def snowFlake (levels:Int, length:Double) {\n    snowSide(levels, length);\n    right(120);\n    setColor( Color.blue);\n    snowSide(levels, length);\n    right(120);\n    setColor(Color.orange);\n    snowSide(levels, length);\n    right(120);\n}\ndef snowSide(levels:Int, length:Double) {\n  if(levels==0){\n    return;\n  }else{\n    avance(length);\n    snowSide(levels-1,length/3);\n  }\n}"}}
  2016-10-12 15:53:11 +0000 [ERROR] from application in ForkJoinPool-3-worker-15 - PLMActor: executionActor ? StartExecution timeout
  2016-10-12 15:53:12 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8689 - Received a message
  2016-10-12 15:53:12 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8689 - {"cmd":"getExercise","args":{"lessonID":"recursion.logo","exerciseID":"recursion.logo.koch.HexaKoch"}}
  2016-10-12 15:53:15 +0000 [ERROR] from application in ForkJoinPool-3-worker-23 - PLMActor: executionActor ? StartExecution timeout
  2016-10-12 15:53:15 +0000 [ERROR] from application in ForkJoinPool-3-worker-29 - PLMActor: executionActor ? StartExecution timeout
  2016-10-12 15:53:17 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8651 - Received a message
  2016-10-12 15:53:17 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8651 - {"cmd":"runExercise","args":{"lessonID":"recursion.logo","exerciseID":"recursion.logo.spiral.Spiral","code":"var length : Int = 5\n\nbaisseCrayon()\ndef spiral(steps:Int, angle:Int, length:Int, increment:Int) {\n avance(length)\n  gauche(45)\n  spiral(0,8, length+3, increment+1)\n  \n}"}}
  2016-10-12 15:53:18 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8695 - Received a message
  2016-10-12 15:53:18 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8695 - {"cmd":"runExercise","args":{"lessonID":"recursion.logo","exerciseID":"recursion.logo.koch.Koch","code":"def snowFlake (levels:Int, length:Double) {\n    snowSide(levels, length);\n    right(120);\n    setColor(Color.blue);\n    snowSide(levels, length);\n    right(120);\n    setColor(Color.orange);\n    snowSide(levels, length);\n    right(120);\n}\n\ndef snowSide(levels:Int, length:Double) \n{\n  \n  if(length == 0)\n  {\n    return;\n  }\n  \n  else\n  {\n    avance(200);\n  }\n  \n}"}}
  2016-10-12 15:53:22 +0000 [ERROR] from application in ForkJoinPool-3-worker-5 - PLMActor: executionActor ? StartExecution timeout
  2016-10-12 15:53:23 +0000 [ERROR] from application in ForkJoinPool-3-worker-1 - PLMActor: executionActor ? StartExecution timeout
  2016-10-12 15:53:23 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8692 - Received a message
  2016-10-12 15:53:23 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8692 - {"cmd":"runExercise","args":{"lessonID":"recursion.logo","exerciseID":"recursion.logo.koch.SquareKoch","code":"void snowSquare (int levels, double length) {\n    squareSide(levels, length);\n    right(90);\n    setColor(Color.blue);\n    squareSide(levels, length);\n    right(90);\n    setColor(Color.orange);\n    squareSide(levels, length);\n    right(90);\n    setColor(Color.magenta);\n    squareSide(levels, length);\n    right(90);\n}\nvoid squareSide(int levels, double length) {\n  if(levels==0){avance(length);}\n  else{\n    squareSide(levels-1,length/2);\n    gauche(90);\n    squareSide(levels-1,length/2);\n    droite(90);\n    squareSide(levels-1,length/2);\n    droite(90);\n    squareSide(levels-1,length/2);\n    gauche(90);\n    squareSide(levels-1,length/2);\n  }\n}"}}
  2016-10-12 15:53:24 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8695 - Received a message
  2016-10-12 15:53:24 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8695 - {"cmd":"runExercise","args":{"lessonID":"recursion.logo","exerciseID":"recursion.logo.koch.PentaKoch","code":"void pentaKoch(int levels, double length) {\n  if(levels==0){\n    avance(length);\n  }\n  else{\n  pentaKoch(levels-1,length*0.4);\n    left(180-(360/5);\n    pentaKoch(levels-1,length*0.4);\n    right(360/5);\n    pentaKoch(levels-1,length*0.4);\n    right(360/5);\n    pentaKoch(levels-1,length*0.4);\n    right(360/5);\n    pentaKoch(levels-1,length*0.4);\n    left(180-(360/5);\n    pentaKoch(levels-1,length*0.4);\n  }\n}"}}
  2016-10-12 15:53:25 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8689 - Received a message
  2016-10-12 15:53:25 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8689 - {"cmd":"runExercise","args":{"lessonID":"recursion.logo","exerciseID":"recursion.logo.koch.Koch","code":"def snowFlake (levels:Int, length:Double) {\n    snowSide(levels, length);\n    right(120);\n    setColor(Color.blue);\n    snowSide(levels, length);\n    right(120);\n    setColor(Color.orange);\n    snowSide(levels, length);\n    right(120);\n}\ndef snowSide(levels:Int, length:Double) {\n  avance(length)\n  snowSide(levels, length)\n  right(120)\n  snowSide(levels, length)\n  right(120)\n  snowSide(levels, length)\n}"}}
  2016-10-12 15:53:27 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8689 - Received a message
  2016-10-12 15:53:27 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8689 - {"cmd":"runExercise","args":{"lessonID":"recursion.logo","exerciseID":"recursion.logo.koch.Koch","code":"def snowFlake (levels:Int, length:Double) {\n    snowSide(levels, length);\n    right(120);\n    setColor(Color.blue);\n    snowSide(levels, length);\n    right(120);\n    setColor(Color.orange);\n    snowSide(levels, length);\n    right(120);\n}\ndef snowSide(levels:Int, length:Double) {\n  if(levels==0){\n    return;\n  }else{\n    avance(length);\n    snowSide(levels-1,length/3);\n  }\n}"}}
  2016-10-12 15:53:30 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8689 - Received a message
  2016-10-12 15:53:30 +0000 [DEBUG] from application in application-akka.actor.default-dispatcher-8689 - {"cmd":"stopExecution","args":{}}
  2016-10-12 16:27:11 +0000 [INFO] from application in application-akka.actor.default-dispatcher-2 - Execution Mode: TRIBUNAL
  #+END_SRC
**** DONE MUTE : Supprimer la boucle de rafraîchissement infinie de Angular
- À l'heure actuelle, Angular rafraîchit de façon infinie l'interface, même si aucun évènement n'a lieu
- *Protractor* permet d'attendre que le rafraîchissement s'interrompe avant de déclencher les instructions suivantes
- Puisqu'il ne s'interrompt jamais, on ne peut pas utiliser cette méthode
- On utilise donc des /sleep(duration)/ en attendant
- Mais rien ne nous garantit que l'évènement a bien lieu avant la fin du /sleep()/
- Afin de rendre le comportement de nos tests déterministes, il est nécessaire de supprimer ce cycle de rafraîchissement infini
**** DONE DISTRIBUTED SYSTEMS : Se documenter sur IPFS
- https://ipfs.io/
**** DONE MUTE : Ajouter des tests pour *SyncService*
- *SyncService* est un composant critique de MUTE
- Écrire des tests pour *SyncService* permettrait:
  - S'assurer de son bon fonctionnement
  - Prévenir toute régression
- Il n'est cependant pas facile à tester
- Besoin de le refactorer ?
** Semaine du <2018-02-05 Mon> au <2018-02-09 Fri>
*** Done
- MUTE : Implémenter le mécanisme de renommage
  - Ajout de la fonction /completeRenamingMap()/
    - Génère la map de renommage pour tous les noeuds du modèle
      - Le pair ayant déclenché le renommage l'a effectué sur un état donné
      - Mais je peux avoir d'autres noeuds dans mon modèle
      - Il faut aussi renommer de façon déterministe ces noeuds
    - Prend la map de renommage globale et la liste des insertions concurrentes en paramètre
    - Extrait la liste des intervals d'identifiants de la map de renommage globale
    - Pour chaque insertion concurrente
      - Récupère l'identifiant précédent avec /findPrevious()/
      - Renomme l'identifiant par rapport au précédent avec /renameIdentifier()/
      - Génère l'interval d'identifiants correspondant au nouvel ident
  - Ajout de la fonction /findPrevious()/
    - Prend en paramètre un identifiant et une liste d'intervals d'identifiants
    - Trouve l'identifiant dans la liste d'intervals qui précéde le noeud inséré
    - Soit on insère un nouveau noeud entre 2 autres (on considère qu'il y a un bloc minimum)
      - Dans ce cas, l'identifiant précédent est le dernier identifiant du noeud précédent
    - Soit on insère un nouveau noeud en splittant un autre
      - Dans ce cas, l'identifiant précédent est un préfixe de l'identifiant courant
      - On peut le récupérer en tronquant l'identifiant courant
    - Pas de garantie sur l'ordre des intervals dans la liste
      - Peut pas interrompre la boucle de recherche si le noeud est inséré entre 2 autres
      - Par contre, dans le cas d'un split, on peut interrompre la boucle de recherche de façon safe
	- Un noeud ne peut pas être contenu dans 2 autres noeuds à la fois
    - Renvoie l'identifiant précédent ainsi que l'interval le contenant
- CRDT : Lire *A Study of CRDTs that do Computations*
*** Planned
**** DONE CRDT : Lire *A Study of CRDTs that do Computations*
- Disponible ici : https://dl.acm.org/citation.cfm?id=2745948
** Semaine du <2018-02-12 Mon> au <2018-02-16 Fri>
*** Done
- MUTE : Implémenter le mécanisme de renommage
  - A trouvé une erreur dans l'algorithme de /renameRemote()/
    - On regénère /renamingMap/ telle qu'elle a été générée par le site ayant déclenché le renommage à partir de l'état courant et des opérations de suppressions concurrentes
    - On génère une nouvelle map /completedRenamingMap/ à partir de /renamingMap/ et des opérations d'insertion concurrentes
    - On génère un nouvel état vide
    - On parcourt chaque noeud de l'ancien état et pour chacun
      1. On extrait l'interval d'identifiants du noeud
      2. On récupère les éléments correspondants
      3. On cherche dans /renamingMap/ le nouvel interval d'identifiants correspondants
      4. On insère dans le nouvel état un nouveau noeud généré à partir de ces données
    - Mais l'étape 2 peut échouer
      - Si le noeud a été modifié en concurrence (append, preprend, split ou suppression partielle)
      - Dans ce cas, l'interval d'identifiants du noeud ne correspond plus à celui d'enregistré dans /completedRenamingMap/
      - Par exemple, on cherche à renommer un noeud correspondant à l'interval /a[0,6]/ alors que dans /completedRenamingMap/ on a les entrées /a[0,5]/ et /a[6,6]/
	- Dû à une insertion en concurrence de /a6/
      - En utilisant simplement /a[0,6]/ en clé, on n'obtiendra pas de résultats
    - L'algo doit donc être corrigé
    - Plusieurs possibilités
      - [ ] Modifier la façon dont est générée /completedRenamingMap/
	- "Appliquer" les opérations concurrentes sur /renamingMap/
	- Permettrait d'obtenir une /completedRenamingMap/ qui colle exactement à notre état
	- Cependant, ça impliquerait d'implémenter la logique de manipulation d'intervals dans *RenamingMap*
	  - Insérer un nouveau bloc => Ajouter une entrée dans la map
	  - Append/Prepend => Modifier une entrée dans la map
	  - Split un bloc => Supprimer l'entrée correspondante et insérer les entrées correspondantes aux 2 morceaux du blocs résultant du split ainsi que le split
	  - Supprimer un bloc => Supprimer l'entrée correspondante
	  - Supprimer un morceau de bloc => Réduire la taille de l'interval d'une entrée
	- Ceci serait lourd et error-prone à mon sens
      - [ ] "Undo" les opérations concurrentes puis rejouer leur transformation
	- L'algorithme consisterait à
	  1. Revenir à l'état sur lequel a été effectué le renommage
	  2. Appliquer l'opération de renommage
	     - Permet de réutiliser le code de /renameLocal()/
	  3. Appliquer les opérations concurrentes
	     - Permet de réutiliser le code utilisé pour appliquer les opérations concurrentes à un renommage après qu'on ait appliqué le renommage
	- Pour l'étape 1, il faut donc "undo" les opérations concurrentes qui ont été appliquées à la copie locale
	  - "Undo" une insertion consiste simplement à supprimer l'interval inséré
	  - "Undo" une suppression est plus problématique
	    - Il s'agit d'insérer de nouveau l'interval supprimé, mais aussi son contenu
	    - Dans notre cas, nous n'avons plus accès au contenu
	    - Mais comme on va de toute façon re-supprimer l'interval en réappliquant l'opération ensuite, on peut se contenter d'insérer des caractères aléatoires
        - Cette solution me paraît intéressante car elle permet de factoriser du code et reste simple
	- Mais "undo" les opérations est une étape dont j'aimerai bien me passer
      - [X] Générer un état correspondant mais avec des éléments factices et remplacer ses éléments par ceux de l'état original
	- Au cours du renommage, on ne modifie que la structure de données (les blocs *RopesNodes*), pas ses éléments (/doc.str/)
	- Mais les deux sont intraséquement liés par design, on ne peut pas modifier la structure sans modifier les éléments
	  - Ce qui est pertinent d'un point de vue conceptuel
	  - Mais qui devient gênant dans le cas présent
	- Pour cela qu'on "undo" les opérations concurrentes dans la solution précédente, afin de revenir à un état où structure de données et éléments concordent
	- On peut cependant éviter de "undo" les opérations en utilisant des éléments factices
	- L'algorithme est le suivant
	  1. Générer un état vide
	  2. Appliquer une opération d'insertion du bloc résultant du renommage, avec des éléments factices
	  3. Appliquer les opérations concurrentes
	  4. Remplacer les éléments de la structure de données obtenue par ceux de l'ancien état
	- Offre de meilleures performances que la stratégie "undo"
	  - Au lieu d'appliquer /k/ opérations concurrentes nécessitant de parcourir la structure de données en /O(log(n))/
	  - On a juste besoin de remplacer /newDoc.str/ par /doc.str/
	  - Si l'implémentation évolue et qu'on répartit les éléments dans les blocs, on aura juste besoin de parcourir la structure de données complète en /O(n)/ pour remplacer les éléments
	- Cette solution permet d'améliorer les performances de l'opération de renommage tout en restant simple
- CRDT : Lire Legion
  - Approche intéressante
  - Plutôt que de construire un nouveau système entièrement distribué reposant sur des CRDTs, du P2P
  - Ils prennent un système centralisé, Google Realtime API
    - https://developers.google.com/google-apps/realtime/overview
  - Et l'améliore en déléguant une partie de ses responsabilités aux utilisateurs
  - Google Realtime API
    - Propose de manipuler une structure de données répliquées
    - Utilise un serveur centralisé
    - Lorsqu'un utilisateur effectue une modification, l'applique à sa copie puis l'envoie au serveur
    - Le serveur, en utilisant OT, transforme l'opération par rapport à sa copie et partage la modification aux autres participants
  - Legion
    - Override Google Realtime API
    - Plutôt que de manipuler la structure de données initiale, manipule un CRDT
    - Met en place et utilise un réseau P2P pour partager les modifications
    - Un pair est élu leader et se charge de mettre à jour la copie du serveur
      - À partir des changements effectués sur le CRDT depuis la dernière synchro, génère des opérations "standards" de Google Realtime API
      - À partir des changements entre la copie du serveur et sa version précédente, génère des opérations correspondantes pour le CRDT
    - Permet à des clients utilisant uniquement Google Realtime API de toujours participer à la collaboration
  - Permet d'améliorer les performances du système
    - Meilleure vitesse de propagation des changements
      - Puisqu'ils sont partagés directement entre utilisateurs
      - Plutôt que de passer par le serveur à chaque fois
    - Meilleure disponibilité
      - Si le serveur plante, les utilisateurs peuvent toujours collaborer
  - Tout en limitant l'effort d'adoption
    - Seulement 2 lignes de code à modifier semblerait pour utiliser Legion dans une application utilisant Google Realtime API à la base
      - Import du script de Legion
      - Utilisation du constructeur de Legion au lieu du constructeur de Google Realtime API
    - Collaboration possible avec les "Legacy clients"
  - Mais le serveur représente toujours un /Single Point Of Failure/
    - Se charge d'authentifier les utilisateurs
    - A la responsabilité des droits d'accès à la ressource
    - Joue le rôle de /signaling/
    - Conserve la clé de chiffrement symétrique des données au sein de la structure
  - Il est donc nécessaire de faire confiance au serveur avec cette approche
- CRDT : Lire *Consistency without concurrency control in large, dynamic systems*
  - Se base sur *Treedoc*
  - Problème adressé
    - Dans *TreeDoc*, le TID d'un élément (son identifiant) représente un chemin dans l'arbre
    - Au fur et à mesure que l'on insère des éléments dans l'arbre, sa hauteur augmente et donc la taille des identifiants
    - Mais supprimer des éléments ne réduit pas la hauteur de l'arbre, notamment dans le cas où l'élément supprimé est un noeud intermédiaire
  - Solution proposée
    - L'idée est de rebalancer l'arbre afin d'éliminer les "trous" dans celui-ci
    - La difficulté consiste à rebalancer l'arbre de façon uniforme sur toutes les copies
    - Ainsi que de gérer les opérations concurrentes à un rebalancement
    - Distingue 2 types de sites : les sites appartenant au /core/ et ceux appartenant à la /nebula/
    - Les sites appartenant au /core/ sont en charge d'effectuer le rebalancing
    - Permet de limiter le mécanisme lourd du rebalancing à un nombre restreint de sites stables grâce au /core/
    - Tout en permettant une collaboration dynamique à grande échelle grâce à la /nebula/
  - Rebalancing de l'arbre par les sites /core/
    - Doivent se mettre d'accord sur quand/quel état déclencher un rebalancing
    - Pour cela, utilisent un 2PC
    - Si un site /core/ reçoit une opération concurrente durant le protocole de consensus, celui-ci échoue
      - Priorité des opérations concurrentes
    - Chaque rebalancing fait évoluer l'/epoch/ de l'arbre
    - L'/epoch/ permet d'identifier le contexte dans lequel une opération a été générée
    - Une fois qu'un rebalancing a été effectué, les sites de la /nebula/ doivent exécuter localement le rebalancing sur leur copie
  - Renommage des opérations concurrentes au rebalancing par les sites /nebula/
    - Identifie les noeuds qui ont été rebalancés
    - Génère l'arbre balancé à partir de ces noeuds
    - Attache les noeuds qui ont été ajoutés en concurrence à leur parent précédent
    - Identifie le nouveau chemin menant au noeud concurrent
  - Remarques
    - Le rebalançing de l'arbre permet effectivement de garbage collecter la structure de données et de réduire la taille des identifiants utilisés
    - Mais il nécessite dans ce système un consensus entre les sites du /core/ pour être effectué
    - Voir si on arrive à faire sauter cette limitation et à proposer un mécanisme entièrement distribué
  - Questions
    - Est-ce qu'adapter ce mécanisme à *LogootSplit* est une contribution suffisante ?
    - Ou faut-il améliorer l'existant ?
*** Planned
**** DONE CRDT : Lire Legion
- Legion propose un système permettant de manipuler une variété de structures de données de manière décentralisée
- Voir https://legion.di.fct.unl.pt/
- Papier disponible ici : https://dl.acm.org/citation.cfm?id=3052673
**** DONE CRDT : Lire *Consistency without concurrency control in large, dynamic systems*
- Claudia m'a indiqué que le mécanisme de renommage lui rappelait ces travaux
- Présentation disponible ici : https://www.cs.cornell.edu/projects/ladis2009/talks/shapiro-talk-ladis2009.pdf
- Papier disponible là : https://www.cs.cornell.edu/projects/ladis2009/papers/letia-ladis2009.pdf
** Semaine du <2018-02-19 Mon> au <2018-02-23 Fri>
*** Done
- MUTE : Implémenter le mécanisme de renommage
  - Suite à la lecture de *Consistency without concurrency control in large, dynamic systems*, il est nécessaire de revoir les objectifs de cette implémentation
  - La principale question est jusqu'où aller dans une 1ère étape ?
    - Proposer une adaptation du mécanisme pour *LogootSplit* ?
    - Proposer une amélioration du mécanisme en le rendant concurrence-safe ?
  - Si on se limite à une adaptation du mécanisme pour *LogootSplit*
    - Ne devrait-on pas implémenter un mécanisme d'élection de leader pour l'expérimentation ?
      - Afin de proposer une évaluation la plus rigoureuse possible
    - Rappel du FLP theorem: le consensus n'est pas atteignable dans un système avec réseau asynchrone et où les noeuds peuvent tomber en panne
    - Il s'agit d'une hypothèse forte et qu'on va être incapable de reproduire en milieu expérimental
  - On va plutôt réfléchir à comment rendre commutative l'opération de renommage avec elle-même
  - Finalement, il s'agit d'un cas particulier de OT
    - Ici, nous avons un système avec 3 opérations
      - Insertion
      - Suppression
      - Renommage
    - Seul l'opération de renommage modifie le contexte réellement
    - Donc seules les opérations concurrentes à une opération de renommage doivent être transformées
    - Transformer une opération de renommage /op1/ concurrente par rapport à une autre /op2/ consiste à
      - Ne rien faire si /op2/ a la priorité sur /op1/
	- L'opération de renommage n'a pas d'effet sur les éléments de la structure de données
	- On peut donc considérer qu'aucune intention de l'utilisateur n'est associée à cette opération
	- On peut donc ignorer ce type d'opération dans certains cas tout en continuant de respecter l'intention de l'utilisateur
      - Appliquer /op1/ sinon
	- Recréer l'état obtenu après le renommage
	- Rejouer, en les transformant, les opérations d'insertion et de suppression concurrentes
	- Mapper le contenu de l'ancien état au nouveau
    - Transformer une opération d'insertion ou de suppression /op1/ par rapport à une opération de renommage /op2/ dépend de son contexte de génération
      - Si le contexte de génération de /op1/ est inférieur au contexte résultant de l'application de /op2/
	- Alors il suffit de transformer l'opération comme décrit précédemment dans ce journal
      - Sinon, cela signifie que le contexte de génération de /op1/ est concurrent au contexte résultant de l'application de /op2/
	- Auquel cas, l'idée est d'utiliser des /backward/forward transformations/
	- On recherche le contexte ancêtre commun de /op1/ et de /op2/
	- On transforme en arrière /op1/ pour obtenir une opération équivalente /op1'/ applicable dans ce contexte ancêtre
	- Puis on applique /op1'/ simplement en la considérant comme une opération concurrente à /op2/
	- Là encore, on va utiliser la /renamingMap/ qui a servi à passer du contexte ancêtre au contexte de /op1/ pour calculer la transformée arrière
	  - Juste qu'on va l'utiliser en sens inverse
- IPFS : Lire *Paper review. IPFS: Content addressed, versioned, P2P file system*
  - Argumente que le problème que IPFS adresse, la bande passante limitée, n'est pas un problème
    - D'après lui, les CDNs existent pour résoudre le problème
    - Sauf que les CDNs ne réduisent pas la bande passante consommée, ils la répartissent juste
      - Plutôt que d'utiliser ma bande passante pour fournir une ressource, je vais utiliser celle des différents serveurs du CDN
    - De plus, c'est le /host/ de la donnée qui a la charge d'utiliser sur un CDN pour répliquer la ressource
      - Je peux tout à fait refuser d'utiliser un CDN pour fournir les ressources statiques de mon application
    - Et c'est ensuite au CDN d'en assurer la disponiblité
      - Donc finalement on déplace la complexité de mon application au CDN
    - Avec IPFS, chaque consommateur d'une ressource peut en plus héberger et fournir cette donnée par la suite
      - Ceci peut s'additionner à un CDN utilisé initialement pour fournir la ressource
  - Donc considère que IPFS complique juste le système inutilement
    - Effectivement, construire un système entièrement distribué peut s'avérer plus complexe que de construire son équivalent centralisé
  - Argumente que des systèmes centralisés qui scalent et qui sont hautement disponibles existent
    - Dropbox, Facebook
    - Selon moi, il ne faut toutefois pas oublier la complexité de ces systèmes et leurs coûts de fonctionnement
  - De mon point de vue, son analyse manque la cible
    - Un des intérêts de IPFS est de changer le mode d'adressage des données
      - On passe d'un adressage /host-based/ à un adressage /content-based/
      - Ceci permet d'éviter le phénomène de centralisation de l'Internet
      - On n'est alors plus dépendant d'un système tiers auquel on ne fait pas forcément confiance (privacy, disponbilité, ...) pour partager une donnée
      - Et on économise effectivement de la bande passante avec ce nouveau mode d'adressage
	- Pour partager une ressource dans un réseau local, il suffit qu'un seul des noeuds ait téléchargé la ressource
    - La réplication des données proposée par IPFS permet aussi le fonctionnement en /offline/
      - Puisque je possède la donnée, je n'ai pas besoin de passer par un service tiers pour y accéder
    - IPFS vise aussi à proposer un système qui met à disposition toutes les mécanismes de scalabilité et de disponibilité qu'il mentionne
      - Plutôt que chacun (ou du moins ceux qui ont les moyens) ne les réimplémente
      - L'idée est de les mettre à disposition de tous tout en cachant leur complexité
  - Une réponse d'un développeur de IPFS est disponible ici : https://news.ycombinator.com/item?id=16432502
  - Référence une bonne vidéo explicative sur les Merkle Trees
    - Disponible ici: https://www.youtube.com/watch?v=YIc6MNfv5iQ
*** Planned
**** DONE IPFS : Lire *Paper review. IPFS: Content addressed, versioned, P2P file system*
- Un blogger a rédigé un post sur son analyse de IPFS
- Peut être intéressant de lire son avis
- Disponible ici : https://muratbuffalo.blogspot.fr/2018/02/paper-review-ipfs-content-addressed.html
** Semaine du <2018-03-05 Mon> au <2018-03-09 Fri>
*** Done
- MUTE : Fix mécanisme de causalité
  - Le scénario permettant de générer ce bug est le suivant:
    - 2 collaborateurs, A et B, rédigent un document (insertions multiples)
    - Au bout d'un moment, A effectue une opération de suppression
    - A poursuit ensuite avec quelques opérations d'insertion
    - À ce moment, les 2 copies doivent converger
    - A se déconnecte
    - B recharge le document
    - B va alors obtenir l'état du document correspondant à toutes ses opérations et toutes les opérations de A précédant l'opération de suppression
  - Ce bug est dû à un problème de sérialisation/désérialisation
    - Le champ /dependencies/ de *RichLogootSOperation* est perdu au cours de la sérialisation/désérialisation
    - Dans le cas d'une opération *LogootSAdd*, cela ne pose pas de problème
    - Dans le cas d'une opération *LogootSDel*, l'opération n'est plus valide
  - L'opération désérialisée est ré-instanciée à 2 endroits du code
    - Dans *SyncMessageService*, lorsqu'on reçoit l'opération d'un autre pair
      - On regénère l'opération manuellement dans /deserializeRichLogootSOperation()/
      - Mais on ne traite pas le cas où l'opération n'est pas valide dans ce code
      - L'opération est donc délivrée correctement puis stockée
    - Dans *SyncStorageService*, lorsqu'on regénère le document à partir du log
      - Ici, on utilise /RichLogootSOperation.fromPlain()/ pour réinstancier l'opération
      - /RichLogootSOperation.fromPlain()/ détecte que l'opération est non-valide et renvoie alors la valeur *null*
      - *SyncStorageService* filtre les opérations *null* et ne délivre donc que les opérations valides
  - Il est intéressant de noter que ce bug affecte uniquement les opérations de suppression des autres utilisateurs
    - Les opérations d'insertion n'ont de toute façon pas de dépendances
    - Nos opérations de suppression sont stockées directement et ne perdent pas leur champ /dependencies/ au cours de la sérialisation/désérialisation
  - Ce bug serait donc similaire au cas où l'on ne stockerait pas les opérations de suppression générées par les autres utilisateurs
    - On ne peut dès lors plus rejouer les opérations suivantes de ces utilisateurs (delivery FIFO)
    - On ne peut potentiellement plus rejouer nos opérations si une d'entre elles est une opération de suppression dépendant d'une insertion distante bufferisée (delivery causal)
  - L'origine de ce problème provient de cette ligne : https://github.com/coast-team/mute/blob/a1ef5a94ddf8fd1bd741040a63ba8eb62f28ab88/src/app/doc/editor/cursor/cursor.proto#L2
    - Afin de réutiliser la configuration *Protobuf* écrite dans /mute-core/, on l'importe dans ce nouveau fichier
    - Cependant, importer dans *Protobuf* se traduit par regénérer le code correspondant à la configuration du package et l'exporter en potentiellement écrasant un objet existant
    - Ici, la configuration de /sync/ est plus récente que celle de /cursor/
      - J'ai regénéré les fichiers *Protobuf* dans /mute-core/, mais pas ceux dans /mute/
    - Ainsi, le code correspondant à la nouvelle configuration de /sync/ n'est pas pris en compte
    - Car il est écrasé par son ancienne version qui a été générée au préalable et incluse dans le code correspondant à la configuration de /cursor/
  - Plusieurs problèmes sont donc à corriger :
    - [X] Utiliser /RichLogootSOperation.fromPlain()/ dans /deserializeRichLogootSOperation()/
      - Permettrait de disposer d'un traitement uniforme des opérations, qu'elles soient reçues à l'instant d'un collaborateur ou qu'il s'agisse d'opérations provenant d'un log
      - Modification de la fonction pour utiliser /RichLogootSOperation.fromPlain()/
    - [X] Actualiser les fichiers *Protobuf* de /mute/
    - [X] Inclure l'actualisation des fichiers *Protobuf* dans le processus de build de /mute-core/ et de /mute/
      - Permettrait de s'assurer que les configurations *Protobuf* soient à jour
      - Ajout de la commande /npm run proto/ dans la phase /prebuild/ de /mute/ et de /mute-core/
- MUTE : Implémenter le mécanisme de renommage
  - L'algorithme pour transformer les opérations de suppression par rapport à un renommage était incorrect
    - Une opération de suppression peut supprimer des identifiants faisant parti du renommage
    - Mais aussi des identifiants qui ont été insérés en concurrence à l'opération de renommage
  - La marche à suivre dans ces 2 cas est différente
  - Pour les identifiants faisant parti du renommage
    - Pour déterminer quels identifiants sont concernés, il faut calculer l'intersection entre les identifiants supprimés et les identifiants renommés
    - Il suffit ensuite de trouver l'image de l'intersection dans /renamingMap/
  - Pour les identifiants insérés en concurrence
    - Pour déterminer quels identifiants sont concernés, il faut calculer la différence entre les identifiants supprimés et l'intersection calculée précédemment
    - Il faut ensuite calculer l'image de la différence dans le nouveau contexte
  - Ajout des fonctions /intersection()/ et /difference()/ dans *IdentifierInterval*
  - Modification de /findPredecessor()/ pour gérer le cas sans prédecesseur
    - Auparavant, initialisait /predecessorId/ et /predecessorIdInterval/ avec un des éléments de /renamedIntervals/
    - Mais potentiellement, aucun élément de /renamedIntervals/ n'est le prédécesseur de /id/
    - Dans ce cas, on pouvait retourner un /predecessorId/ tel que /predecessorId > id/, ce qui est incorrect
    - Dorénavant, /findPredecessor()/ retourne soit le couple /<predecessorId, predecessorIdInterval>/, soit /undefined/
  - Modification de /renameIdentifierInterval()/ pour gérer le cas sans prédecesseur
    - Puisque /findPredecessor()/ peut maintenant retourner la valeur /undefined/, il faut modifier /renameIdentifierInterval()/ en conséquence
    - Initialise /newPredecessorId/ avec /Id[-1, 0, 0, 0]/
      - Comme les éléments renommés commence à /Id[0, renamingReplicaNumber, renamingClock, 0]/, on est sûr que /newPredecessorId/ est plus petit que n'importe quel autre identifiant
    - Puis écrase cette valeur si /findPredecessor()/ a retourné un résultat
  - Étude d'une modification de /renameIdentifierInterval()/ pour limiter l'augmentation de la taille des splits effectués en concurrence d'un renommage
    - Dans le scénario suivant :
      #+CAPTION: Renommage d'un split concurrent
      #+NAME: fig:concurrent-split-renaming.jpg
      [[file:img/concurrent-split-renaming.jpg]]
      - Un site A effectue le renommage suivant : /a[0..5] -> a'[0..5]/
      - Un site B insére en concurrence du renommage l'identifiant /a1b0/
      - Lorsqu'on joue l'insertion de /a1b0/ sur le site A, on la transforme par rapport au renommage
      - On insère en finalité l'identifiant /a'1a1b0/
      - Mais si on insérait l'identifiant /a'1b0/, l'ordre obtenu serait identique
	#+CAPTION: Renommage optimisé d'un split concurrent
        #+NAME: fig:concurrent-split-better-renaming.jpg
        [[file:img/concurrent-split-better-renaming.jpg]]
      - De plus, /a1/ peut être en pratique un identifiant de taille conséquente
    - Le but est d'améliorer le mécanisme de renommage en omettant la particule qui a été renommé
    - L'algorithme est le suivant
      - Une fois qu'on a trouvé que /a1/ est le prédecesseur de /a1b0/
      - On vérifie si /a1/ est un préfixe de /a1b0/
      - Si c'est le cas
	- On tronque /a1b0/ pour ne récupérer que le reste: /b0/
      - On récupère l'image de /a1/ : /a'1/
      - On concatène /a'1/ et /b0/ et on obtient ainsi /a'1b0/
    - Mais un problème survient si le prédecesseur du split est aussi le dernier élément d'un interval renommé
      #+CAPTION: Contre-exemple de l'optimisation du renommage d'un split concurrent
      #+NAME: fig:counter-example-concurrent-split-better-renaming.jpg
      [[file:img/counter-example-concurrent-split-better-renaming.jpg]]
    - Il suffit juste de ne pas tronquer l'identifiant renommé dans ce cas
    - Pour expliciter le cas problématique :
    - Il ne faut pas que, suite à cette optimisation, on tombe dans un cas où l'on compare 2 tuples ayant une profondeur différente
      - On appelle profondeur d'un tuple sa position dans l'identifiant d'origine
      - On ne compare que des tuples de même profondeur
      - Ici, il faut s'assurer que l'optimisation ne va pas aboutir dans certains scénarios à une comparaison incohérente
      - C'est ce qu'il se passe notamment dans le contre-exemple
- IAEM : Réunion de rencontre doctorants 1A et Directeur ED IAEM
  - Comité de suivi de thèse
    - Rôle
      - Audition du doctorant conduisant la rédaction d'un rapport jugeant de la faisabilité de la thèse et donc de la capacité de réinscription du doctorant
    - Le rapport du comité de suivi doit être déposé par le doctorant sur ADUM
  - Formations
    - Doctoriales
      - Valide le quota de formations "professionnelles" à suivre
*** Planned
**** DONE MUTE : Fix mécanisme de causalité
- En effectuant des tests utilisateurs sur MUTE, on s'est aperçu que le mécanisme de causalité présente des problèmes
- On constate le bug en rechargeant un document
  - Au cours de l'initialisation du document à partir du log stocké, on n'arrive pas à rejouer toutes les opérations
  - Certaines opérations sont bufferisées car on n'aurait pas toutes les dépendances pour les jouer
  - On n'arrive donc pas à rejouer l'entièreté du log
  - Une synchronisation avec un autre pair peut débloquer la situation
  - Cependant, si ces opérations du log sont stockées dans cet ordre, cela veut dire qu'elles ont été délivrées dans cet ordre
  - Voir d'où provient ce bug
    - Est-ce qu'une opération n'est pas correctement loggée ?
    - Ou est-ce qu'une opération n'est pas détectée comme délivrable alors qu'elle est en vérité ?
** Semaine du <2018-03-12 Mon> au <2018-03-16 Fri>
*** Done
- MUTE : Implémenter le mécanisme de renommage
  - Poursuite de l'étude de l'optimisation du renommage des splits concurrents
    - Y-a-t il un moyen d'assurer qu'on ne tombe pas dans le scénario problématique ?
    - Le raisonnement suivant suffit :
      - Le problème se produit lorsqu'on compare deux identifiants /id'1/ et /id'2/ entre eux afin de déterminer leur ordre avec
	- /id1/, identifiant généré au cours d'un split puis ensuite ré-écrit en /id'1/ de façon optimisé au cours du renommage
	  - Sa taille est donc inchangé dans le pire cas, réduite sinon
	- /id2/, identifiant généré au cours d'une insertion puis ensuite transformé en /id'2/ au cours du renommage
	  - Sa taille est donc augmenté de 1
      - Le simple fait qu'on ait pu effectuer l'optimisation implique que des identifiants /id3/ et /id4/ existent tels que /id3 < id1 < id4 < id2/
      - On a donc :
	- /id1/ étant un split, il se décompose en /id3 + x/ et se ré-écrit en /id'3 + x/
	- /id'2 = id'4 + id2/
      - Ainsi, /id'3 < id'1 < id'4 < id'2/
    - On peut donc bel et bien optimiser le renommage d'un split si celui-ci n'a pas eu lieu à la fin d'un interval renommé
  - Implémentation de l'optimisation du renommage des splits concurrents
    - Ajout d'une méthode /reverseTruncate()/ dans *Identifier*
    - Modification de /renameIdentifierInterval()/ pour tronquer la partie "renommée" dans split
  - Réflexion sur l'exécution d'une opération distante de renommage
    - Pour exécuter /renameRemote()/, j'ai besoin d'accéder à la liste des opérations concurrentes à l'opération de renommage
    - Pour pouvoir accéder à ce log, 2 approches sont possibles
      - *LogootSplit* maintient le log des opérations
      - On délègue la responsabilité de fournir le log, et donc de maintenir ce dernier, au composant qui délivre l'opération de renommage
    - Maintenir le log dans *LogootSplit*
      - Si on maintient le log dans *LogootSplit*, on a finalement que déplacé le problème
      - Auparavant on avait des identifiants qui grossissaient indéfiniment
      - Maintenant on a des tombstones sous la forme du log
      - Pour que la solution soit viable, il est nécessaire de garbage collecter les opérations
    - Garbage collection d'opérations
      - Dans *LogootSplit*, j'ai besoin de conserver une opération tant qu'un renommage en concurrence peut être générée
      - Dans le cas où seulement un pair peut effectuer le renommage
	- On peut garbage collecter une opération si la dernière opération de renommage dépend causalement sur celle-ci
      - Dans le cas où chaque pair peut déclencher un renommage
	- Je ne peux plus garbage collecter les opérations à moins de connaître avec certitude les membres du groupe
	- Si je connais la liste des membres du groupe
	  - Je peux garbage collecter une opération /op_i/ si je reçois de chaque membre une opération /op_k/ dépendant causalement d'une opération de renommage /op_j/ dominant /op_i/
	    - Possible d'obtenir cette information grâce à l'/epoch/ d'une opération
	- Si je ne connais pas les membres du groupe
	  - Il est toujours possible qu'un membre du groupe ait été invité sans que je ne le sache
	  - Il peut émettre des opérations concurrentes aux miennes et à celles des autres depuis un certain temps
	  - Il est donc possible qu'il émette un renommage qui soit concurrent et prioritaire par rapport à un renommage qui ayant été accepté par tous les autres collaborateurs
	- Scénario d'exemple :
	  #+CAPTION: Garbage collection rendant impossible un renommage concurrent
          #+NAME: fig:concurrent-renaming-incorrect-gc.jpg
	  [[file:img/concurrent-renaming-incorrect-gc.jpg]]
    - Déléguer la responsabilité
      - Je me retrouve dans ce cas avec un problème d'interface
      - La fonction /execute()/ de *LogootSOperation* prend en paramètre juste un *LogootSRopes* pour le moment
	- Puisque *LogootSAdd* et *LogootSDel* contiennent toutes les informations nécessaires à leur exécution
      - Dans le cas de *LogootSRename*, on se verrait contraint d'ajouter un paramètre supplémentaire, /log: LogootSOperation[]/
      - Comment spécifier une interface compatible ?
      - Possible de contourner le problème d'interface en incluant le log dans *LogootSRename* même
	- Lorsqu'on génère l'opération, on laisse ce champ /undefined/
	- Lorsqu'on reçoit une opération de renommage distante
	  - On la désérialise
	  - Puis on l'enrichit avec notre log d'opérations
	- Ça ne me paraît pas intuitif
	- Il faudrait ajouter des contraintes pour forcer l'enrichissement de l'opération avant de pouvoir l'appliquer
      - Autre possibilité, ajouter des interfaces *Transformable* et *Applicable*
	- Il existerait 2 classes pour l'opération de renommage
	- L'opération locale de renommage générerait une opération distante qui implémenterait *Transformable*
	- Cette opération serait partagée avec les autres collaborateurs
	- Et c'est en utilisant sa fonction /transform(doc: LogootSRopes, concurrentOps: LogootSOperation[])/ que les collaborateurs obtiendraient une opération de renommage implémentant *Applicable*
	  - Comment contraindre la pureté de la fonction /transform()/ ?
	- Et c'est grâce à la fonction /applyTo(doc: LogootSRopes)/ de cette dernière qu'ils mettraient à jour leur copie du document
	- Les opérations *LogootSAdd* et *LogootSDel* devraient aussi être refactorées de la sorte
	- De cette manière, toute la logique des opérations et de leurs transformations serait encapsulée dans /mute-structs/
	- Et la seule responsabilité de /mute-core/ serait de transformer les opérations avant de les délivrer
      - Des interfaces supplémentaires, *Compressable* et *Decompressable*, permettent de représenter le mécanisme d'optimisation de l'opération de renommage
	- Les opérations distantes implémenteraient l'interface *Compressable*
	- Les compresser renverraient une opération équivalent *Decompressable*
	- Ainsi, on les compresserait avant de les partager sur le réseau
	- Les sites distants les décompresseraient avant de les transformer par rapport aux opérations concurrentes  puis de les appliquer sur leur état
	- On peut généraliser ce comportement aux autres opérations *LogootSAdd* et *LogootSDel*
	  - Pour *LogootSDel*, on peut par exemple ne conserver que la partie unique des identifiants supprimés
	    - On gagne en bande passante mais on perd en calculs
	  - Pour *LogootSAdd*, les méthodes /compress()/ et /decompress()/ peuvent se contenter de renvoyer l'opération telle quelle
- Meeting
  - Now that i have figure out and written down the transformation functions of insertions and deletions concurrent to a renaming
  - Thinking about the correct way to implement it
  - At first, the renaming mechanism did not require much additional metadata
    - A log of operations
  - So thought about putting everything needed in /mute-structs/
  - But it was because only one node would be able to perform the renaming
  - Now that we want every node to be able to perform the renaming, we have to deal with concurrent renamings
  - It requires much more metadata
  - And some of these metadata are in /mute-core/ currently
  - So some reflexion to do a correct separation of concern
  - And how these two projects will interact together
*** Planned
**** IN-PROGRESS MUTE : Implémenter le mécanisme de renommage
** Semaine du <2018-03-19 Mon> au <2018-03-23 Fri>
*** Done
*** Planned
**** TODO OT : Lire *OT FAQ*
- Voir si les méthodes utilisées dans le mécanisme de renommage correspondent bien à des fonctions de transformations
- Voir dans ce cas quelles sont les propriétés qu'elles doivent vérifiées, et comment prouver qu'elles les vérifient bien
- Disponible ici : http://www3.ntu.edu.sg/home/czsun/projects/otfaq/#_Toc321146157
**** TODO MUTE : Implémenter un log CRDT-agnostic
- Pour le besoin des expérimentations, nous avons besoin de traces d'utilisation
- Cependant le log d'opérations que nous stockons actuellement dans MUTE n'est pas adapté
  - Il n'offre qu'une linéarisation des opérations pour un utilisateur donné
    - On ne conserve pas les informations de concurrence et de causalité
  - On ne peut pas utiliser les opérations directement avec un CRDT
    - Les opérations étant des opérations *LogootSplit*
    - On peut s'en sortir en rejouant les opérations et en récupérant les opérations textes générées
- On pourrait, afin de construire un corpus, générer un autre log contenant
  - Les opérations textes de l'utilisateur
    - Afin de pouvoir les rejouer en utilisant un autre modèle
  - Avec pour chaque opération
    - Le vecteur d'état représentant le contexte de génération de l'opération
      - Afin de capturer les informations de causalité des opérations
    - Potentiellement, l'état après opération
      - Afin de vérifier la correction du modèle utilisé
      - Mais dans ce cas, il ne faudrait jouer strictement que les opérations distantes faisant partie des dépendances de la prochaine opération locale
- On pourrait ainsi rejouer fidèlement une collaboration à partir des logs de chaque participant
  - Un noeud par participant
  - Initialise un réseau P2P regroupant tous les noeuds
  - Dans l'ordre causal de ses opérations locales
    - Chaque noeud essaie de jouer sa prochaine opération
      - Il peut la jouer uniquement s'il a reçu toutes ses dépendances causales
      - Si le noeud ne possède pas toutes les dépendances de sa prochaine opération, il attend
    - Une fois l'opération locale jouée, il partage avec les autres noeuds l'opération distante correspondante
    - Potentiellement, vérifie après avoir appliqué chaque opération que l'état courant correspond à l'état enregistré
  - Doit s'assurer que
    - Le réseau P2P est correctement construit avant de donner le top départ aux noeuds
    - Chaque opération distante est délivrée /at-least-once/ à chaque noeud
- Reste à réfléchir à comment gérer la fin de la simulation
  - Ce n'est pas parce qu'un noeud n'a plus opérations locales à jouer que la collaboration est finie
    - D'autres noeuds peuvent avoir des opérations restantes de leur côté
    - Par exemple, un noeud peut avoir jouer toutes ses opérations au bout de 5min sur les 50min de collaboration
  - Faut-il spécifier un état final aux noeuds qu'ils doivent atteindre avant de quitter ?
    - Grâce au vecteur d'état obtenu en aggrégeant le nombre d'opérations par noeud
  - Ou finalement, chaque noeud peut quitter une fois son travail effectué ?
**** TODO CRDT : Se renseigner sur replikativ
- http://replikativ.io/
**** TODO CRDT : Se renseigner sur OrbitDB
- https://github.com/orbitdb/orbit-db
**** TODO DISTRIBUTED SYSTEMS : Se renseigner sur Dat
- https://datproject.org/
- https://datproject.org/paper
**** TODO CONSENSUS : Lire *The weakest failure detector for solving consensus*
- *Perspectives on the CAP Theorem* ([[perspective-cap-theorem]]) cite ce papier de la manière suivante
  #+BEGIN_QUOTE
  In many ways, a failure detector exactly encapsulates the synchrony requirements for consensus.
  They showed that a particular failure detector Ω is the weakest failure detector for solving consensus.
  The failure detector Ω essentially encapsulates a leader election service
  #+END_QUOTE
- Je ne comprends pas le lien entre /failure detector/ et /synchrony requirements for consensus/
- Ce papier m'aidera p-e à comprendre
**** TODO CRDT : Lire *Replicated Data Types: Specification, Verification, Optimality*
**** TODO CRDT : Lire *CRDT notes*
- Disponible ici: https://github.com/pfrazee/crdt_notes
- Regroupe des notes de lectures sur plusieurs articles concernant les CRDT
**** TODO CRDT : Lire *A Conflict-Free Replicated JSON Datatype*
- Disponible ici: https://arxiv.org/pdf/1608.03960.pdf
**** TODO MUTE : Faire une liste des scénarios à tester d'une version à l'autre
**** TODO MUTE : Rendre permanent l'identifiant et les clocks d'un utilisateur pour un document
- Pour l'historique, il est important de conserver la liste des collaborateurs ayant collaboré sur un document
- Pour faciliter l'implémentation de cette liste, il faut modifier le code pour réutiliser le même identifiant pour un même utilisateur au fil des sessions
- À noter que les clocks aussi doivent être conservée pour prévenir tout bug
  - Clock de /mute-structs/ pour éviter de générer un bloc avec le même identifiant
  - Clock de /mute-core/ pour éviter de labeller des messages avec le même couple /<identifiant, clock>/
**** TODO MUTE : Ajouter le /docId/ en tant que paramètre du constructeur de *DocService*
- Cet attribut est actuellement initialisé via le flux /initSource/
- Celui-ci émet l'identifiant du document actuel à son initialisation
- Cependant, l'initialisation du document correspond à l'instantiation du *DocService*
- Nous pouvons donc simplifier le code en ajoutant /docId/ en tant que paramètre du constructeur
**** TODO MUTE : Étudier la suppression de *LogootSBlock*
- L'utilisation de *LogootSBlock* semble limitée
  - Conserve une référence vers un *IdentifierInterval*
  - Cet *IdentifierInterval* ne peut que grossir
  - Conserve le nombre d'éléments de cet *IdentifierInterval* qui existent encore
  - Permet de déterminer si les éléments de cet *IdentifierInterval* nous appartiennent
    - Pour voir si on peut append ou prepend
- C'est ensuite une ou plusieurs instances de *RopesNodes* qui référencent un *LogootSBlock*
- Les instances de *LogootSBlock* sont aussi référencées dans /mapBaseToBlock/
  - Cette map nous permet de récupérer un bloc via sa base
  - Elle est utilisée pour récupérer un bloc s'il existe, ou pour déterminer qu'il faut le créer
- Serait-il possible de supprimer *LogootSBlock* ?
  - L'objectif serait de simplifier la structure de données
  - Il faudrait en contrepartie enrichir *RopesNodes* ou *LogootSRopes*
  - Voir si ça permettrait effectivement de simplifier le code
**** TODO MUTE : Fusionner blocs adjacents issus d'un split après la suppression
- Lors d'un split, un bloc est coupé en deux et un nouveau bloc est inséré au milieu
- Après la suppression du bloc inséré, on pourrait fusionner les deux parties du bloc initial pour le recréer
- Ceci permettrait de rendre commutatif ce scénario d'opérations : /insertion-split-deletion/
**** TODO MUTE : Ajouter la gestion du titre du document
- Le titre du document peut être l'objet de modifications concurrentes
- Il est donc nécessaire de s'assurer qu'il converge chez tous les utilisateurs
- Utiliser *LogootSplit* pour gérer le titre semble un peu /overkill/
- Un simple *LWW-Register* suffirait
- Voir pour lier le document et son titre
  - Le titre peut être amener à évoluer suite à des modifications du document
  - Lier l'état du document et l'état du titre?
**** TODO MUTE : Améliorer le pipe /slice/ d'Angular pour les *Strings*
- Angular propose un pipe /slice/ permettant de limiter le nombre de caractères que nous souhaitons afficher d'une *String*
- Cependant, rien n'indique dans le résultat si la chaîne de caractères a effectivement été tronquée ou non
- Créer un pipe /sliceString/ ajoutant '...' au résultat si la chaîne a été coupée
**** TODO CRDT : Lire *Kaleido*
* Glossaire
- Eventual convergence property
  #+BEGIN_QUOTE
  Copies of shared objects are identical at all sites if updates cease and all generated updates are propagated to all sites.
  #+END_QUOTE
- Precedence property
  #+BEGIN_QUOTE
  If one update /Oa/ causally precedes another update /Ob/, then,
  at each site, the execution of /Oa/ happens before the execution of /Ob/.
  #+END_QUOTE
- Intention-preservation
  #+BEGIN_QUOTE
  For any update /O/, the effect of executing /O/ at all sites is the same as the intention of /O/ when executed at the site that originated it,
  and the effect of executing /O/ does not change the effect of non concurrent operations.
  #+END_QUOTE
- Mathematics operations properties
  - Associativity
    #+BEGIN_QUOTE
    Associativity means that you can apply a function in any order:
      =f(a,f(b,c)) = f(f(a,b),c)=
    #+END_QUOTE
  - Commutativity
    #+BEGIN_QUOTE
    Commutativity means that a function's arguments are order-insensitive:
      =f(a,b) = f(b,a))=
    #+END_QUOTE
  - Idempotence
    #+BEGIN_QUOTE
    Idempotence means you can call a function on the same input any number of times and get the same result:
      =f(f(x))=f(x) (e.g., max(42, max(42, 42)) = 42))=
    #+END_QUOTE
- Systems properties
  - Safety
    #+BEGIN_QUOTE
    Informally, an algorithm is safe if nothing bad ever happens. -- Perspectives on the CAP Theorem
    #+END_QUOTE
  - Liveness
    #+BEGIN_QUOTE
    By contrast, an algorithm is live if eventually something good happens. -- Perspectives on the CAP Theorem
    #+END_QUOTE
  - Unreliable
    #+BEGIN_QUOTE
    There are many different ways in which a system can be unreliable. There may be partitions,
    crash failures, message loss, malicious attacks (or Byzantine failures), etc. -- Perspectives on the CAP Theorem
    #+END_QUOTE
